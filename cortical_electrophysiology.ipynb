{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780c8e36-1686-4929-8d53-a52dbcadcc62",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multiunit recordings from multiple cortical areas\n",
    "\n",
    "We will collect neurons from several cortical areas to perform population *dynamical* and *attractor* analysis, and get the *functional connectivity*.     \n",
    "This will address three relevant points:\n",
    "- Does the dynamic analysis hold at **higher temporal resolution**?\n",
    "    - How do events statistics (duration and size) compare to 2-photon?\n",
    "- Are population events only a **side-effect of behavior** (locomotion, whisker pad, pupil)?\n",
    "    - Do behavioral components explain pattern reproducibility?\n",
    "- Do **all areas of cortex** show attractor dynamics?\n",
    "    - How does cluster reproducibility compare to 2-photon?\n",
    "\n",
    "To do all this, we analyse the [data](https://janelia.figshare.com/articles/dataset/Eight-probe_Neuropixels_recordings_during_spontaneous_behaviors/7739750/4) by [Stringer et al. 2019](science.org/doi/10.1126/science.aav7893).   \n",
    "Eight-probe Neuropixels recordings in three mice during spontaneous activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99df4ec6-2371-4d70-bfe2-c3e54d074390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "from builtins import exec\n",
    "exec(open(\"./imports_functions.py\").read())\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43d468-6d74-49c0-98ea-a4ee385dc16b",
   "metadata": {},
   "source": [
    "**WARNING**: the next cell takes time to download and unzip the neuropixel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a72f962-c629-4438-9264-9e1204cfe184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data available.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"stringer/7739750.zip\"):\n",
    "    print(\"Downloading neuropixel data ...\")\n",
    "    resp = wget.download(\"https://janelia.figshare.com/ndownloader/articles/7739750/versions/4\", \"stringer/7739750.zip\")\n",
    "    print(\"... Done: \"+resp)\n",
    "\n",
    "if not os.path.exists(\"stringer/7739750\"):\n",
    "    # unzip downloaded folder\n",
    "    if os.path.exists(\"stringer/7739750.zip\"):\n",
    "        print(\"... unzipping\")\n",
    "        shutil.unpack_archive(\"stringer/7739750.zip\", \"stringer/7739750\")\n",
    "        shutil.unpack_archive(\"stringer/7739750/spks.zip\", \"stringer/7739750/spks\")\n",
    "        shutil.unpack_archive(\"stringer/7739750/faces.zip\", \"stringer/7739750/faces\")\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(\"All data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c45d437-412e-4f0c-91cb-003c7ae09467",
   "metadata": {},
   "source": [
    "### Data prepreocessing\n",
    "\n",
    "This analysis is based on the file `ephysLoad.m`.\n",
    "\n",
    "Each \"spks\" is a structure of length 8, where each entry is a different probe (these probes were recorded simultaneously). It contains the spike times (in seconds, e.g. 4048.44929626 sec (?kHz sampling)), the cluster identity of each spike (its cell), and the height of each cluster on the probe.\n",
    "\n",
    "The location of each site on the probe in microns in the Allen CCF framework is given in \"ccfCoords\". The brain area for each site is in \"borders\" as a function of the height of the site. \n",
    "\n",
    "We need the spikes from each area and probe to be separate lists. So, we build a dictionary to hold them, and save it locally as `area_spiketrains.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11030168-b84e-46a8-bda7-4a2fbab74a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loaded populations\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"stringer/7739750/area_spiketrains.npy\"):\n",
    "    area_spiketrains = np.load(\"stringer/7739750/area_spiketrains.npy\", allow_pickle=True).item()\n",
    "    print(\"... loaded populations\")\n",
    "else:\n",
    "    print(\"... collecting populations\")\n",
    "    \n",
    "    probeLoc = sio.loadmat('stringer/7739750/probeLocations.mat')\n",
    "    probeBorders = sio.loadmat('stringer/7739750/probeBorders.mat', squeeze_me=True)\n",
    "\n",
    "    mouse_names = ['Krebs','Waksman','Robbins']\n",
    "    cortical_areas = ['FrCtx','FrMoCtx','SomMoCtx','SSCtx','V1','V2','RSP']\n",
    "\n",
    "    # first count the cells you want to take with this structure\n",
    "    # then think on how you want to store the spikes... compatible with the dynamical_analysis\n",
    "    area_spiketrains = {\n",
    "        'Krebs' : {'FrCtx':[], 'FrMoCtx':[], 'SomMoCtx':[], 'SSCtx':[], 'V1':[], 'V2':[], 'RSP':[]},\n",
    "        'Waksman' : {'FrCtx':[], 'FrMoCtx':[], 'SomMoCtx':[], 'SSCtx':[], 'V1':[], 'V2':[], 'RSP':[]},\n",
    "        'Robbins' : {'FrCtx':[], 'FrMoCtx':[], 'SomMoCtx':[], 'SSCtx':[], 'V1':[], 'V2':[], 'RSP':[]}\n",
    "    }\n",
    "\n",
    "    for imouse in range(len(mouse_names)):\n",
    "        print(mouse_names[imouse])\n",
    "\n",
    "        spks = sio.loadmat('stringer/7739750/spks/spks%s_Feb18.mat'%mouse_names[imouse], squeeze_me=True)\n",
    "\n",
    "        # probe k\n",
    "        # k = 7\n",
    "        for k in range(8):\n",
    "            print(\"probe\",k)\n",
    "\n",
    "            # spike times (in seconds)\n",
    "            st = spks['spks'][k][0]\n",
    "            # clusters\n",
    "            clu = spks['spks'][k][1]\n",
    "            print(\"clusters (cells) of the spikes\",len(np.unique(clu)))\n",
    "            # cluster heights (in microns)\n",
    "            # (see siteCoords to convert to site location)\n",
    "            Wh = spks['spks'][k][2]\n",
    "\n",
    "            # where is the probe in the brain (consolidated labels)\n",
    "            # borders are in microns\n",
    "            # use Wh to determine which clusters are in which brain region\n",
    "            borders = probeBorders['probeBorders'][imouse]['borders'][k]\n",
    "            for j in range(len(borders)):\n",
    "                population = [] # one population per border, there can be several borders\n",
    "                b = borders[j]\n",
    "                if b[2] not in cortical_areas:\n",
    "                    continue\n",
    "                print('upper border %d um, lower border %d um, area %s'%(b[0],b[1],b[2]))\n",
    "                wneurons = np.logical_and(Wh>=b[1], Wh<b[0])\n",
    "                nn = wneurons.sum()\n",
    "                print('%d neurons in %s'%(nn,b[-1]))\n",
    "                # we should not include population smaller than those in MICrONS\n",
    "                if nn<10:\n",
    "                    print('population too small. Rejected.')\n",
    "                    continue\n",
    "\n",
    "                cortical_neurons = np.nonzero(wneurons)[0]\n",
    "                for cn in cortical_neurons:\n",
    "                    cn_idxs = [i for i in range(len(clu)) if clu[i]==cn]\n",
    "                    # print(cn_idxs)\n",
    "                    population.append( sorted(st[cn_idxs]) )\n",
    "                    \n",
    "                area_spiketrains[ mouse_names[imouse] ][ b[2] ].append( population )\n",
    "            print()\n",
    "\n",
    "    # save to file\n",
    "    np.save(\"stringer/7739750/area_spiketrains.npy\", area_spiketrains)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001efe03-3e0a-4255-aa62-23639d33a6eb",
   "metadata": {},
   "source": [
    "The following spiketrains will be loaded.\n",
    "\n",
    "| mouse | probe | borders (um) | area | #neurons |\n",
    "|:----|:----|:----|:---|:---|\n",
    "| **Krebs** | 0 | 4000, 1100 | FrMoCtx | 5 |\n",
    "|           | 1 | 4000, 1800 | FrMoCtx | 73 |\n",
    "|           | 2 | 4000, 2600 | V1 | 61 |\n",
    "|           | 3 | 4000, 2400 | V1 | 141 |\n",
    "|           | 4 | 4000, 1800 | SomMoCtx | 65 |\n",
    "|           | 5 | 4000, 2100 | SomMoCtx | 26 |\n",
    "|           | 6 | 4000, 2350 | V1 | 68 |\n",
    "|           | 7 | 4000, 2600 | V1 | 64 |\n",
    "| **Waksman** | 0 | 4000, 1700 | FrMoCtx | 446 |\n",
    "|             | 0 | 1200, 0 | FrMoCtx | 201 |\n",
    "|             | 1 | 4000, 2150 | FrCtx | 31 |\n",
    "|             | 2 | 4000, 2700 | V1 | 155 |\n",
    "|             | 3 | 4000, 2250 | RSP | 112 |\n",
    "|             | 4 | 4000, 2000 | SomMoCtx | 220 |\n",
    "|             | 5 | 4000, 2600 | SSCtx | 50 |\n",
    "|             | 6 | 4000, 2650 | V2 | 124 |\n",
    "|             | 7 | 4000, 2850 | V1 | 96 |\n",
    "| **Robbins** | 0 | 4000, 3400 | FrMoCtx | 16 |\n",
    "|             | 1 | 4000, 3100 | FrMoCtx | 70 |\n",
    "|             | 3 | 4000, 3550 | RSP | 10 |\n",
    "|             | 4 | 4000, 3500 | SomMoCtx | 10 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f0754be-e291-4a07-9bda-2660756cdd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_frame_duration = 0.00000001 # sec (e.g. 4048.44929626 s)\n",
    "# frame_duration = 0.001 # sec (e.g. 4048.449 s)\n",
    "frame_duration = 0.01 # sec (e.g. 4048.45 s)\n",
    "local_path = os.getcwd() + '/stringer/7739750/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "278c2d9c-d9c9-4139-a39a-cb6d4e19a134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krebs\n",
      "FrMoCtx\n",
      "    population firing: 2.84±2.85 sp/frame\n",
      "    cells firing rate: 0.04±0.20 sp/s\n",
      "... generating surrogates to establish population event threshold\n",
      "... loaded surrogates\n",
      "    event size threshold (mean): 3.4416623623776474\n",
      "... find peaks\n",
      "... find minima\n",
      "... find population events\n",
      "... signatures of population events\n",
      "    number of events: 12189\n",
      "    number of events per sec: 2.388518650099948\n",
      "    events duration: 0.090±0.040\n",
      "    events size: 18.000±6.694\n",
      "... Similarity of events matrix\n",
      "... clustering\n",
      "    linkage\n",
      "    surrogate events signatures for clustering threshold\n",
      "... loaded surrogates\n",
      "    cluster reproducibility threshold: 0.2987436376216102\n",
      "    cluster size threshold: 2\n",
      "    Total number of clusters: 294\n",
      "    # clusters (after removing those below reproducibility threshold): 281\n",
      "... finding cluster cores\n",
      "    removing cores firing unspecifically\n",
      "    gathering cores from all clusters\n",
      "    # cores: 62\n",
      "    # non-cores: 11\n",
      "    cores per cluster: 10.61±5.48 (min 0, max 32)\n",
      "    others per cluster: 62.98±4.48 (min 47, max 73)\n",
      "    starting tractor analysis\n",
      "... coloring frames\n",
      "... finding trajectories\n",
      "... performing dimensionality reduction (using PCA)\n",
      "(129215, 3)\n",
      "... testing cluster manifolds\n",
      "SomMoCtx\n",
      "    population firing: 3.34±2.79 sp/frame\n",
      "    cells firing rate: 0.05±0.23 sp/s\n",
      "... generating surrogates to establish population event threshold\n",
      "... loaded surrogates\n",
      "    event size threshold (mean): 4.6765188650349785\n",
      "... find peaks\n",
      "... find minima\n",
      "... find population events\n",
      "... signatures of population events\n",
      "    number of events: 14332\n",
      "    number of events per sec: 2.803131637072296\n",
      "    events duration: 0.080±0.039\n",
      "    events size: 16.000±6.616\n",
      "... Similarity of events matrix\n",
      "... clustering\n",
      "    linkage\n",
      "    surrogate events signatures for clustering threshold\n",
      "... loaded surrogates\n",
      "    cluster reproducibility threshold: 0.35616326834914114\n",
      "    cluster size threshold: 2\n",
      "    Total number of clusters: 206\n",
      "    # clusters (after removing those below reproducibility threshold): 178\n",
      "... finding cluster cores\n",
      "    removing cores firing unspecifically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gathering cores from all clusters\n",
      "    # cores: 48\n",
      "    # non-cores: 17\n",
      "    cores per cluster: 6.94±4.21 (min 0, max 19)\n",
      "    others per cluster: 58.06±4.21 (min 46, max 65)\n",
      "    starting tractor analysis\n",
      "... coloring frames\n",
      "... finding trajectories\n",
      "... performing dimensionality reduction (using PCA)\n",
      "(128006, 3)\n",
      "... testing cluster manifolds\n",
      "    population firing: 1.64±1.58 sp/frame\n",
      "    cells firing rate: 0.06±0.28 sp/s\n",
      "... generating surrogates to establish population event threshold\n",
      "... loaded surrogates\n",
      "    event size threshold (mean): 2.2897011667771343\n",
      "... find peaks\n",
      "... find minima\n",
      "... find population events\n",
      "... signatures of population events\n",
      "    number of events: 12006\n",
      "    number of events per sec: 2.3497126269751942\n",
      "    events duration: 0.090±0.039\n",
      "    events size: 6.000±2.786\n",
      "... Similarity of events matrix\n",
      "... clustering\n",
      "    linkage\n",
      "    surrogate events signatures for clustering threshold\n",
      "... loaded surrogates\n",
      "    cluster reproducibility threshold: 0.5155888302068389\n",
      "    cluster size threshold: 2\n",
      "    Total number of clusters: 67\n",
      "    # clusters (after removing those below reproducibility threshold): 52\n",
      "... finding cluster cores\n",
      "    removing cores firing unspecifically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gathering cores from all clusters\n",
      "    # cores: 19\n",
      "    # non-cores: 7\n",
      "    cores per cluster: 1.87±1.48 (min 0, max 5)\n",
      "    others per cluster: 24.13±1.48 (min 21, max 26)\n",
      "    starting tractor analysis\n",
      "... coloring frames\n",
      "... finding trajectories\n",
      "... performing dimensionality reduction (using PCA)\n",
      "(128046, 3)\n",
      "... testing cluster manifolds\n",
      "V1\n",
      "    population firing: 4.36±4.39 sp/frame\n",
      "    cells firing rate: 0.07±0.30 sp/s\n",
      "... generating surrogates to establish population event threshold\n",
      "... loaded surrogates\n",
      "    event size threshold (mean): 5.639604262147799\n",
      "... find peaks\n",
      "... find minima\n",
      "... find population events\n",
      "... signatures of population events\n",
      "    number of events: 11188\n",
      "    number of events per sec: 2.1916391356855387\n",
      "    events duration: 0.100±0.042\n",
      "    events size: 20.000±9.019\n",
      "... Similarity of events matrix\n",
      "... clustering\n",
      "    linkage\n",
      "    surrogate events signatures for clustering threshold\n",
      "... loaded surrogates\n",
      "    cluster reproducibility threshold: 0.315854948708489\n",
      "    cluster size threshold: 2\n",
      "    Total number of clusters: 104\n",
      "    # clusters (after removing those below reproducibility threshold): 100\n",
      "... finding cluster cores\n",
      "    removing cores firing unspecifically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gathering cores from all clusters\n",
      "    # cores: 38\n",
      "    # non-cores: 23\n",
      "    cores per cluster: 8.46±6.90 (min 0, max 24)\n",
      "    others per cluster: 52.54±6.90 (min 37, max 61)\n",
      "    starting tractor analysis\n",
      "... coloring frames\n",
      "... finding trajectories\n",
      "... performing dimensionality reduction (using PCA)\n",
      "(129116, 3)\n",
      "... testing cluster manifolds\n",
      "    population firing: 4.49±4.18 sp/frame\n",
      "    cells firing rate: 0.03±0.18 sp/s\n",
      "... generating surrogates to establish population event threshold\n",
      "... loaded surrogates\n",
      "    event size threshold (mean): 5.958191066649793\n",
      "... find peaks\n",
      "... find minima\n",
      "... find population events\n",
      "... signatures of population events\n",
      "    number of events: 11515\n",
      "    number of events per sec: 2.2547227777714682\n",
      "    events duration: 0.100±0.045\n",
      "    events size: 26.000±14.885\n",
      "... Similarity of events matrix\n",
      "... clustering\n",
      "    linkage\n",
      "    surrogate events signatures for clustering threshold\n",
      "... loaded surrogates\n",
      "    cluster reproducibility threshold: 0.2900881762430503\n",
      "    cluster size threshold: 2\n",
      "    Total number of clusters: 403\n",
      "    # clusters (after removing those below reproducibility threshold): 375\n",
      "... finding cluster cores\n",
      "    removing cores firing unspecifically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gathering cores from all clusters\n",
      "    # cores: 120\n",
      "    # non-cores: 21\n",
      "    cores per cluster: 18.86±13.88 (min 0, max 72)\n",
      "    others per cluster: 124.31±11.32 (min 83, max 141)\n",
      "    starting tractor analysis\n",
      "... coloring frames\n",
      "... finding trajectories\n",
      "... performing dimensionality reduction (using PCA)\n",
      "(129077, 3)\n",
      "... testing cluster manifolds\n",
      "    population firing: 3.42±3.43 sp/frame\n",
      "    cells firing rate: 0.05±0.23 sp/s\n",
      "... generating surrogates to establish population event threshold\n",
      "... loaded surrogates\n",
      "    event size threshold (mean): 4.457858931076882\n",
      "... find peaks\n",
      "... find minima\n",
      "... find population events\n",
      "... signatures of population events\n",
      "    number of events: 11611\n",
      "    number of events per sec: 2.2759356896745713\n",
      "    events duration: 0.100±0.042\n",
      "    events size: 20.000±8.934\n",
      "... Similarity of events matrix\n",
      "... clustering\n",
      "    linkage\n",
      "    surrogate events signatures for clustering threshold\n",
      "... loaded surrogates\n",
      "    cluster reproducibility threshold: 0.3180095423197237\n",
      "    cluster size threshold: 2\n",
      "    Total number of clusters: 199\n",
      "    # clusters (after removing those below reproducibility threshold): 168\n",
      "... finding cluster cores\n",
      "    removing cores firing unspecifically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gathering cores from all clusters\n",
      "    # cores: 54\n",
      "    # non-cores: 14\n",
      "    cores per cluster: 9.36±6.68 (min 0, max 26)\n",
      "    others per cluster: 58.64±6.68 (min 42, max 68)\n",
      "    starting tractor analysis\n",
      "... coloring frames\n",
      "... finding trajectories\n",
      "... performing dimensionality reduction (using PCA)\n",
      "(128272, 3)\n",
      "... testing cluster manifolds\n",
      "    population firing: 3.66±3.35 sp/frame\n",
      "    cells firing rate: 0.06±0.25 sp/s\n",
      "... generating surrogates to establish population event threshold\n",
      "... loaded surrogates\n",
      "    event size threshold (mean): 4.792838315565842\n",
      "... find peaks\n",
      "... find minima\n",
      "... find population events\n",
      "... signatures of population events\n",
      "    number of events: 11429\n",
      "    number of events per sec: 2.2413864786482884\n",
      "    events duration: 0.100±0.045\n",
      "    events size: 19.000±8.906\n",
      "... Similarity of events matrix\n",
      "... clustering\n",
      "    linkage\n",
      "    surrogate events signatures for clustering threshold\n",
      "... loaded surrogates\n",
      "    cluster reproducibility threshold: 0.3240296446183197\n",
      "    cluster size threshold: 2\n",
      "    Total number of clusters: 110\n",
      "    # clusters (after removing those below reproducibility threshold): 106\n",
      "... finding cluster cores\n",
      "    removing cores firing unspecifically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gathering cores from all clusters\n",
      "    # cores: 52\n",
      "    # non-cores: 12\n",
      "    cores per cluster: 10.21±6.40 (min 0, max 25)\n",
      "    others per cluster: 53.79±6.40 (min 39, max 64)\n",
      "    starting tractor analysis\n",
      "... coloring frames\n",
      "... finding trajectories\n",
      "... performing dimensionality reduction (using PCA)\n",
      "... testing cluster manifolds\n",
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;241;43m0\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# start of spontaneous activity in each mouse (in seconds)\n",
    "etstart = [3811, 3633, 3323]\n",
    "\n",
    "for imouse,(mousename,areas) in enumerate(area_spiketrains.items()):\n",
    "    print(\"\\nmouse:\",mousename)\n",
    "    \n",
    "    exp_path = local_path + '%s/'%mousename\n",
    "    exp_tstart = etstart[imouse]\n",
    "\n",
    "    # reading behavior data to make statistics about event dependence on it\n",
    "    # we will use the field 'stimulus' to store the avg motSVD of the frames \n",
    "    # The behavioral file is the processed version of a mouse face movie (time x pixels x pixels). \n",
    "    faces = sio.loadmat('stringer/7739750/faces/%s_face_proc.mat'%mousename, squeeze_me=True)\n",
    "    video_timestamps = faces['times'] # same temporal resolution of ephy\n",
    "    motSVD = faces['motionSVD']\n",
    "    exp_istart = (np.abs(video_timestamps - exp_tstart)).argmin()    \n",
    "    motSVD_1c = motSVD[:,0] # only first component\n",
    "    motSVD_1c[motSVD_1c < -4000] = np.mean(motSVD_1c) # corrections\n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "    ax.plot(video_timestamps[exp_istart:], motSVD_1c[exp_istart:], linewidth=0.5, color='k')\n",
    "    fig.savefig(exp_path+\"/motSVD_%s.png\"%mousename, transparent=True, dpi=900)\n",
    "    plt.close()\n",
    "    fig.clear()\n",
    "    fig.clf()\n",
    "\n",
    "    for area,probe_populations in areas.items():\n",
    "        if len(probe_populations)>0:\n",
    "            print(\"area: \",area)\n",
    "                        \n",
    "            for ipop,spiketrains in enumerate(probe_populations): \n",
    "                print(\"population:\",ipop)\n",
    "\n",
    "                # rounding to ms\n",
    "                spiketrains = [np.round(sp, 3) for sp in spiketrains]\n",
    "                start_time = min([min(st) for st in spiketrains])\n",
    "                stop_time = max([max(st) for st in spiketrains])\n",
    "                time = np.arange(start_time,stop_time,frame_duration)\n",
    "\n",
    "                fig = plt.figure(figsize=[12.8,4.8])\n",
    "                for row,train in enumerate(spiketrains):\n",
    "                    plt.scatter( train, [row]*len(train), marker='o', edgecolors='none', s=1, c='k' )\n",
    "                plt.ylabel(\"cell IDs\")\n",
    "                plt.xlabel(\"time (s)\")\n",
    "                # plt.show()\n",
    "                fig.savefig(exp_path+'%s_%s_rasterplot.png'%(area,ipop), transparent=False, dpi=800)\n",
    "                plt.tight_layout()\n",
    "                plt.close()\n",
    "\n",
    "                ophys_cell_ids = list(range(len(spiketrains)))\n",
    "                ophys_cell_indexes = ophys_cell_ids # here is an alias\n",
    "\n",
    "                core_reproducibility_perc = 95 # % threshold for detecting cores\n",
    "                scan_spiketrains = spiketrains\n",
    "                scan_id = '_%s_%s'%(area,ipop)\n",
    "                \n",
    "                %run \"dynamical_analysis.ipynb\"\n",
    "                \n",
    "                # # Match smooth motion energy curve with the cluster it belongs to\n",
    "                # # Count the number of events belonging to a pattern before and after the change.\n",
    "                # ccolors,ccounts = np.unique(cluster_color_array, return_counts=True)\n",
    "                # cluster_events_counts = dict(zip(ccolors,ccounts))\n",
    "                # Npre_beh_cluster = {el:0. for el in np.unique(cluster_color_array)}\n",
    "                # Npost_beh_cluster = {el:0. for el in np.unique(cluster_color_array)}\n",
    "                # for sni in smoothed_beh_indices:\n",
    "                #     snitime = exp_tstart + sni * frame_duration\n",
    "                #     snitime_pre = snitime - 0.15 # s\n",
    "                #     snitime_post = snitime + 0.15 # s\n",
    "                #     for ievent,(event,ecolor) in enumerate(zip(events,cluster_color_array)):\n",
    "                #         event_start_time = exp_tstart + event['start'] * frame_duration\n",
    "                #         if snitime_pre < event_start_time and event_start_time < snitime:\n",
    "                #             Npre_beh_cluster[ecolor] += 1\n",
    "                #         if snitime < event_start_time and event_start_time < snitime_post:\n",
    "                #             Npost_beh_cluster[ecolor] += 1\n",
    "                # # detail\n",
    "                # fig = plt.figure()\n",
    "                # plt.scatter(range(len(Npre_beh_cluster.keys())), Npre_beh_cluster.values(), marker='<', c=list(Npre_beh_cluster.keys()), edgecolors=list(Npre_beh_cluster.keys()), s=1)\n",
    "                # plt.scatter(range(len(Npost_beh_cluster.keys())), Npost_beh_cluster.values(), marker='>', c=list(Npost_beh_cluster.keys()), edgecolors='none', s=1)\n",
    "                # plt.vlines(range(len(Npost_beh_cluster.keys())), Npost_beh_cluster.values(), Npre_beh_cluster.values(), colors=list(Npost_beh_cluster.keys()), linewidths=0.6)\n",
    "                # plt.ylabel('occurrence')\n",
    "                # plt.xlabel('Patterns')\n",
    "                # fig.savefig(exp_path+\"/results/Pattern_behavior_%s_%s%s.png\"%(mousename,area,ipop), transparent=True, dpi=600)\n",
    "                # plt.close()\n",
    "                # fig.clear()\n",
    "                # fig.clf()\n",
    "                # # summary\n",
    "                # Nsame = 0\n",
    "                # Npost = 0\n",
    "                # Npre = 0\n",
    "                # for pre,post in zip(Npre_beh_cluster.values(),Npost_beh_cluster.values()):\n",
    "                #     if pre==post: Nsame +=1\n",
    "                #     if pre>post: Npre +=1\n",
    "                #     if pre<post: Npost +=1\n",
    "                # fig = plt.figure()\n",
    "                # plt.bar([0,1,2], [Npre,Nsame,Npost], width=0.8, color='C0')\n",
    "                # plt.ylabel('occurrences')\n",
    "                # plt.xlabel('pattern timing relative to movement')\n",
    "                # plt.xticks(range(3),['before','same','after'])\n",
    "                # fig.savefig(exp_path+\"/results/Pattern_behavior_summary_%s_%s%s.png\"%(mousename,area,ipop), transparent=True, dpi=600)\n",
    "                # plt.close()\n",
    "                # fig.clear()\n",
    "                # fig.clf()\n",
    "                \n",
    "                # PCA dimensional reduction, trajectories, and manifold checking\n",
    "                %run \"attractor_analysis.ipynb\"\n",
    "\n",
    "    gc.collect()\n",
    "    print()\n",
    "    \n",
    "    0/0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df7b3e-1e8f-433b-8d6a-74ab074db700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
