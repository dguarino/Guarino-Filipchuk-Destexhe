{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780c8e36-1686-4929-8d53-a52dbcadcc62",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multiunit recordings from several cortical areas\n",
    "\n",
    "We will collect neurons from several cortical areas to perform population *dynamical* and *attractor* analysis, and get the *functional connectivity*.     \n",
    "This will address three relevant points:\n",
    "- Does the dynamic analysis hold at **higher temporal resolution**?\n",
    "    - How do events statistics (duration and size) compare to 2-photon?\n",
    "- Are population events only a **side-effect of behavior** (locomotion, whisker pad, pupil)?\n",
    "    - Do behavioral components explain pattern reproducibility?\n",
    "- Do **all areas of cortex** show attractor dynamics?\n",
    "    - How do pattern trajectories compare to MICrONS?\n",
    "\n",
    "To do all this, we analyse the [data](https://janelia.figshare.com/articles/dataset/Eight-probe_Neuropixels_recordings_during_spontaneous_behaviors/7739750/4) by [Stringer et al. 2019](science.org/doi/10.1126/science.aav7893).   \n",
    "Eight-probe Neuropixels recordings in three mice during spontaneous activity.   \n",
    "\n",
    "This notebook calls `dynamical_analysis.ipynb` and `attractor_analysis.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99df4ec6-2371-4d70-bfe2-c3e54d074390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "from builtins import exec\n",
    "exec(open(\"./imports_functions.py\").read())\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43d468-6d74-49c0-98ea-a4ee385dc16b",
   "metadata": {},
   "source": [
    "**WARNING**: the next cell takes time to download and unzip the neuropixel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a72f962-c629-4438-9264-9e1204cfe184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data available.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"stringer/7739750.zip\"):\n",
    "    print(\"Downloading neuropixel data ...\")\n",
    "    resp = wget.download(\"https://janelia.figshare.com/ndownloader/articles/7739750/versions/4\", \"stringer/7739750.zip\")\n",
    "    print(\"... Done: \"+resp)\n",
    "\n",
    "if not os.path.exists(\"stringer/7739750\"):\n",
    "    # unzip downloaded folder\n",
    "    if os.path.exists(\"stringer/7739750.zip\"):\n",
    "        print(\"... unzipping\")\n",
    "        shutil.unpack_archive(\"stringer/7739750.zip\", \"stringer/7739750\")\n",
    "        shutil.unpack_archive(\"stringer/7739750/spks.zip\", \"stringer/7739750/spks\")\n",
    "        shutil.unpack_archive(\"stringer/7739750/faces.zip\", \"stringer/7739750/faces\")\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(\"All data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c45d437-412e-4f0c-91cb-003c7ae09467",
   "metadata": {},
   "source": [
    "### Data prepreocessing\n",
    "\n",
    "This analysis is based on the file `ephysLoad.m`.\n",
    "\n",
    "Each \"spks\" is a structure of length 8, where each entry is a different probe (these probes were recorded simultaneously). It contains the spike times (in seconds, e.g. 4048.44929626 sec (?kHz sampling)), the cluster identity of each spike (its cell), and the height of each cluster on the probe.\n",
    "\n",
    "The location of each site on the probe in microns in the Allen CCF framework is given in \"ccfCoords\". The brain area for each site is in \"borders\" as a function of the height of the site. \n",
    "\n",
    "We need the spikes from each area and probe to be separate lists. So, we build a dictionary to hold them, and save it locally as `area_spiketrains.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11030168-b84e-46a8-bda7-4a2fbab74a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loaded populations\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"stringer/7739750/area_spiketrains.npy\"):\n",
    "    area_spiketrains = np.load(\"stringer/7739750/area_spiketrains.npy\", allow_pickle=True).item()\n",
    "    print(\"... loaded populations\")\n",
    "else:\n",
    "    print(\"... collecting populations\")\n",
    "    \n",
    "    probeLoc = sio.loadmat('stringer/7739750/probeLocations.mat')\n",
    "    probeBorders = sio.loadmat('stringer/7739750/probeBorders.mat', squeeze_me=True)\n",
    "\n",
    "    mouse_names = ['Krebs','Waksman','Robbins']\n",
    "    cortical_areas = ['FrCtx','FrMoCtx','SomMoCtx','SSCtx','V1','V2','RSP']\n",
    "\n",
    "    # first count the cells you want to take with this structure\n",
    "    # then think on how you want to store the spikes... compatible with the dynamical_analysis\n",
    "    area_spiketrains = {\n",
    "        'Krebs' : {'FrCtx':[], 'FrMoCtx':[], 'SomMoCtx':[], 'SSCtx':[], 'V1':[], 'V2':[], 'RSP':[]},\n",
    "        'Waksman' : {'FrCtx':[], 'FrMoCtx':[], 'SomMoCtx':[], 'SSCtx':[], 'V1':[], 'V2':[], 'RSP':[]},\n",
    "        'Robbins' : {'FrCtx':[], 'FrMoCtx':[], 'SomMoCtx':[], 'SSCtx':[], 'V1':[], 'V2':[], 'RSP':[]}\n",
    "    }\n",
    "\n",
    "    for imouse in range(len(mouse_names)):\n",
    "        print(mouse_names[imouse])\n",
    "\n",
    "        spks = sio.loadmat('stringer/7739750/spks/spks%s_Feb18.mat'%mouse_names[imouse], squeeze_me=True)\n",
    "\n",
    "        # probe k\n",
    "        # k = 7\n",
    "        for k in range(8):\n",
    "            print(\"probe\",k)\n",
    "\n",
    "            # spike times (in seconds)\n",
    "            st = spks['spks'][k][0]\n",
    "            # clusters\n",
    "            clu = spks['spks'][k][1]\n",
    "            print(\"clusters (cells) of the spikes\",len(np.unique(clu)))\n",
    "            # cluster heights (in microns)\n",
    "            # (see siteCoords to convert to site location)\n",
    "            Wh = spks['spks'][k][2]\n",
    "\n",
    "            # where is the probe in the brain (consolidated labels)\n",
    "            # borders are in microns\n",
    "            # use Wh to determine which clusters are in which brain region\n",
    "            borders = probeBorders['probeBorders'][imouse]['borders'][k]\n",
    "            for j in range(len(borders)):\n",
    "                population = [] # one population per border, there can be several borders\n",
    "                b = borders[j]\n",
    "                if b[2] not in cortical_areas:\n",
    "                    continue\n",
    "                print('upper border %d um, lower border %d um, area %s'%(b[0],b[1],b[2]))\n",
    "                wneurons = np.logical_and(Wh>=b[1], Wh<b[0])\n",
    "                nn = wneurons.sum()\n",
    "                print('%d neurons in %s'%(nn,b[-1]))\n",
    "                # we should not include population smaller than those in MICrONS\n",
    "                if nn<10:\n",
    "                    print('population too small. Rejected.')\n",
    "                    continue\n",
    "\n",
    "                cortical_neurons = np.nonzero(wneurons)[0]\n",
    "                for cn in cortical_neurons:\n",
    "                    cn_idxs = [i for i in range(len(clu)) if clu[i]==cn]\n",
    "                    # print(cn_idxs)\n",
    "                    population.append( sorted(st[cn_idxs]) )\n",
    "                    \n",
    "                area_spiketrains[ mouse_names[imouse] ][ b[2] ].append( population )\n",
    "            print()\n",
    "\n",
    "    # save to file\n",
    "    np.save(\"stringer/7739750/area_spiketrains.npy\", area_spiketrains)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001efe03-3e0a-4255-aa62-23639d33a6eb",
   "metadata": {},
   "source": [
    "The following spiketrains will be loaded.\n",
    "\n",
    "| mouse | probe | borders (um) | area | #neurons |\n",
    "|:----|:----|:----|:---|:---|\n",
    "| **Krebs** | 0 | 4000, 1100 | FrMoCtx | 5 |\n",
    "|           | 1 | 4000, 1800 | FrMoCtx | 73 |\n",
    "|           | 2 | 4000, 2600 | V1 | 61 |\n",
    "|           | 3 | 4000, 2400 | V1 | 141 |\n",
    "|           | 4 | 4000, 1800 | SomMoCtx | 65 |\n",
    "|           | 5 | 4000, 2100 | SomMoCtx | 26 |\n",
    "|           | 6 | 4000, 2350 | V1 | 68 |\n",
    "|           | 7 | 4000, 2600 | V1 | 64 |\n",
    "| **Waksman** | 0 | 4000, 1700 | FrMoCtx | 446 |\n",
    "|             | 0 | 1200, 0 | FrMoCtx | 201 |\n",
    "|             | 1 | 4000, 2150 | FrCtx | 31 |\n",
    "|             | 2 | 4000, 2700 | V1 | 155 |\n",
    "|             | 3 | 4000, 2250 | RSP | 112 |\n",
    "|             | 4 | 4000, 2000 | SomMoCtx | 220 |\n",
    "|             | 5 | 4000, 2600 | SSCtx | 50 |\n",
    "|             | 6 | 4000, 2650 | V2 | 124 |\n",
    "|             | 7 | 4000, 2850 | V1 | 96 |\n",
    "| **Robbins** | 0 | 4000, 3400 | FrMoCtx | 16 |\n",
    "|             | 1 | 4000, 3100 | FrMoCtx | 70 |\n",
    "|             | 3 | 4000, 3550 | RSP | 10 |\n",
    "|             | 4 | 4000, 3500 | SomMoCtx | 10 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f0754be-e291-4a07-9bda-2660756cdd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_frame_duration = 0.00000001 # sec (e.g. 4048.44929626 s)\n",
    "# frame_duration = 0.001 # sec (e.g. 4048.449 s)\n",
    "frame_duration = 0.01 # sec (e.g. 4048.45 s)\n",
    "local_path = os.getcwd() + '/stringer/7739750/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "278c2d9c-d9c9-4139-a39a-cb6d4e19a134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mouse: Krebs\n",
      "area:  FrMoCtx\n",
      "population: 0\n",
      "    population firing: 2.84±2.85 sp/frame\n",
      "    cells firing rate: 0.04±0.20 sp/s\n",
      "... generating surrogates to establish population event threshold\n",
      "... loaded surrogates\n",
      "    event size threshold (mean): 3.4416623623776474\n",
      "... find peaks\n",
      "... find minima\n",
      "... find population events\n",
      "... processing behavioral data\n",
      "    interval 0.05\n",
      "    pre 0.015 (149/9718)\n",
      "    post 0.170 (1656/9718)\n",
      "    interval 0.1\n",
      "    pre 0.074 (723/9718)\n",
      "    post 0.218 (2120/9718)\n",
      "    interval 0.15\n",
      "    pre 0.132 (1281/9718)\n",
      "    post 0.268 (2606/9718)\n",
      "    interval 0.2\n",
      "    pre 0.193 (1874/9718)\n",
      "    post 0.321 (3118/9718)\n",
      "    interval 0.25\n",
      "    pre 0.244 (2371/9718)\n",
      "    post 0.369 (3582/9718)\n",
      "    interval 0.3\n",
      "    pre 0.297 (2890/9718)\n",
      "    post 0.414 (4028/9718)\n",
      "... signatures of population events\n",
      "    number of events: 9718\n",
      "    number of events per sec: 1.9043091510108536\n",
      "    events duration: 0.100±0.040\n",
      "    events size: 19.000±6.483\n",
      "... Similarity of events matrix\n",
      "... clustering\n",
      "    linkage\n",
      "    surrogate events signatures for clustering threshold\n",
      "... loaded surrogates\n",
      "    cluster reproducibility threshold: 0.19066564490349733\n",
      "    cluster size threshold: 2\n",
      "    Total number of clusters: 250\n",
      "    # clusters (after removing those below reproducibility threshold): 249\n",
      "... finding cluster cores\n",
      "    removing cores firing unspecifically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/npyio.py:528: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    gathering cores from all clusters\n",
      "    # cores: 70\n",
      "    # non-cores: 3\n",
      "    cores per cluster: 18.45±5.11 (min 0, max 36)\n",
      "    others per cluster: 54.55±5.11 (min 37, max 73)\n",
      "... Starting attractor analysis\n",
      "    coloring frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finding trajectories\n",
      "    trajectories lengths: 21.48±19.84 (median:14.00)\n",
      "... performing dimensionality reduction of the state space (using PCA)\n",
      "129215 3342\n",
      "0 (0.8274509803921568, 0.8274509803921568, 0.8274509803921568, 0.01)\n",
      "(2, 8)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_142/3121702915.py:74\u001b[0m, in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(iline,cline)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(elines[iline])\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;241;43m0\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m             fig\u001b[38;5;241m.\u001b[39mclf()\n\u001b[1;32m    104\u001b[0m             \u001b[38;5;66;03m# dimensional reduction, trajectories, and manifold checking\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m             \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattractor_analysis.ipynb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;66;03m# structural analysis\u001b[39;00m\n\u001b[1;32m    108\u001b[0m             \u001b[38;5;66;03m# # make binary spiketrains\u001b[39;00m\n\u001b[1;32m    109\u001b[0m             \u001b[38;5;66;03m# binary_spiketrains = np.zeros( (len(scan),len(time)+2) )\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;66;03m# np.save(exp_path+\"/results/functional_adjacency_matrix_%d.npy\"%scan_id, functional_adjacency_matrix)\u001b[39;00m\n\u001b[1;32m    129\u001b[0m             \u001b[38;5;66;03m# global_functional_adjacency_matrix[scan_id] = np.array(functional_adjacency_matrix)\u001b[39;00m\n\u001b[1;32m    132\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2305\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2303\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2305\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/magics/execution.py:717\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m preserve_keys(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_execfile_ipy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m# Control the response to exit() calls made by the script being run\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2811\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile_ipy\u001b[0;34m(self, fname, shell_futures, raise_exceptions)\u001b[0m\n\u001b[1;32m   2809\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_cell(cell, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shell_futures\u001b[38;5;241m=\u001b[39mshell_futures)\n\u001b[1;32m   2810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_exceptions:\n\u001b[0;32m-> 2811\u001b[0m     \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2812\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39msuccess:\n\u001b[1;32m   2813\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:251\u001b[0m, in \u001b[0;36mExecutionResult.raise_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_before_exec\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_in_exec\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/tmp/ipykernel_142/3121702915.py:74\u001b[0m, in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(iline,cline)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(elines[iline])\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;241;43m0\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# start of spontaneous activity in each mouse (in seconds)\n",
    "etstart = [3811, 3633, 3323]\n",
    "\n",
    "for imouse,(mousename,areas) in enumerate(area_spiketrains.items()):\n",
    "    print(\"\\nmouse:\",mousename)\n",
    "    \n",
    "    exp_path = local_path + '%s/'%mousename\n",
    "    exp_tstart = etstart[imouse]\n",
    "\n",
    "    # reading behavior data to make statistics about event dependence on it\n",
    "    # we will use the field 'stimulus' to store the avg motSVD of the frames \n",
    "    # The behavioral file is the processed version of a mouse face movie (time x pixels x pixels). \n",
    "    faces = sio.loadmat('stringer/7739750/faces/%s_face_proc.mat'%mousename, squeeze_me=True)\n",
    "    video_timestamps = faces['times'] # same temporal resolution of ephy\n",
    "    motSVD = faces['motionSVD']\n",
    "    exp_istart = (np.abs(video_timestamps - exp_tstart)).argmin()    \n",
    "    motSVD_1c = motSVD[:,0] # only first component\n",
    "    motSVD_1c[motSVD_1c < -4000] = np.mean(motSVD_1c) # corrections\n",
    "    fig, ax = plt.subplots(figsize=(20,5))\n",
    "    ax.plot(video_timestamps[exp_istart:], motSVD_1c[exp_istart:], linewidth=0.5, color='k')\n",
    "    fig.savefig(exp_path+\"/motSVD_%s.png\"%mousename, transparent=True, dpi=900)\n",
    "    plt.close()\n",
    "    fig.clear()\n",
    "    fig.clf()\n",
    "\n",
    "    for area,probe_populations in areas.items():\n",
    "        if len(probe_populations)>0:\n",
    "            print(\"area: \",area)\n",
    "                        \n",
    "            for ipop,spiketrains in enumerate(probe_populations): \n",
    "                print(\"population:\",ipop)\n",
    "\n",
    "                # rounding to ms\n",
    "                spiketrains = [np.round(sp, 3) for sp in spiketrains]\n",
    "                start_time = min([min(st) for st in spiketrains])\n",
    "                stop_time = max([max(st) for st in spiketrains])\n",
    "                time = np.arange(start_time,stop_time,frame_duration)\n",
    "\n",
    "                fig = plt.figure(figsize=[12.8,4.8])\n",
    "                for row,train in enumerate(spiketrains):\n",
    "                    plt.scatter( train, [row]*len(train), marker='o', edgecolors='none', s=1, c='k' )\n",
    "                plt.ylabel(\"cell IDs\")\n",
    "                plt.xlabel(\"time (s)\")\n",
    "                # plt.show()\n",
    "                fig.savefig(exp_path+'%s_%s_rasterplot.png'%(area,ipop), transparent=False, dpi=800)\n",
    "                plt.tight_layout()\n",
    "                plt.close()\n",
    "\n",
    "                ophys_cell_ids = list(range(len(spiketrains)))\n",
    "                ophys_cell_indexes = ophys_cell_ids # here is an alias\n",
    "\n",
    "                core_reproducibility_perc = 95 # % threshold for detecting cores\n",
    "                scan_spiketrains = spiketrains\n",
    "                scan_id = '_%s_%s'%(area,ipop)\n",
    "                \n",
    "                core_reproducibility_perc = 60 # threshold for detecting cores\n",
    "                %run \"dynamical_analysis.ipynb\"\n",
    "                \n",
    "                # Match smooth motion energy curve with the cluster it belongs to\n",
    "                # Count the number of events belonging to a pattern before and after the change.\n",
    "                ccolors,ccounts = np.unique(cluster_color_array, return_counts=True)\n",
    "                cluster_events_counts = dict(zip(ccolors,ccounts))\n",
    "                Npre_beh_cluster = {el:0. for el in np.unique(cluster_color_array)}\n",
    "                Npost_beh_cluster = {el:0. for el in np.unique(cluster_color_array)}\n",
    "                for sni in smoothed_beh_indices:\n",
    "                    snitime = exp_tstart + sni * frame_duration\n",
    "                    snitime_pre = snitime - 0.15 # s\n",
    "                    snitime_post = snitime + 0.15 # s\n",
    "                    for ievent,(event,ecolor) in enumerate(zip(events,cluster_color_array)):\n",
    "                        event_start_time = exp_tstart + event['start'] * frame_duration\n",
    "                        if snitime_pre < event_start_time and event_start_time < snitime:\n",
    "                            Npre_beh_cluster[ecolor] += 1\n",
    "                        if snitime < event_start_time and event_start_time < snitime_post:\n",
    "                            Npost_beh_cluster[ecolor] += 1\n",
    "                # detail\n",
    "                fig = plt.figure()\n",
    "                plt.scatter(range(len(Npre_beh_cluster.keys())), Npre_beh_cluster.values(), marker='<', c=list(Npre_beh_cluster.keys()), edgecolors=list(Npre_beh_cluster.keys()), s=1)\n",
    "                plt.scatter(range(len(Npost_beh_cluster.keys())), Npost_beh_cluster.values(), marker='>', c=list(Npost_beh_cluster.keys()), edgecolors='none', s=1)\n",
    "                plt.vlines(range(len(Npost_beh_cluster.keys())), Npost_beh_cluster.values(), Npre_beh_cluster.values(), colors=list(Npost_beh_cluster.keys()), linewidths=0.6)\n",
    "                plt.ylabel('occurrence')\n",
    "                plt.xlabel('Patterns')\n",
    "                fig.savefig(exp_path+\"/results/Pattern_behavior_%s_%s%s.png\"%(mousename,area,ipop), transparent=True, dpi=600)\n",
    "                plt.close()\n",
    "                fig.clear()\n",
    "                fig.clf()\n",
    "                # summary\n",
    "                Nsame = 0\n",
    "                Npost = 0\n",
    "                Npre = 0\n",
    "                for pre,post in zip(Npre_beh_cluster.values(),Npost_beh_cluster.values()):\n",
    "                    if pre==post: Nsame +=1\n",
    "                    if pre>post: Npre +=1\n",
    "                    if pre<post: Npost +=1\n",
    "                fig = plt.figure()\n",
    "                plt.bar([0,1,2], [Npre,Nsame,Npost], width=0.8, color='C0')\n",
    "                plt.ylabel('occurrences')\n",
    "                plt.xlabel('pattern timing relative to movement')\n",
    "                plt.xticks(range(3),['before','same','after'])\n",
    "                fig.savefig(exp_path+\"/results/Pattern_behavior_summary_%s_%s%s.png\"%(mousename,area,ipop), transparent=True, dpi=600)\n",
    "                plt.close()\n",
    "                fig.clear()\n",
    "                fig.clf()\n",
    "                \n",
    "                # dimensional reduction, trajectories, and manifold checking\n",
    "                %run \"attractor_analysis.ipynb\"\n",
    "                \n",
    "                # structural analysis\n",
    "                # # make binary spiketrains\n",
    "                # binary_spiketrains = np.zeros( (len(scan),len(time)+2) )\n",
    "                # # print(binary_spiketrains.shape)\n",
    "\n",
    "                # for row,train in enumerate(scan):\n",
    "                #     # iterate over spiketrains assigning 1 to the binary_spiketrains at the corresponding position\n",
    "                #     tidxs = np.trunc(np.array(train)/frame_duration).astype(int)\n",
    "                #     tidxs[tidxs>len(time)] = len(time) \n",
    "                #     binary_spiketrains[row][tidxs] = 1\n",
    "\n",
    "                # functional_adjacency_matrix = []\n",
    "                # for irow,bsti in enumerate(binary_spiketrains):\n",
    "                #     row_xcorr = []\n",
    "                #     for jrow,bstj in enumerate(binary_spiketrains):\n",
    "                #         if irow==jrow:\n",
    "                #             row_xcorr.append(0.0) # no self connections\n",
    "                #             continue\n",
    "                #         row_xcorr.append(crosscorrelation(bsti, bstj, maxlag=1, mode='corr')[2])\n",
    "                #     functional_adjacency_matrix.append(row_xcorr)\n",
    "                # functional_adjacency_matrix = np.array(functional_adjacency_matrix)\n",
    "                # np.save(exp_path+\"/results/functional_adjacency_matrix_%d.npy\"%scan_id, functional_adjacency_matrix)\n",
    "                # global_functional_adjacency_matrix[scan_id] = np.array(functional_adjacency_matrix)\n",
    "\n",
    "\n",
    "    gc.collect()\n",
    "    print()\n",
    "    \n",
    "    0/0 # using only 'Krebs' mouse to save execution time.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df7b3e-1e8f-433b-8d6a-74ab074db700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
