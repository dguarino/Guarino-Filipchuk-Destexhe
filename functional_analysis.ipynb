{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1422c776-2bb0-41a4-ad54-1fcb2bc13fd7",
   "metadata": {},
   "source": [
    "## Functional analysis\n",
    "\n",
    "**NOTE: This ipynb can only be embedded in others.**\n",
    "\n",
    "We start by making all spiketrains of the the same length and binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a34b9-acf7-4954-89c5-68e9bbfbd9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structural analysis\n",
    "print(\"... Functional correlation analysis (functional structure)\")\n",
    "\n",
    "# make binary spiketrains\n",
    "print(\"    binary spiketrains\")\n",
    "binary_spiketrains = np.zeros( (len(spiketrains),len(time)+2) )\n",
    "print(\"    shape:\", binary_spiketrains.shape)\n",
    "for row,train in enumerate(spiketrains):\n",
    "    # iterate over spiketrains assigning 1 to the binary_spiketrains at the corresponding position\n",
    "    tidxs = np.trunc(np.array(train)/frame_duration).astype(int) - int(exp_tstart/frame_duration)\n",
    "    tidxs[tidxs>len(time)] = len(time) \n",
    "    binary_spiketrains[row][tidxs] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc948467-b185-4e6b-bb0a-61db45567b3b",
   "metadata": {},
   "source": [
    "Then we build an adjacency matrix based on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f0359a-9120-42a2-b18c-7f315a1655af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"    starting functional adjacency matrix\")\n",
    "functional_adjacency_matrix = []\n",
    "for irow,bsti in enumerate(binary_spiketrains):\n",
    "    row_xcorr = []\n",
    "    for jrow,bstj in enumerate(binary_spiketrains):\n",
    "        if irow==jrow:\n",
    "            row_xcorr.append(0.0) # no self connections\n",
    "            continue\n",
    "        row_xcorr.append(crosscorrelation(bsti, bstj, maxlag=1, mode='corr')[2])\n",
    "    functional_adjacency_matrix.append(row_xcorr)\n",
    "functional_adjacency_matrix = np.array(functional_adjacency_matrix)\n",
    "print(\"    full adjacency matrix:\",functional_adjacency_matrix.shape)\n",
    "\n",
    "# To ensure sparseness of the matrix, discard weak correlations (<0.4, Sadovsky and MacLean 2013)\n",
    "functional_adjacency_matrix[ functional_adjacency_matrix <= functional_adjacency_matrix.max()*perc_corr ] = 0.0\n",
    "np.save(exp_path+\"/results/functional_adjacency_matrix_%s.npy\"%(scan_id), functional_adjacency_matrix)\n",
    "\n",
    "# plot\n",
    "fig = plt.figure()\n",
    "plt.pcolormesh(functional_adjacency_matrix)\n",
    "cbar = plt.colorbar()\n",
    "fig.savefig(exp_path+'/results/adjacency_matrix_%s.png'%(scan_id), transparent=True)\n",
    "plt.close()\n",
    "fig.clear()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb0524-ee2d-409f-9a29-dcce0233a96e",
   "metadata": {},
   "source": [
    "### is the cross-correlation between cells significant to justify a functional connectivity analysis?\n",
    "Before performing functional connectivity let's check that the correlogram of the best correlated cells is beyond their shuffled surrogates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd7675-8eb7-454f-bb8b-10ddc12ffcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"    checking details of best cross-correlation pairs \")\n",
    "# pick highly correlated cells for further inspection\n",
    "# thresholds for the top and bottom percentiles\n",
    "top_threshold = np.percentile(functional_adjacency_matrix, 95)\n",
    "highly_correlated_indices = np.where(functional_adjacency_matrix > top_threshold)\n",
    "\n",
    "bin_size = 1 # can be made lower\n",
    "lags = np.arange(-50, 51, bin_size)\n",
    "num_pairs = 30 if len(highly_correlated_indices[0])>30 else len(highly_correlated_indices[0])-1\n",
    "co_occurrence_counts = []\n",
    "surrogates_co_occurrence_counts = []\n",
    "for i in range(num_pairs):\n",
    "    spike_times1 = binary_spiketrains[highly_correlated_indices[0][i]].astype(int)\n",
    "    spike_times2 = binary_spiketrains[highly_correlated_indices[1][i]].astype(int)\n",
    "    co_occurrence_counts_per_lag = np.convolve(spike_times1, spike_times2[::-1], mode='same')\n",
    "    co_occurrence_counts.append(co_occurrence_counts_per_lag)\n",
    "    # geenrate surrogates by reshuffling\n",
    "    surrogates_co_occurrences = []\n",
    "    for j in range(10):\n",
    "        surrspike_times1 = np.random.permutation(spike_times1)\n",
    "        surrspike_times2 = np.random.permutation(spike_times2)\n",
    "        co_occurrence_counts_per_lag = np.convolve(surrspike_times1, surrspike_times2[::-1], mode='same')\n",
    "        surrogates_co_occurrences.append(co_occurrence_counts_per_lag)\n",
    "    surrogates_co_occurrence_counts.append(np.mean(surrogates_co_occurrences, axis=0))   \n",
    "    \n",
    "# grid of individual cross-correlations\n",
    "num_plots = len(co_occurrence_counts)\n",
    "num_rows = int(np.sqrt(num_plots))\n",
    "num_cols = int(np.ceil(num_plots / num_rows))\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "for i, co_occurrence_counts_pair in enumerate(co_occurrence_counts):\n",
    "    plt.subplot(num_rows, num_cols, i+1)\n",
    "    plt.plot(lags, co_occurrence_counts_pair[:len(lags)], color='blue')\n",
    "    plt.plot(lags, surrogates_co_occurrence_counts[i][:len(lags)], color='red', linestyle='dashed')\n",
    "fig.text(0.5, 0.04, 'Lag (ms)', ha='center')\n",
    "fig.text(0.04, 0.5, 'Correlation', va='center', rotation='vertical')\n",
    "plt.tight_layout()\n",
    "fig.savefig(exp_path+'/results/correlogram_%s.svg'%(scan_id), transparent=True)\n",
    "plt.close()\n",
    "fig.clear()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34e659-d2c2-4a7f-aea4-467bcfee87e6",
   "metadata": {},
   "source": [
    "### creating the graph\n",
    "\n",
    "Creating graph from functional_adjacency_matrix as in Sadovsky and MacLean 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaec81b-8461-44cc-bab6-4bd8a46cf42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional_adjacency_matrix[ functional_adjacency_matrix <= functional_adjacency_matrix.max()*perc_corr ] = 0.0\n",
    "functional_adjacency_matrix[ functional_adjacency_matrix >= functional_adjacency_matrix.max()*perc_corr ] = 1.0\n",
    "\n",
    "dgraph = ig.Graph.Weighted_Adjacency(functional_adjacency_matrix, mode='directed')\n",
    "ig.plot(dgraph, exp_path+'/results/ring_%s.png'%(scan_id), layout=dgraph.layout(\"circle\"), edge_curved=0.2, edge_color='#000', edge_width=0.5, edge_arrow_size=0.1, vertex_size=5, vertex_color='#000', margin=50)\n",
    "print('    preparing vertex labels for cores and others')\n",
    "dgraph.vs[\"ophys_cell_id\"] = ophys_cell_ids\n",
    "is_id_core = np.array( [0] * len(ophys_cell_ids) )\n",
    "is_id_core[core_indexes] = 1\n",
    "dgraph.vs[\"is_core\"] = is_id_core.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda8758-43c9-439d-b905-e5d08a03bda8",
   "metadata": {},
   "source": [
    "### Modularity\n",
    "\n",
    "The relationship between degree and local clustering coefficient of nodes should be log-linear to have a modular network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6e8e2d-ec05-4a07-a085-1bae36ce244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.array(dgraph.degree())\n",
    "print(\"    Degree distributions\")\n",
    "# https://igraph.org/python/api/latest/igraph._igraph.GraphBase.html#degree\n",
    "degdist = dgraph.degree_distribution(bin_width=5)\n",
    "degree_counts = [bi[2] for bi in degdist.bins()]\n",
    "fig = plt.figure()\n",
    "plt.plot(range(len(degree_counts)), degree_counts, linewidth=3.0)\n",
    "plt.ylabel('Number of vertices')\n",
    "plt.xlabel('Degree')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.savefig(exp_path+'/results/degree_distribution_%s.png'%(scan_id), transparent=True, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Clustering Coefficient of only excitatory cells\n",
    "print('    Local Clustering Coefficient (cores too)')\n",
    "local_clustering_coefficients = np.array(dgraph.transitivity_local_undirected(vertices=None, mode=\"zero\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b29213-243f-43a6-b79f-8e2d7f01a1c7",
   "metadata": {},
   "source": [
    "### Cores are the connectors between modules\n",
    "\n",
    "High information flow nodes often arise from modular networks, characterized by a log-linear relationship between local clustering coefficient and degree. In particular, high information flow nodes have low cluster coefficient, acting as connectors between modules.\n",
    "\n",
    "Here, on the left, we color the core units while displaying them over the hierarchical modularity plot.      \n",
    "On the right, we plot the cores local clustering histogram on a linear scale, to appreciate their distribution skewed towards low values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a103d8a-3035-4331-b6fb-939eae6c7861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign cores to their lcc and degree\n",
    "# print(core_indexes)\n",
    "core_local_clustering_coefficients = np.array(dgraph.transitivity_local_undirected(vertices=core_indexes, mode=\"zero\"))\n",
    "core_degrees = np.array(dgraph.degree(vertices=core_indexes, mode=\"all\"))\n",
    "\n",
    "# figure\n",
    "fig, (hmmap, chist) = plt.subplots(1, 2, gridspec_kw={'width_ratios': [6, 1]})\n",
    "# hierarchy\n",
    "hmmap.scatter( degrees, local_clustering_coefficients, marker='o', facecolor='#111111', s=50, edgecolors='none', alpha=0.5) \n",
    "hmmap.scatter( core_degrees, core_local_clustering_coefficients, marker='o', facecolor='none', s=50, edgecolors='forestgreen') \n",
    "hmmap.set_yscale('log')\n",
    "hmmap.set_ylim([0.02,1.1])\n",
    "hmmap.set_xscale('log')\n",
    "hmmap.spines['top'].set_visible(False)\n",
    "hmmap.spines['right'].set_visible(False)\n",
    "hmmap.set_ylabel('LCC')\n",
    "hmmap.set_xlabel('degree')\n",
    "hmmap.tick_params(axis='both', bottom='on', top='on', left='off', right='off')\n",
    "# core lcc histogram\n",
    "bins = np.linspace(0.02,1,50)\n",
    "barheight = (max(local_clustering_coefficients)-min(local_clustering_coefficients))/50\n",
    "lcc_hist, lcc_binedges = np.histogram(core_local_clustering_coefficients, bins)\n",
    "chist.barh(bins[:-1], lcc_hist, height=barheight, align='center', color='green', linewidth=0)\n",
    "chist.spines['top'].set_visible(False)\n",
    "chist.spines['right'].set_visible(False)\n",
    "chist.tick_params(axis='x', which='both', bottom=True, top=False, labelsize='x-small')\n",
    "chist.tick_params(axis='y', which='both', left=True, right=False, labelleft=True)\n",
    "chist_ticks = chist.get_xticks()\n",
    "chist.set_ylim([0.01,1.1])\n",
    "chist.set_ylabel('LCC')\n",
    "chist.set_xlabel('count')\n",
    "chist.yaxis.set_label_position(\"right\")\n",
    "chist.spines['top'].set_visible(False)\n",
    "chist.spines['right'].set_visible(False)\n",
    "chist.spines['bottom'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "fig.savefig(exp_path+\"/results/cores_hierarchical_modularity_%s.svg\"%(scan_id), transparent=True)\n",
    "plt.close()\n",
    "fig.clear()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541d30e-678f-4341-a749-12227c70cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flow analysis\n",
    "print(\"... Flow Analysis\")\n",
    "\n",
    "if len(core_indexes)>1 and len(other_indexes)>1:\n",
    "    # The amount of flow on an edge cannot exceed the capacity of the edge.\n",
    "    # therefore, edges with high capacity will be more important for the flow.\n",
    "    # here we test the hypothesis that edges towards cores have higher capacity\n",
    "    # or that the sum of edges towards cores have a higher total capacity\n",
    "    cell_total_capacity = {cid:list() for cid in ophys_cell_ids}\n",
    "    edges_sourcing = {cid:0 for cid in ophys_cell_ids}\n",
    "    edges_targeting = {cid:0 for cid in ophys_cell_ids}\n",
    "\n",
    "    for cluster_k,events_cellids in scan_clustered_spectrums.items(): # we consider only the scan 0 because it's the largest (for now)\n",
    "        cluster_k = cluster_k.split(',')[0]\n",
    "\n",
    "        if cluster_k == 'gray':\n",
    "            continue\n",
    "\n",
    "        for vnt in events_cellids:\n",
    "            for posi,vidj in enumerate(vnt[1:]):\n",
    "                vidi = vnt[posi] # enumerate will go from 0\n",
    "                # print(vidi, vidj)\n",
    "\n",
    "                # check beginning and end are not the same\n",
    "                if dgraph.vs.find(ophys_cell_id=vidi).index == dgraph.vs.find(ophys_cell_id=vidj).index:\n",
    "                    continue\n",
    "                # # check there is a path between the two\n",
    "                # if len(spinesgraph.get_all_shortest_paths(spinesgraph.vs.find(name=vidi).index, to=spinesgraph.vs.find(name=vidj).index, weights=None, mode='out'))>0:\n",
    "                #     continue\n",
    "\n",
    "                # Take the maximum flow between the previous and next vertices\n",
    "                mfres = dgraph.maxflow(dgraph.vs.find(ophys_cell_id=vidi).index, dgraph.vs.find(ophys_cell_id=vidj).index)\n",
    "                # print(mfres)\n",
    "                # returns a tuple containing the following:\n",
    "                # graph - the graph on which this flow is defined\n",
    "                # value - the value (capacity) of the maximum flow between the given vertices\n",
    "                # flow - the flow values on each edge. For directed graphs, this is simply a list where element i corresponds to the flow on edge i.\n",
    "                # cut - edge IDs in the minimal cut corresponding to the flow.\n",
    "                # partition - vertex IDs in the parts created after removing edges in the cut\n",
    "                # es - an edge selector restricted to the edges in the cut.\n",
    "\n",
    "                # we get a flow value for each edge contributing to the flow.\n",
    "                # source\n",
    "                mfres_value = mfres.value\n",
    "                if vidi in np.array(ophys_cell_ids)[core_indexes]:\n",
    "                    mfres_value /= len(core_indexes)\n",
    "                else:\n",
    "                    mfres_value /= len(other_indexes)\n",
    "                cell_total_capacity[vidi].append(mfres_value)\n",
    "                # target\n",
    "                mfres_value = mfres.value\n",
    "                if vidj in np.array(ophys_cell_ids)[core_indexes]:\n",
    "                    mfres_value /= len(core_indexes)\n",
    "                else:\n",
    "                    mfres_value /= len(other_indexes)\n",
    "                cell_total_capacity[vidj].append(mfres_value)\n",
    "\n",
    "                # Iterate over the edges identified by the flow.\n",
    "                # count the edges sourcing from cores, and those targeting cores. Which is more?\n",
    "                for edge in mfres.es:\n",
    "                    sourceid = int(dgraph.vs[edge.source]['ophys_cell_id'])\n",
    "                    targetid = int(dgraph.vs[edge.target]['ophys_cell_id'])\n",
    "                    if sourceid in cell_total_capacity.keys():\n",
    "                        edges_sourcing[sourceid] +=1 # just count\n",
    "                    if targetid in cell_total_capacity.keys():\n",
    "                        edges_targeting[targetid] +=1 # just count\n",
    "\n",
    "    # # Flow\n",
    "    # # print(cell_total_capacity)\n",
    "    # flowvalue_cores = []\n",
    "    # for cid in np.array(ophys_cell_ids)[core_indexes]:\n",
    "    #     flowvalue_cores.extend(cell_total_capacity[cid])\n",
    "    # flowvalue_others = []\n",
    "    # for cid in np.array(ophys_cell_ids)[other_indexes]:\n",
    "    #     flowvalue_others.extend(cell_total_capacity[cid])\n",
    "    # # description\n",
    "    # print(\"    Flow cores: \"+str(stats.describe(flowvalue_cores)) )\n",
    "    # print(\"    Flow others: \"+str(stats.describe(flowvalue_others)) )\n",
    "    # # significativity\n",
    "    # print(\"    Welch t test:  %.3f p= %.3f\" % stats.ttest_ind(flowvalue_cores, flowvalue_others, equal_var=False))\n",
    "    # d,_ = stats.ks_2samp(flowvalue_cores, flowvalue_others) # non-parametric measure of effect size [0,1]\n",
    "    # print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "    # fig, ax = plt.subplots()\n",
    "    # xs = np.random.normal(1, 0.04, len(flowvalue_cores))\n",
    "    # plt.scatter(xs, flowvalue_cores, alpha=0.3, c='forestgreen')\n",
    "    # xs = np.random.normal(2, 0.04, len(flowvalue_others))\n",
    "    # plt.scatter(xs, flowvalue_others, alpha=0.3, c='silver')\n",
    "    # vp = ax.violinplot([flowvalue_cores,flowvalue_others], widths=0.15, showextrema=False, showmeans=True)\n",
    "    # for pc in vp['bodies']:\n",
    "    #     pc.set_edgecolor('black')\n",
    "    # for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    #     pc.set_facecolor(cb)\n",
    "    # vp['cmeans'].set_color('orange')\n",
    "    # # vp['cmedians'].set_linewidth(2.)\n",
    "    # ax.spines['top'].set_visible(False)\n",
    "    # ax.spines['bottom'].set_visible(False)\n",
    "    # ax.spines['left'].set_visible(False)\n",
    "    # ax.spines['right'].set_visible(False)\n",
    "    # plt.ylabel('Normalized flow value')\n",
    "    # plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(flowvalue_cores)), \"other\\n(n={:d})\".format(len(flowvalue_others))])\n",
    "    # fig.savefig(exp_path+\"/results/global_cores_others_flowvalue_%s.svg\"%(scan_id), transparent=True)\n",
    "    # plt.show()\n",
    "    # # fig.clf()\n",
    "    # # plt.close()\n",
    "\n",
    "    # Cuts\n",
    "    # print(edges_sourcing)\n",
    "    # print(edges_targeting)\n",
    "    flowcuts_core_sources = []\n",
    "    flowcuts_core_targets = []\n",
    "    for cid in np.array(ophys_cell_ids)[core_indexes]:\n",
    "        flowcuts_core_sources.append(edges_sourcing[cid]/len(core_indexes))\n",
    "        flowcuts_core_targets.append(edges_targeting[cid]/len(core_indexes))\n",
    "    flowcuts_other_sources = []\n",
    "    flowcuts_other_targets = []\n",
    "    for cid in np.array(ophys_cell_ids)[other_indexes]:\n",
    "        flowcuts_other_sources.append(edges_sourcing[cid]/len(other_indexes))\n",
    "        flowcuts_other_targets.append(edges_targeting[cid]/len(other_indexes))\n",
    "\n",
    "    # description\n",
    "    print(\"    Cut edges sourcing from cores: \"+str(stats.describe(flowcuts_core_sources)) )\n",
    "    print(\"    Cut edges targeting cores: \"+str(stats.describe(flowcuts_core_targets)) )\n",
    "    print(\"    Cut edges sourcing from others: \"+str(stats.describe(flowcuts_other_sources)) )\n",
    "    print(\"    Cut edges targeting others: \"+str(stats.describe(flowcuts_other_targets)) )\n",
    "    # significativity\n",
    "    print(\"    Core targets vs sources Welch t test:  %.3f p= %.3f\" % stats.ttest_ind(flowcuts_core_targets, flowcuts_core_sources, equal_var=False))\n",
    "    d,_ = stats.ks_2samp(flowcuts_core_targets, flowcuts_core_sources) # non-parametric measure of effect size [0,1]\n",
    "    print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "    print(\"    Core targets vs Other targets Welch t test:  %.3f p= %.3f\" % stats.ttest_ind(flowcuts_core_targets, flowcuts_other_targets, equal_var=False))\n",
    "    d,_ = stats.ks_2samp(flowcuts_core_targets, flowcuts_other_targets) # non-parametric measure of effect size [0,1]\n",
    "    print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    xs = np.random.normal(1, 0.04, len(flowcuts_core_sources))\n",
    "    plt.scatter(xs, flowcuts_core_sources, alpha=0.3, c='forestgreen')\n",
    "    xs = np.random.normal(2, 0.04, len(flowcuts_core_targets))\n",
    "    plt.scatter(xs, flowcuts_core_targets, alpha=0.3, c='forestgreen')\n",
    "    xs = np.random.normal(3, 0.04, len(flowcuts_other_sources))\n",
    "    plt.scatter(xs, flowcuts_other_sources, alpha=0.3, c='silver')\n",
    "    xs = np.random.normal(4, 0.04, len(flowcuts_other_targets))\n",
    "    plt.scatter(xs, flowcuts_other_targets, alpha=0.3, c='silver')\n",
    "    vp = ax.violinplot([flowcuts_core_sources,flowcuts_core_targets,flowcuts_other_sources,flowcuts_other_targets], widths=0.15, showextrema=False, showmeans=True)\n",
    "    for pc in vp['bodies']:\n",
    "        pc.set_edgecolor('black')\n",
    "    for pc in vp['bodies'][0:2]:\n",
    "        pc.set_facecolor('#228B224d')\n",
    "    for pc in vp['bodies'][2:]:\n",
    "        pc.set_facecolor('#D3D3D34d')\n",
    "    vp['cmeans'].set_color('orange')\n",
    "    # vp['cmedians'].set_linewidth(2.)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.ylabel('Normalized edges in the cut')\n",
    "    plt.xticks([1, 2, 3, 4], [\"core as\\nsource\", \"core as\\ntarget\", \"other as\\nsource\", \"other as\\ntarget\"])\n",
    "    fig.savefig(exp_path+\"/results/global_cores_others_cutvalue_%s.svg\"%(scan_id), transparent=True)\n",
    "    plt.show()\n",
    "    # fig.clf()\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1ecefa-74d7-4220-80f1-8be0b9f46759",
   "metadata": {},
   "source": [
    "### PageRank\n",
    "\n",
    "If a network has high flow nodes, they will also score high in the [PageRank algorithm](https://en.wikipedia.org/wiki/PageRank).    \n",
    "Core neurons having both high flow values and high cut values should have a higher pagerank value than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8d8c6-932e-41a4-a17c-cfbf44ed8d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('... PageRank centrality')\n",
    "pagerank_cores = []\n",
    "pagerank_others = []\n",
    "\n",
    "if len(core_indexes)>1:\n",
    "    pagerank_cores = np.array(dgraph.personalized_pagerank(vertices=core_indexes, directed=True, damping=0.85, reset=\"is_core\"))\n",
    "if len(other_indexes)>1:\n",
    "    pagerank_others = np.array(dgraph.personalized_pagerank(vertices=other_indexes, directed=True, damping=0.85, reset=\"is_core\"))\n",
    "    \n",
    "if len(core_indexes)>1 and len(other_indexes)>1:\n",
    "    \n",
    "    # description\n",
    "    print(\"    cores: \"+str(stats.describe(pagerank_cores)) )\n",
    "    print(\"    others: \"+str(stats.describe(pagerank_others)) )\n",
    "    # significativity\n",
    "    print(\"    Kruskal-Wallis test:  %.3f p= %.3f\" % stats.kruskal(pagerank_cores, pagerank_others))\n",
    "    d,_ = stats.ks_2samp(pagerank_cores, pagerank_others) # non-parametric measure of effect size [0,1]\n",
    "    print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    xs = np.random.normal(1, 0.04, len(pagerank_cores))\n",
    "    plt.scatter(xs, pagerank_cores, alpha=0.3, c='forestgreen')\n",
    "    xs = np.random.normal(2, 0.04, len(pagerank_others))\n",
    "    plt.scatter(xs, pagerank_others, alpha=0.3, c='silver')\n",
    "    vp = ax.violinplot([pagerank_cores,pagerank_others], widths=0.15, showextrema=False, showmedians=True)\n",
    "    for pc in vp['bodies']:\n",
    "        pc.set_edgecolor('black')\n",
    "    for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "        pc.set_facecolor(cb)\n",
    "    vp['cmedians'].set_color('orange')\n",
    "    vp['cmedians'].set_linewidth(2.)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.ylabel('PageRank')\n",
    "    plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(pagerank_cores)), \"other\\n(n={:d})\".format(len(pagerank_others))])\n",
    "    fig.savefig(exp_path+\"/results/global_cores_others_pagerank_%s.svg\"%(scan_id), transparent=True)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
