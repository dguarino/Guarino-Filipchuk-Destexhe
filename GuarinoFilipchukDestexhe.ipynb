{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How-to: core neurons are crossroads of cortical dynamics \n",
    "\n",
    "Analysis code to reproduce all panels in figures 1 and 2 of the paper by Guarino, Filipchuk, Destexhe (2022)   \n",
    "preprint link: https://www.biorxiv.org/content/10.1101/2022.05.24.493230v2\n",
    "\n",
    "All this code is hosted on a github [repository](https://github.com/dguarino/Guarino-Filipchuk-Destexhe) (with a Zenodo DOI persistent identifier [here](https://zenodo.org)) and can be interactively executed here [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/dguarino/Guarino-Filipchuk-Destexhe/HEAD?urlpath=Lab).  \n",
    "The repository also contains a copy of the required data files from the [MICrONS project phase1](https://www.microns-explorer.org/phase1) (freely available on the project website), to ease the setup on Binder. \n",
    "\n",
    "This notebook performs loading and selection of the MICrONS data, structural and dynamical analyses, and plots the results as in the paper panels.\n",
    "\n",
    "We divided the analysis code into:\n",
    "- `imports_functions.py` : performs the imports and definition of various helper functions.\n",
    "- `structural_analysis.py` : creates a graph from the connectivity matrix and computes several graph measures (using [igraph](https://igraph.org)).\n",
    "- `dynamical_analysis.py` : performs the same population event analysis as in [Filipchuk et al. 2022](https://www.biorxiv.org/content/10.1101/2021.08.31.458322v2) and then also extracts the core neurons of the events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())\n",
    "\n",
    "from builtins import exec\n",
    "exec(open(\"./imports_functions.py\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading curated data from MICrONS project phase 1\n",
    "\n",
    "The following code for data loading and selection is taken from   \n",
    "https://github.com/AllenInstitute/MicronsBinder/blob/master/notebooks/intro/MostSynapsesInAndOut.ipynb   \n",
    "https://github.com/AllenInstitute/MicronsBinder/blob/master/notebooks/vignette_analysis/function/structure_function_analysis.ipynb\n",
    "\n",
    "`Neurons.pkl` contains the `segment_id` for each pyramidal neuron in the EM volume.    \n",
    "`Soma.pkl` contains the soma position for all the cells in the EM volume.   \n",
    "`calcium_trace.pkl` contains the calcium imaging traces (including deconvolved spikes).    \n",
    "`soma_subgraph_synapses_spines_v185.csv` contains the list of synapses with root pre-/post-synaptic somas.\n",
    "\n",
    "**CAUTION: The cell below might take some time to load the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"MICrONS_data/calcium_trace.pkl\"):\n",
    "    print(\"Downloading 2photon calcium traces ...\")\n",
    "    resp = wget.download(\"https://zenodo.org/record/5646567/files/calcium_trace.pkl?download=1\", \"MICrONS_data/calcium_trace.pkl\")\n",
    "    print(\"... Done: \"+resp)\n",
    "\n",
    "if not os.path.exists(\"MICrONS_data/pni_synapses_v185.csv\"):\n",
    "    print(\"Downloading Synapse table ...\")\n",
    "    resp = wget.download(\"https://zenodo.org/record/3710459/files/pni_synapses_v185.csv?download=1\", \"MICrONS_data/pni_synapses_v185.csv\")\n",
    "    print(\"... Done: \"+resp)\n",
    "\n",
    "if not os.path.exists(\"MICrONS_data/calcium_trace.pkl\"):\n",
    "    print(\"Downloading soma_subgraph_synapses_spines_v185 ...\")\n",
    "    resp = wget.download(\"https://zenodo.org/record/3710459/files/soma_subgraph_synapses_spines_v185.csv?download=1\", \"MICrONS_data/soma_subgraph_synapses_spines_v185.csv\")\n",
    "    print(\"... Done: \"+resp)\n",
    "\n",
    "with open(\"MICrONS_data/Neuron.pkl\", 'rb') as handle:\n",
    "    Neuron = pickle.load(handle)\n",
    "with open(\"MICrONS_data/Soma.pkl\", 'rb') as handle:\n",
    "    Soma = pickle.load(handle)\n",
    "if os.path.exists(\"MICrONS_data/calcium_trace.pkl\"):\n",
    "    calcium_trace = pd.read_pickle(\"MICrONS_data/calcium_trace.pkl\")\n",
    "# print(calcium_trace)\n",
    "\n",
    "syn_spines_df = pd.read_csv('MICrONS_data/soma_subgraph_synapses_spines_v185.csv')\n",
    "# id, pre_root_id, post_root_id, cleft_vx, spine_vol_um3\n",
    "\n",
    "syn_df = pd.read_csv('MICrONS_data/pni_synapses_v185.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the IDs and number of recorded pyramidal neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyc_list = Neuron[\"segment_id\"]\n",
    "n_pyc = pyc_list.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the folder to which all results will be saved, and the frame duration (from the MICrONS docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = os.getcwd()\n",
    "frame_duration = 0.0674 # sec, 14.8313 frames per second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Accessing 2-photon Calcium imaging data subset\n",
    "\n",
    "We are interested in reading only the Ca-imaging data of the cells for which also the EM reconstruction is available.   \n",
    "\n",
    "##### CAUTION: next cell can take some time to load all calcium imaging data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pyramidal neurons recorded with 2-photon Calcium imaging:  112\n",
      "... producing spike rasterplot\n"
     ]
    }
   ],
   "source": [
    "print(\"Pyramidal neurons recorded with 2-photon Calcium imaging: \",len(calcium_trace))\n",
    "ophys_cell_ids = list(calcium_trace.keys())\n",
    "n_frames = len(calcium_trace[ophys_cell_ids[0]]['spike'])\n",
    "start_time = 200*frame_duration # 200 frames of blank screen\n",
    "stop_time = (200+n_frames)*frame_duration\n",
    "time = np.arange(start_time,stop_time,frame_duration)\n",
    "\n",
    "decs = []\n",
    "for ocell_id in ophys_cell_ids:\n",
    "    decs.append(calcium_trace[ocell_id][\"spike\"]) # deconvolved Ca spiketrains\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(n_frames), decs[0])\n",
    "fig.savefig(exp_path+'/results/deconvolved_Ca_spikes0.png', dpi=300, transparent=True)\n",
    "plt.close()\n",
    "fig.clf()\n",
    "spiketrains = []\n",
    "for decst in decs:\n",
    "    spiketrains.append( time[:][np.nonzero(decst)] )\n",
    "\n",
    "print(\"... producing spike rasterplot\")\n",
    "fig = plt.figure(figsize=[12.8,4.8])\n",
    "for row,train in enumerate(spiketrains):\n",
    "    plt.scatter( train, [row]*len(train), marker='o', edgecolors='none', s=1, c='k' )\n",
    "plt.ylabel(\"cell IDs\")\n",
    "plt.xlabel(\"time (s)\")\n",
    "fig.savefig(exp_path+'/results/rasterplot.png', transparent=False, dpi=800)\n",
    "plt.close()\n",
    "fig.clear()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the cell indexes from the list of IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ophys_cell_indexes = range(len(ophys_cell_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get soma center locations\n",
    "\n",
    "They are provided in voxels coordinates of 4,4,40 nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyc_soma_loc = np.zeros((n_pyc, 3))\n",
    "for i in range(n_pyc):\n",
    "    seg_id = pyc_list[i]\n",
    "    pyc_soma_loc[i,:] = get_soma_loc(Soma, seg_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join cell indexes with their position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyc_ca_soma_loc = np.zeros((len(ophys_cell_indexes), 3))\n",
    "for i in ophys_cell_indexes:\n",
    "    seg_id = ophys_cell_ids[i]\n",
    "    idx = np.where(pyc_list==seg_id)[0][0]\n",
    "    pyc_ca_soma_loc[i,:] = pyc_soma_loc[idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only the synapses of the 2p recorded neurons\n",
    "\n",
    "Take only synapses and spines whose root_id is either pre- or post- synaptic to somas corresponding to 2photon-recorded pyramidal neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyc_ca_syn_df = syn_df.query('(pre_root_id in @ophys_cell_ids) and (post_root_id in @ophys_cell_ids)')\n",
    "pyc_ca_syn_spines_df = syn_spines_df.query('(pre_root_id in @ophys_cell_ids) and (post_root_id in @ophys_cell_ids)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also take post-synaptic spines of IDs which are coming from non-imaged neurons, and even neurons whose somas are not present in the EM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1669, 17)\n"
     ]
    }
   ],
   "source": [
    "postsyn_spines_df = syn_spines_df.query('post_root_id in @ophys_cell_ids')\n",
    "print(postsyn_spines_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural Analysis\n",
    "\n",
    "First, we build an adjacency matrix of the 2p/EM-imaged neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.zeros((len(ophys_cell_indexes), len(ophys_cell_indexes)))\n",
    "for i in ophys_cell_indexes:\n",
    "    root_id = ophys_cell_ids[i]\n",
    "    root_id_postsyn_list = pyc_ca_syn_df[pyc_ca_syn_df['pre_root_id'] == root_id]['post_root_id'].tolist()\n",
    "    # print(root_id_postsyn_list)\n",
    "    for ps in root_id_postsyn_list:\n",
    "        if ps in ophys_cell_ids:\n",
    "            # ips = np.argwhere(ophys_cell_ids==ps)[0][0]\n",
    "            ips = ophys_cell_ids.index(ps)\n",
    "            # print(ps, ips)\n",
    "            adjacency_matrix[i][ips]=1\n",
    "np.save(exp_path+'/results/adjacency_matrix.npy', adjacency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several global purely structural measures.    \n",
    "This includes **panel 2B** (with inset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... adjacency matrix\n",
      "... loaded\n",
      "    number of vertices: 112\n",
      "... Network nodes degrees\n",
      "... Degree distributions\n",
      "... Betweenness centrality\n",
      "... Motifs\n",
      "... density: 0.02431441326530612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "structural_analysis.py:153: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  motifsratio = motifs/surrogate_motifs\n"
     ]
    }
   ],
   "source": [
    "global_degree_counts = []\n",
    "global_degree_distribution = []\n",
    "global_structural_betweeness = []\n",
    "global_structural_motifs = []\n",
    "global_structural_motifsratio = []\n",
    "global_structural_motifsurrogates = []\n",
    "\n",
    "exec(open(\"./structural_analysis.py\").read())\n",
    "\n",
    "global_structural_betweeness.append(betweenness_centrality)\n",
    "global_degree_counts.append(degree_counts)\n",
    "global_degree_distribution.append(degrees)\n",
    "global_structural_motifs.append(motifs)\n",
    "global_structural_motifsurrogates.append(surrogate_motifs)\n",
    "global_structural_motifsratio.append(motifsratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamical Analysis\n",
    "\n",
    "Here we first population events, we quantify them, and we extract their core neurons.   \n",
    "This analysis extends (from step 5 on) that performed by Filipchuk et al. 2022:\n",
    "1. Compute population instantaneous firing rate (bin)\n",
    "\n",
    "2. Establish significance threshold for population events   \n",
    "    2.1 compute Inter-Spike Intervals (ISI) of the original spiketrains   \n",
    "    2.2 reshuffle ISI (100) times   \n",
    "    2.3 compute the population instantaneous firing rate for each surrogate time-binned rasterplot   \n",
    "\n",
    "3. Find population events   \n",
    "    3.1 smoothed firing rate   \n",
    "    3.2 instantaneous threshold is the 99% of the surrogate population instantaneous firing rate   \n",
    "    3.3 the peaks above intersections of smoothed fr and threshold mark population events   \n",
    "    3.4 the minima before and after a peak are taken as start and end times of the population event   \n",
    "    \n",
    "4. Find clusters of events   \n",
    "    4.1 produce a cell id signature vector of each population event   \n",
    "    4.2 perform clustering linkage by complete cross-correlation of event vectors   \n",
    "    4.3 produce surrogates clusters to establish a cluster significance threshold     \n",
    "    4.4 find the event reproducibility within each cluster (cluster events cross-correlation)   \n",
    "\n",
    "5. Find core neurons   \n",
    "    5.1 take all neurons participating to a cluster of events   \n",
    "    5.2 use the 99% of the cluster event reproducibility as significance threshold   \n",
    "    5.3 if the occurrence frequency of a neuron is beyond threshold, then the neuron is taken as core   \n",
    "    5.4 remove core neurons if firing unspecifically within and outside their cluster   \n",
    "    \n",
    "### All panels of Figure 1\n",
    "\n",
    "are produced in the next cell by the file `dynamical_analysis.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... firing statistics\n",
      "    population firing: 1.23±1.14 sp/frame\n",
      "    smoothing\n",
      "... generating surrogates to establish population event threshold\n",
      "    cells firing rate: 0.01±0.10 sp/s\n",
      "    event size threshold (mean): 3.2139256164294947\n",
      "... find population events in the trial\n",
      "... signatures of population events\n",
      "    number of events: 225\n",
      "    number of events per sec: 0.12228127955130923\n",
      "    events duration: 0.674±0.255\n",
      "    events size: 8.000±3.919\n",
      "... Similarity of events matrix\n",
      "... clustering\n",
      "    linkage\n",
      "    surrogate events signatures for clustering threshold\n",
      "    cluster reproducibility threshold: 0.25135164220675643\n",
      "    cluster size threshold: 2\n",
      "    Total number of clusters: 91\n",
      "    removing below size threshold clusters: 3\n",
      "    removing below reproducibility threshold clusters: 86\n",
      "... finding cluster cores\n",
      "    removing cores firing unspecifically\n",
      "    gathering cores from all clusters\n",
      "    # cores: 19\n",
      "    # non-cores: 93\n",
      "    plotting single events rasterplots ...\n",
      "[[], [648518346349539862, 648518346349539366, 648518346349536788], [648518346349539852, 648518346349537513, 648518346349536924, 648518346349539821], [648518346349537487, 648518346349538336], [648518346349539895, 648518346349538209, 648518346349537153, 648518346349539840, 648518346349538112, 648518346349531851, 648518346349532050, 648518346349539599, 648518346349532006, 648518346349532086]]\n"
     ]
    }
   ],
   "source": [
    "global_structural_motif_cores = {k: 0 for k in range(16)}\n",
    "global_structural_motif_others = {k: 0 for k in range(16)}\n",
    "global_events_sec = []\n",
    "global_events_duration = []\n",
    "global_cluster_number = []\n",
    "global_cluster_selfsimilarity = []\n",
    "\n",
    "exec(open(\"./dynamical_analysis.py\").read())\n",
    "\n",
    "global_events_sec.append(events_sec)\n",
    "global_events_duration.extend(events_durations_f)\n",
    "global_cluster_number.append(nclusters)\n",
    "global_cluster_selfsimilarity.extend(reproducibility_list)\n",
    "\n",
    "print(clusters_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Mixing structural and dynamical analyses results to characterize core connectivity\n",
    "\n",
    "Here, we collect the evidence contrasting the hypothesis that core neurons are strongly connected.   \n",
    "We tested two fundamental attractor-driven assumptions:\n",
    "- synapses between cores are more efficient compared to others   \n",
    "- circuits made by cores involve more recursive connections toward cores\n",
    "\n",
    "### Spine number and volume (panel 2A, 2B)\n",
    "\n",
    "We can take the **number** (2A) and **volume** (2B) of post-synaptic spines as proxy for their functional efficacy.   \n",
    "The number of cores and non-cores for each cluster is different. Therefore we have to normalize this count to evaluate.\n",
    "\n",
    "For each set of reproducible cluster we count:    \n",
    "- the number of synapses made by a cell type (core or not) towards others, weighted by the squared number of target cells    \n",
    "    - the expectation is that core-to-core and core-to-other synapses should be numerous in order to pull the dynamics\n",
    "- the post-synaptic spine volume of synapses made by a cell type (core or not) towards others.   \n",
    "    - the expectation is that core-to-core and core-to-other spines should be larger in order to pull the dynamics\n",
    "\n",
    "**There are no synapses between core neurons of each cluster.**    \n",
    "Note that the resulting normalized synapse counts (for the others) check with the network density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... network density (ratio between the edges present and the maximum number of edges that the graph can contain): 0.02431441326530612\n",
      "... Normalized number of spines\n",
      "    0.000000 core2core normalized spines number\n",
      "    0.020232 core2other normalized spines number\n",
      "    0.019534 other2core normalized spines number\n",
      "    0.021804 other2other normalized spines number\n",
      "... Spine volumes\n",
      "    0 core2core spines\n",
      "    17 core2other spines, volume: 0.085±0.06 µm3\n",
      "    11 other2core spines, volume: 0.090±0.06 µm3\n",
      "    257 other2other spines, volume: 0.075±0.07 µm3\n"
     ]
    }
   ],
   "source": [
    "# the density of the directed graph.\n",
    "network_density = dgraph.density(loops=True)\n",
    "print(\"... network density (ratio between the edges present and the maximum number of edges that the graph can contain):\", network_density )\n",
    "# spine number\n",
    "core2core_spine_num = 0.0 # to be normalized\n",
    "core2other_spine_num = 0.0\n",
    "other2core_spine_num = 0.0\n",
    "other2other_spine_num = 0.0\n",
    "# spine volume\n",
    "core2core_spine_vol = [] # µm3\n",
    "core2other_spine_vol = []\n",
    "other2core_spine_vol = []\n",
    "other2other_spine_vol = []\n",
    "\n",
    "set_ids = set(ophys_cell_ids)\n",
    "for dyn_core_ids in clusters_cores:\n",
    "    dyn_other_ids = set_ids.symmetric_difference(dyn_core_ids)\n",
    "\n",
    "    # id, pre_root_id, post_root_id, cleft_vx, spine_vol_um3\n",
    "    core2core_synapse_df = pyc_ca_syn_spines_df.query(f'(pre_root_id in {list(dyn_core_ids)}) and (post_root_id in {list(dyn_core_ids)})')\n",
    "    if not core2core_synapse_df.empty:\n",
    "        core2core_spine_vol.extend( core2core_synapse_df['spine_vol_um3'].tolist() )\n",
    "        core2core_spine_num += len(core2core_synapse_df['spine_vol_um3'].tolist())/(len(dyn_core_ids)*len(dyn_core_ids)) # normalized by target\n",
    "    \n",
    "    core2other_synapse_df = pyc_ca_syn_spines_df.query(f'(pre_root_id in {list(dyn_core_ids)}) and (post_root_id in {list(dyn_other_ids)})')\n",
    "    if not core2other_synapse_df.empty:\n",
    "        core2other_spine_vol.extend( core2other_synapse_df['spine_vol_um3'].tolist() )\n",
    "        core2other_spine_num += len(core2other_synapse_df['spine_vol_um3'].tolist())/(len(dyn_core_ids)*len(dyn_other_ids)) \n",
    "    \n",
    "    other2core_synapse_df = pyc_ca_syn_spines_df.query(f'(pre_root_id in {list(dyn_other_ids)}) and (post_root_id in {list(dyn_core_ids)})')\n",
    "    if not other2core_synapse_df.empty:\n",
    "        other2core_spine_vol.extend( other2core_synapse_df['spine_vol_um3'].tolist() )\n",
    "        other2core_spine_num += len(other2core_synapse_df['spine_vol_um3'].tolist())/(len(dyn_core_ids)*len(dyn_other_ids)) \n",
    " \n",
    "    other2other_synapse_df = pyc_ca_syn_spines_df.query(f'(pre_root_id in {list(dyn_other_ids)}) and (post_root_id in {list(dyn_other_ids)})')\n",
    "    if not other2other_synapse_df.empty:\n",
    "        other2other_spine_vol.extend( other2other_synapse_df['spine_vol_um3'].tolist() )\n",
    "        other2other_spine_num += len(other2other_synapse_df['spine_vol_um3'].tolist())/(len(dyn_other_ids)*len(dyn_other_ids)) \n",
    "\n",
    "# description\n",
    "# number\n",
    "print(\"... Normalized number of spines\")\n",
    "print(\"    {:f} core2core normalized spines number\".format((core2core_spine_num)) )\n",
    "print(\"    {:f} core2other normalized spines number\".format((core2other_spine_num)) )\n",
    "print(\"    {:f} other2core normalized spines number\".format((other2core_spine_num)) )\n",
    "print(\"    {:f} other2other normalized spines number\".format((other2other_spine_num)) )\n",
    "\n",
    "# spines\n",
    "print(\"... Spine volumes\")\n",
    "print(\"    {:d} core2core spines\".format(len(core2core_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(core2core_spine_vol)) )\n",
    "print(\"    {:d} core2other spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(core2other_spine_vol), np.mean(core2other_spine_vol),np.std(core2other_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(core2other_spine_vol)) )\n",
    "print(\"    {:d} other2core spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(other2core_spine_vol), np.mean(other2core_spine_vol),np.std(other2core_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(other2core_spine_vol)) )\n",
    "print(\"    {:d} other2other spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(other2other_spine_vol), np.mean(other2other_spine_vol),np.std(other2other_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(other2other_spine_vol)) )\n",
    "\n",
    "# plotting\n",
    "# all spine number by type\n",
    "x = np.array([\"core-core\", \"core-other\", \"other-core\", \"other-other\"])\n",
    "y = np.array([core2core_spine_num, core2other_spine_num, other2core_spine_num, other2other_spine_num])\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x, y, color=['forestgreen','forestgreen','silver','silver'])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Normalized number of spines')\n",
    "fig.savefig(exp_path+'/results/global_cores_others_spine_num.svg', transparent=True)\n",
    "fig.clf()\n",
    "plt.close()\n",
    "\n",
    "# all spine volumes by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(0, 0.04, len(core2other_spine_vol))\n",
    "plt.scatter(xs, core2other_spine_vol, edgecolor='forestgreen', facecolor=('#228B224d'))\n",
    "xs = np.random.normal(1, 0.04, len(other2core_spine_vol))\n",
    "plt.scatter(xs, other2core_spine_vol, edgecolor='silver', facecolor=('#D3D3D34d'))\n",
    "xs = np.random.normal(2, 0.04, len(other2other_spine_vol))\n",
    "plt.scatter(xs, other2other_spine_vol, edgecolor='silver', facecolor=('#D3D3D34d'))\n",
    "vp = ax.violinplot([core2other_spine_vol,other2core_spine_vol,other2other_spine_vol], [0,1,2], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc in vp['bodies'][0:1]:\n",
    "    pc.set_facecolor('#228B224d')\n",
    "for pc in vp['bodies'][1:]:\n",
    "    pc.set_facecolor('#D3D3D34d')\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Spine Volume (µm^3)')\n",
    "plt.xticks([0, 1, 2], [ \"core-other\\n(n={:d})\".format(len(core2other_spine_vol)),\"other-core\\n(n={:d})\".format(len(other2core_spine_vol)),\"other-other\\n(n={:d})\".format(len(other2other_spine_vol))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_spine_vol.svg', transparent=True)\n",
    "fig.savefig(exp_path+'/results/global_cores_others_spine_vol.png', transparent=True, dpi=1200)\n",
    "fig.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Ca-imaged and outside EM volume inputs (panel 2B, last two boxes)\n",
    "\n",
    "Core responses could be due to non-imaged and outside volume sources. How can we rule this out (or reduce our lack of knowledge)?   \n",
    "We can ask *Are there more or stronger spines made by non-imaged neurons (either local or far) on cores or others?*   \n",
    "We have this information since we know the cell ID of all somas in the volume. We can take the spines having presynaptic ID different from the known Ca-imaged IDs or different from the somas within the EM volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... postsynaptic spines on cores or others from sources non-imaged or without soma in the volume\n",
      "    107 far2core spines, volume: 0.083±0.09 µm3\n",
      "    2383 far2other spines, volume: 0.081±0.09 µm3\n",
      "    far-core vs far-other spine size Kruskal-Wallis test results: 0.018610687229792457 0.8914884790990162\n",
      "    Kolmogorov-Smirnov Effect Size: 0.044\n"
     ]
    }
   ],
   "source": [
    "print(\"... postsynaptic spines on cores or others from sources non-imaged or without soma in the volume\")\n",
    "far2core_spine_vol = [] # µm3\n",
    "far2other_spine_vol = []\n",
    "set_ids = set(ophys_cell_ids)\n",
    "for dyn_core_ids in clusters_cores:\n",
    "    dyn_other_ids = set_ids.symmetric_difference(dyn_core_ids)\n",
    "    # searching\n",
    "    # id, pre_root_id, post_root_id, cleft_vx, spine_vol_um3\n",
    "    far2core_synapse_df = postsyn_spines_df.query(f'(pre_root_id not in {list(set_ids)}) and (post_root_id in {list(dyn_core_ids)})')\n",
    "    if not far2core_synapse_df.empty:\n",
    "        far2core_spine_vol.extend( far2core_synapse_df['spine_vol_um3'].tolist() )\n",
    "    far2other_synapse_df = postsyn_spines_df.query(f'(pre_root_id not in {list(set_ids)}) and (post_root_id in {list(dyn_other_ids)})')\n",
    "    if not far2other_synapse_df.empty:\n",
    "        far2other_spine_vol.extend( far2other_synapse_df['spine_vol_um3'].tolist() )\n",
    "        \n",
    "# description\n",
    "print(\"    {:d} far2core spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(far2core_spine_vol), np.mean(far2core_spine_vol),np.std(far2core_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(far2core_spine_vol)) )\n",
    "print(\"    {:d} far2other spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(far2other_spine_vol), np.mean(far2other_spine_vol),np.std(far2other_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(far2other_spine_vol)) )\n",
    "\n",
    "# significativity\n",
    "kwstat,pval = stats.kruskal(far2core_spine_vol, far2other_spine_vol)\n",
    "print(\"    far-core vs far-other spine size Kruskal-Wallis test results:\",kwstat,pval)\n",
    "if len(far2core_spine_vol)>0 and len(far2other_spine_vol)>0:\n",
    "    d,_ = stats.ks_2samp(far2core_spine_vol, far2other_spine_vol) # non-parametric measure of effect size [0,1]\n",
    "    print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "# all spine volumes by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(far2core_spine_vol))\n",
    "plt.scatter(xs, far2core_spine_vol, edgecolor='forestgreen', facecolor=('#228B224d'))\n",
    "xs = np.random.normal(2, 0.04, len(far2other_spine_vol))\n",
    "plt.scatter(xs, far2other_spine_vol, edgecolor='silver', facecolor=('#D3D3D34d'))\n",
    "vp = ax.violinplot([far2core_spine_vol,far2other_spine_vol], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Spine Volume (µm^3)')\n",
    "plt.xticks([1, 2], [\"far-core\\n(n={:d})\".format(len(far2core_spine_vol)), \"far-other\\n(n={:d})\".format(len(far2other_spine_vol))])\n",
    "fig.savefig(exp_path+'/results/global_far_cores_others_spine_vol.svg', transparent=True)\n",
    "fig.savefig(exp_path+'/results/global_far_cores_others_spine_vol.png', transparent=True, dpi=1200)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are core more mutually connected than others?\n",
    "\n",
    "We started by asking whether a global measure such as assortativity - - gives a clear summary of mutuality between all cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... assortativity\n",
      "    overall: -0.043674020711391294\n",
      "    assortativity degree: -0.08993903571766572\n"
     ]
    }
   ],
   "source": [
    "dgraph.vs[\"ophys_cell_id\"] = ophys_cell_ids\n",
    "is_id_core = np.array( [0] * len(ophys_cell_ids) )\n",
    "is_id_core[core_indexes] = 1\n",
    "dgraph.vs[\"is_core\"] = is_id_core.tolist()\n",
    "is_syn_core = np.array( [0] * len(pyc_ca_syn_df) )\n",
    "for cid in [item for sublist in clusters_cores for item in sublist]:\n",
    "    is_syn_core[pyc_ca_syn_df['pre_root_id'] == cid] = 1\n",
    "dgraph.es[\"is_core\"] = is_syn_core.tolist()\n",
    "color_dict = {0: \"gray\", 1: \"green\"}\n",
    "ig.plot(dgraph, exp_path+'/results/all_ring.svg', layout=dgraph.layout(\"circle\"),\n",
    "        edge_curved=0.2,\n",
    "        edge_color=[color_dict[is_core] for is_core in dgraph.es[\"is_core\"]],\n",
    "        edge_width=0.5,\n",
    "        edge_arrow_size=0.1,\n",
    "        vertex_size=5,\n",
    "        vertex_color=[color_dict[is_core] for is_core in dgraph.vs[\"is_core\"]],\n",
    "        vertex_frame_color=[color_dict[is_core] for is_core in dgraph.vs[\"is_core\"]],\n",
    "        margin=50)\n",
    "print('... assortativity')\n",
    "# is a preference for a network's nodes to attach to others that are similar in some way\n",
    "print(\"    overall:\", dgraph.assortativity_nominal(\"is_core\", directed=True) )\n",
    "# cores degree distro vs others degree distro\n",
    "# biological networks typically show negative assortativity, or disassortative mixing, or disassortativity, as high degree nodes tend to attach to low degree nodes.\n",
    "print(\"    assortativity degree:\", dgraph.assortativity_degree(directed=True) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Motif connectivity of cores and others (panel 2D)\n",
    "\n",
    "This measure of the network reports the participation of cores (or non-cores) in triplet motifs.    \n",
    "Note that the triplets are not exclusively made of cores (or non-cores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... saved mutual connectivity of cores and others\n"
     ]
    }
   ],
   "source": [
    "# For each set of reproducible cluster cores we count their connectivity motifs.\n",
    "set_indexes = set(ophys_cell_indexes)\n",
    "for dyn_core_ids in clusters_cores:\n",
    "    dyn_core_indexes = set([ophys_cell_ids.index(strid) for strid in dyn_core_ids])\n",
    "    dyn_other_indexes = set_indexes.symmetric_difference(dyn_core_indexes)\n",
    "    for mclass, mlist in motif_vertices.items():\n",
    "        for mtriplet in mlist:\n",
    "            intersection_cores = len(list(dyn_core_indexes.intersection(mtriplet)))\n",
    "            intersection_others = len(list(dyn_other_indexes.intersection(mtriplet)))\n",
    "            global_structural_motif_cores[mclass] += intersection_cores\n",
    "            global_structural_motif_others[mclass] += intersection_others\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.bar(global_structural_motif_cores.keys(), global_structural_motif_cores.values(), color='forestgreen')\n",
    "plt.ylabel('cores occurrences')\n",
    "plt.yscale('log')\n",
    "plt.ylim([0.7,plt.ylim()[1]])\n",
    "plt.xlabel('motifs types')\n",
    "fig.savefig(exp_path+'/results/global_motifs_cores.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clear()\n",
    "fig.clf()\n",
    "fig = plt.figure()\n",
    "plt.bar(global_structural_motif_others.keys(), global_structural_motif_others.values(), color='silver')\n",
    "plt.ylabel('non-cores occurrences')\n",
    "plt.yscale('log')\n",
    "plt.ylim([0.7,plt.ylim()[1]])\n",
    "plt.xlabel('motifs types')\n",
    "fig.savefig(exp_path+'/results/global_motifs_others.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clear()\n",
    "fig.clf()\n",
    "print(\"... saved mutual connectivity of cores and others\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    graph diameter (#vertices): 7\n",
      "    graph average path length (#vertices): 2.5824324324324324\n"
     ]
    }
   ],
   "source": [
    "# dgraph is already defined from the structural_analysis included file\n",
    "print(\"    graph diameter (#vertices):\", dgraph.diameter(directed=True, unconn=True, weights=None))\n",
    "print(\"    graph average path length (#vertices):\", dgraph.average_path_length(directed=True, unconn=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Do the cores of each cluster form a clique? (panel E)\n",
    "\n",
    "If the cores of each cluster are pattern completion units, they should participate in more cliques (set of vertices where an edge is present between any two of them) than other non-core neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_674/301039441.py:1: RuntimeWarning: Edge directions are ignored for clique calculations at src/cliques/cliquer_wrapper.c:57\n",
      "  cliques = dgraph.cliques(min=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cliques made by cores: 100\n",
      "    cliques made by others: 169\n"
     ]
    }
   ],
   "source": [
    "cliques = dgraph.cliques(min=2)\n",
    "\n",
    "cliques_cores = []\n",
    "cliques_others = []\n",
    "\n",
    "for cluster_cids in clustered_spectrums:\n",
    "    cluster_core_indices = []\n",
    "    # we take the index of the cell participating in this cluster\n",
    "    cluster_indices = [ophys_cell_ids.index(strid) for strid in cluster_cids]\n",
    "    # we take the cores of this cluster\n",
    "    cluster_core_indices = list(set(core_indexes).intersection(cluster_indices))\n",
    "    cluster_other_indices = list(set(other_indexes).intersection(cluster_indices))\n",
    "    # we take the edges between the cores\n",
    "    for clique in cliques:\n",
    "        if set(clique).issubset(cluster_core_indices):\n",
    "            cliques_cores.append(clique)\n",
    "        if set(clique).issubset(cluster_other_indices):\n",
    "            cliques_others.append(clique)\n",
    "\n",
    "cores_cliques_count = len(cliques_cores)\n",
    "others_cliques_count = len(cliques_others)\n",
    "\n",
    "print(\"    cliques made by cores:\",cores_cliques_count)\n",
    "print(\"    cliques made by others:\",others_cliques_count)\n",
    "\n",
    "# print(core_edges)\n",
    "x = np.array([\"cores\", \"others\"])\n",
    "y = np.array([cores_cliques_count, others_cliques_count])\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x, y, color=['forestgreen','silver'])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Count of cliques')\n",
    "plt.xticks([0, 1], [\"core\\n(n={:d})\".format(cores_cliques_count), \"other\\n(n={:d})\".format(others_cliques_count)])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_cliques.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality and flow for cores\n",
    "\n",
    "If cores are not more mutually connected comapred to others, then what is their characterizing feature?    \n",
    "In the cells above, we saw indications of more interconnections between cores and others than within the same type.     \n",
    "We can better characterize that..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree centrality of cores and others (panel 2F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... degree centrality\n",
      "    cores: DescribeResult(nobs=19, minmax=(0, 45), mean=11.68421052631579, variance=197.33918128654966, skewness=1.0172038169530693, kurtosis=-0.20913864740963106)\n",
      "    others: DescribeResult(nobs=93, minmax=(0, 36), mean=4.172043010752688, variance=42.8831229546517, skewness=2.4632096675579036, kurtosis=6.6436291039539626)\n",
      "    Welch t test:  2.281 p= 0.034\n",
      "    Kolmogorov-Smirnov Effect Size: 0.315\n"
     ]
    }
   ],
   "source": [
    "print('... degree centrality')\n",
    "degree_centrality_cores = dgraph.degree(core_indexes, mode='all', loops=True)\n",
    "degree_centrality_others = dgraph.degree(other_indexes, mode='all', loops=True)\n",
    "# description\n",
    "print(\"    cores: \"+str(stats.describe(degree_centrality_cores)) )\n",
    "print(\"    others: \"+str(stats.describe(degree_centrality_others)) )\n",
    "# significativity\n",
    "print(\"    Welch t test:  %.3f p= %.3f\" % stats.ttest_ind(degree_centrality_cores, degree_centrality_others, equal_var=False))\n",
    "d,_ = stats.ks_2samp(degree_centrality_cores, degree_centrality_others) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(degree_centrality_cores))\n",
    "plt.scatter(xs, degree_centrality_cores, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(degree_centrality_others))\n",
    "plt.scatter(xs, degree_centrality_others, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([degree_centrality_cores,degree_centrality_others], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Degree')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(degree_centrality_cores)), \"other\\n(n={:d})\".format(len(degree_centrality_others))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_degree.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness of cores and others (panel 2G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... betweenness\n",
      "    cores: DescribeResult(nobs=19, minmax=(0.0001, 617.3584776334777), mean=101.34851806030227, variance=28753.436796071433, skewness=1.7941408606134543, kurtosis=2.5429619844405478)\n",
      "    others: DescribeResult(nobs=93, minmax=(0.0001, 555.6747113997113), mean=17.068675880153297, variance=4236.215428044212, skewness=6.518634960916281, kurtosis=49.182590131465965)\n",
      "    Welch t test:  2.135 p= 0.046\n",
      "    Kolmogorov-Smirnov Effect Size: 0.303\n"
     ]
    }
   ],
   "source": [
    "print('... betweenness')\n",
    "cores_betweenness = betweenness_centrality[core_indexes]\n",
    "others_betweenness = betweenness_centrality[other_indexes]\n",
    "cores_betweenness[cores_betweenness<0.0001] = 0.0001 # for later stats and plotting\n",
    "others_betweenness[others_betweenness<0.0001] = 0.0001\n",
    "print(\"    cores: \"+str(stats.describe(cores_betweenness)) )\n",
    "print(\"    others: \"+str(stats.describe(others_betweenness)) )\n",
    "# significativity\n",
    "print(\"    Welch t test:  %.3f p= %.3f\" % stats.ttest_ind(cores_betweenness, others_betweenness, equal_var=False))\n",
    "d,_ = stats.ks_2samp(cores_betweenness, others_betweenness) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(cores_betweenness))\n",
    "plt.scatter(xs, cores_betweenness, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(others_betweenness))\n",
    "plt.scatter(xs, others_betweenness, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([cores_betweenness,others_betweenness], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Betweenness')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(cores_betweenness)), \"other\\n(n={:d})\".format(len(others_betweenness))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_betweenness.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hub scores of cores and others (panel 2H)\n",
    "\n",
    "Are the cores also hubs of the network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... hub score\n",
      "    hub cores: DescribeResult(nobs=19, minmax=(0.0, 0.8013914826450919), mean=0.2482347880672655, variance=0.07191456105109344, skewness=0.9163364046182091, kurtosis=-0.5166573657005489)\n",
      "    hub others: DescribeResult(nobs=93, minmax=(0.0, 1.0), mean=0.12848438811305246, variance=0.04145697994285601, skewness=2.331235273362784, kurtosis=4.847848290256551)\n",
      "    Kruskal-Wallis test:  2.207 p= 0.029\n",
      "    Kolmogorov-Smirnov Effect Size: 0.344\n"
     ]
    }
   ],
   "source": [
    "print(\"... hub score\")\n",
    "# what is the overlap of cores and hubs?\n",
    "# Hub\n",
    "hub_scores = np.array(dgraph.hub_score(weights=None, scale=True, return_eigenvalue=False))\n",
    "hub_scores_cores = hub_scores[core_indexes]\n",
    "hub_scores_others = hub_scores[other_indexes]\n",
    "print(\"    hub cores: \"+str(stats.describe(hub_scores_cores)) )\n",
    "print(\"    hub others: \"+str(stats.describe(hub_scores_others)) )\n",
    "# significativity\n",
    "print(\"    Kruskal-Wallis test:  %.3f p= %.3f\" % stats.ttest_ind(hub_scores_cores, hub_scores_others))\n",
    "d,_ = stats.ks_2samp(hub_scores_cores, hub_scores_others) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "# all eccentricity by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(hub_scores_cores))\n",
    "plt.scatter(xs, hub_scores_cores, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(hub_scores_others))\n",
    "plt.scatter(xs, hub_scores_others, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([hub_scores_cores,hub_scores_others], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Hub score')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(hub_scores_cores)), \"other\\n(n={:d})\".format(len(hub_scores_others))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_hub_score.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow of cores vs others (panel 2J)\n",
    "\n",
    "So far, we used structural (graph) measures of neurons selected by looking at their activity.   \n",
    "So, in a sense, we already crossed structural and dynamical information about the network.    \n",
    "However, we could push this even further.   \n",
    "To understand how core centrality could affect population events, we considered the flow – number and identity of connections to cut to interrupt the circuit between the first and the last firing neuron of each population event (e.g. the subgraphs made by neurons active in the events depicted in Fig. 1E). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... flow between beginning and end of event cells\n",
      "    cores in the edges removed to stop the flow: 0\n",
      "    others in the edges removed to stop the flow: 0\n"
     ]
    }
   ],
   "source": [
    "print('... flow between beginning and end of event cells')\n",
    "# Flow\n",
    "# Returns all the cuts between the source and target vertices in a directed graph.\n",
    "# This function lists all edge-cuts between a source and a target vertex. Every cut is listed exactly once.\n",
    "core_edges = []\n",
    "other_edges = []\n",
    "for sts,stscol in zip(source_target_cidx,source_target_color):\n",
    "    cuts = dgraph.all_st_cuts(source=sts[0], target=sts[1])\n",
    "    for cut in cuts:\n",
    "        for edge in cut.es:\n",
    "            source_vertex_id = edge.source\n",
    "            target_vertex_id = edge.target\n",
    "            if source_vertex_id in core_indexes:\n",
    "                core_edges.append(source_vertex_id)\n",
    "            elif target_vertex_id in core_indexes:\n",
    "                core_edges.append(target_vertex_id)\n",
    "            else:\n",
    "                other_edges.append(source_vertex_id)\n",
    "                other_edges.append(target_vertex_id)\n",
    "# clusters_cores_by_color\n",
    "cores_edges_count = sum(np.unique(core_edges, return_counts=True)[1])\n",
    "others_edges_count = sum(np.unique(other_edges, return_counts=True)[1])\n",
    "print(\"    cores in the edges removed to stop the flow:\",cores_edges_count)\n",
    "print(\"    others in the edges removed to stop the flow:\",others_edges_count)\n",
    "\n",
    "# print(core_edges)\n",
    "x = np.array([\"cores\", \"others\"])\n",
    "y = np.array([cores_edges_count, others_edges_count])\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x, y, color=['forestgreen','silver'])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Count of cutting-flow edges')\n",
    "plt.xticks([0, 1], [\"core\\n(n={:d})\".format(cores_edges_count), \"other\\n(n={:d})\".format(others_edges_count)])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_flow.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Supplementary figure 3\n",
    "   \n",
    "To have keep cores within the attractor framework, cores activity could be sustained by indirect synaptic feedback, through highly connected secondary paths.   \n",
    "To back up the attractor idea, one would expect that core neurons would have shorter paths or cycles, compared to others. \n",
    "\n",
    "### Shortest paths of cores and others (panel S3A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... density: 0.02431441326530612\n",
      "... number of paths in a complete graph of the same size: 4.317298994652368e+178\n",
      "... number of shortest paths between cores\n",
      "    cores shortest paths: DescribeResult(nobs=342, minmax=(0, 5), mean=0.9912280701754386, variance=2.231594381849051, skewness=1.0351565106205716, kurtosis=-0.5207712140685272)\n",
      "    others shortest paths: DescribeResult(nobs=8556, minmax=(0, 8), mean=0.5733987844787284, variance=2.0141327368027304, skewness=2.3079022444523254, kurtosis=4.044514974293836)\n",
      "    equal variances? LeveneResult(statistic=28.387064203775036, pvalue=1.0175664002223936e-07)\n",
      "    Welch t test:  5.082 p= 0.000\n",
      "    Kolmogorov-Smirnov Effect Size: 0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_674/1911908125.py:10: RuntimeWarning: Couldn't reach some vertices at src/paths/unweighted.c:368\n",
      "  shrtpth = dgraph.get_shortest_paths(coreidx, to=othercores, weights=None, mode='out', output='vpath')\n",
      "/tmp/ipykernel_674/1911908125.py:17: RuntimeWarning: Couldn't reach some vertices at src/paths/unweighted.c:368\n",
      "  shrtpth = dgraph.get_shortest_paths(otheridx, to=otherothers, weights=None, mode='out', output='vpath')\n"
     ]
    }
   ],
   "source": [
    "print(\"... number of paths in a complete graph of the same size:\", (np.math.factorial(112-2)*np.e))\n",
    "print('... number of shortest paths between cores')\n",
    "core_shortestpaths = []\n",
    "for coreidx in core_indexes:\n",
    "    othercores = list(core_indexes)\n",
    "    othercores.remove(coreidx)\n",
    "    shrtpth = dgraph.get_shortest_paths(coreidx, to=othercores, weights=None, mode='out', output='vpath')\n",
    "    for strp in shrtpth:\n",
    "        core_shortestpaths.append(len(strp))\n",
    "other_shortestpaths = []\n",
    "for otheridx in other_indexes:\n",
    "    otherothers = list(other_indexes)\n",
    "    otherothers.remove(otheridx)\n",
    "    shrtpth = dgraph.get_shortest_paths(otheridx, to=otherothers, weights=None, mode='out', output='vpath')\n",
    "    for strp in shrtpth:\n",
    "        other_shortestpaths.append(len(strp))\n",
    "print(\"    cores shortest paths: \"+str(stats.describe(core_shortestpaths)) )\n",
    "print(\"    others shortest paths: \"+str(stats.describe(other_shortestpaths)) )\n",
    "print(\"    equal variances? \"+str(stats.levene(core_shortestpaths, other_shortestpaths)) )\n",
    "# significativity\n",
    "print(\"    Welch t test:  %.3f p= %.3f\" % stats.ttest_ind(core_shortestpaths, other_shortestpaths, equal_var=False))\n",
    "d,_ = stats.ks_2samp(core_shortestpaths, other_shortestpaths) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(core_shortestpaths))\n",
    "plt.scatter(xs, core_shortestpaths, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(other_shortestpaths))\n",
    "plt.scatter(xs, other_shortestpaths, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([core_shortestpaths,other_shortestpaths], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Shortest path length')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(core_shortestpaths)), \"other\\n(n={:d})\".format(len(other_shortestpaths))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_shortestpath.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycles between cores or others (panel S3B)\n",
    "\n",
    "Cycles are built starting from a core (or other) and iterating neighbors of different lenghts, where the last vertex is the starting one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... cycles\n"
     ]
    }
   ],
   "source": [
    "print('... cycles')\n",
    "# breadth first search of paths and unique cycles\n",
    "def get_cycles(adj, paths, maxlen):\n",
    "    # tracking the actual path length:\n",
    "    maxlen -= 1\n",
    "    nxt_paths = []\n",
    "    # iterating over all paths:\n",
    "    for path in paths['paths']:\n",
    "        # iterating neighbors of the last vertex in the path:\n",
    "        for nxt in adj[path[-1]]:\n",
    "            # attaching the next vertex to the path:\n",
    "            nxt_path = path + [nxt]\n",
    "            if path[0] == nxt and min(path) == nxt:\n",
    "                # the next vertex is the starting vertex, we found a cycle\n",
    "                # we keep the cycle only if the starting vertex has the\n",
    "                # lowest vertex id, to avoid having the same cycles\n",
    "                # more than once\n",
    "                paths['cycles'].append(nxt_path)\n",
    "                # if you don't need the starting vertex\n",
    "                # included at the end:\n",
    "                # paths$cycles <- c(paths$cycles, list(path))\n",
    "            elif nxt not in path:\n",
    "                # keep the path only if we don't create\n",
    "                # an internal cycle in the path\n",
    "                nxt_paths.append(nxt_path)\n",
    "    # paths grown by one step:\n",
    "    paths['paths'] = nxt_paths\n",
    "    if maxlen == 0:\n",
    "        # the final return when maximum search length reached\n",
    "        return paths\n",
    "    else:\n",
    "        # recursive return, to grow paths further\n",
    "        return get_cycles(adj, paths, maxlen)\n",
    "# Comparison of core based cycles vs other based cycles\n",
    "maxlen = 10 # the maximum length to limit computation time\n",
    "# creating an adjacency list\n",
    "adj = [[n.index for n in v.neighbors()] for v in dgraph.vs]\n",
    "# recursive search of cycles\n",
    "# for each core vertex as candidate starting point\n",
    "core_cycles = []\n",
    "for start in core_indexes:\n",
    "    core_cycles += get_cycles(adj,{'paths': [[start]], 'cycles': []}, maxlen)['cycles']\n",
    "print(\"    # core-based cycles:\", len(core_cycles) )\n",
    "# count the length of loops involving 1 core\n",
    "core_cycles_lens = [len(cycle) for cycle in core_cycles]\n",
    "print(\"    core-based cycles length: \"+str(stats.describe(core_cycles_lens)) )\n",
    "\n",
    "other_cycles = []\n",
    "for start in other_indexes:\n",
    "    other_cycles += get_cycles(adj,{'paths': [[start]], 'cycles': []}, maxlen)['cycles']\n",
    "print(\"    # other-based cycles:\", len(other_cycles) )\n",
    "# count the length of loops involving 1 core\n",
    "other_cycles_lens = [len(cycle) for cycle in other_cycles]\n",
    "print(\"    other-based cycles length: \"+str(stats.describe(other_cycles_lens)) )\n",
    "\n",
    "d,_ = stats.ks_2samp(core_cycles_lens, other_cycles_lens) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "# all cycles by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(core_cycles_lens))\n",
    "plt.scatter(xs, core_cycles_lens, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(other_cycles_lens))\n",
    "plt.scatter(xs, other_cycles_lens, alpha=0.3, c='silver')\n",
    "bp = ax.boxplot([core_cycles_lens,other_cycles_lens], notch=0, sym='', showcaps=False, zorder=10)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Cycles length')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(core_cycles_lens)), \"other\\n(n={:d})\".format(len(other_cycles_lens))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_cyclelens.png', transparent=True, dpi=1500)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
