{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How-to: core neurons are crossroads of cortical dynamics \n",
    "\n",
    "Analysis code to reproduce all panels in figures 1 and 2 of the paper by Guarino, Filipchuk, Destexhe (2022)   \n",
    "preprint link: https://www.biorxiv.org/content/10.1101/2022.05.24.493230v2\n",
    "\n",
    "All this code is hosted on a github [repository](https://github.com/dguarino/Guarino-Filipchuk-Destexhe) (with a Zenodo DOI persistent identifier [here](https://zenodo.org)) and can be interactively executed here.  \n",
    "The repository also contains a copy of the required data files from the [MICrONS project phase1](https://www.microns-explorer.org/phase1) (freely available on the project website), to ease the setup on Binder. \n",
    "\n",
    "This notebook performs loading and selection of the MICrONS data, structural and dynamical analyses, and plots the results as in the paper panels.\n",
    "\n",
    "We divided the analysis code into:\n",
    "- `imports_functions.py` : performs the imports and definition of various helper functions.\n",
    "- `structural_analysis.py` : creates a graph from the connectivity matrix and computes several graph measures (using [igraph](https://igraph.org)).\n",
    "- `dynamical_analysis.py` : performs the same population event analysis as in [Filipchuk et al. 2022](https://www.biorxiv.org/content/10.1101/2021.08.31.458322v2) and then also extracts the core neurons of the events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "from builtins import exec\n",
    "exec(open(\"./imports_functions.py\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading curated data from MICrONS project phase 1\n",
    "\n",
    "The following code for data loading and selection is taken from   \n",
    "https://github.com/AllenInstitute/MicronsBinder/blob/master/notebooks/intro/MostSynapsesInAndOut.ipynb   \n",
    "https://github.com/AllenInstitute/MicronsBinder/blob/master/notebooks/vignette_analysis/function/structure_function_analysis.ipynb\n",
    "\n",
    "`Neurons.pkl` contains the `segment_id` for each pyramidal neuron in the EM volume.    \n",
    "`Soma.pkl` contains the soma position for all the cells in the EM volume.   \n",
    "`calcium_trace.pkl` contains the calcium imaging traces (including deconvolved spikes).    \n",
    "`soma_subgraph_synapses_spines_v185.csv` contains the list of synapses with root pre-/post-synaptic somas.\n",
    "\n",
    "**CAUTION: The cell below might take some time to load the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1961, 17)\n",
      "(3239275, 16)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"MICrONS_data/calcium_trace.pkl\"):\n",
    "    print(\"Downloading 2photon calcium traces ...\")\n",
    "    resp = wget.download(\"https://zenodo.org/record/5646567/files/calcium_trace.pkl?download=1\", \"MICrONS_data/calcium_trace.pkl\")\n",
    "    print(\"... Done: \"+resp)\n",
    "\n",
    "if not os.path.exists(\"MICrONS_data/pni_synapses_v185.csv\"):\n",
    "    print(\"Downloading Synapse table ...\")\n",
    "    resp = wget.download(\"https://zenodo.org/record/3710459/files/pni_synapses_v185.csv?download=1\", \"MICrONS_data/pni_synapses_v185.csv\")\n",
    "    print(\"... Done: \"+resp)\n",
    "\n",
    "if not os.path.exists(\"MICrONS_data/calcium_trace.pkl\"):\n",
    "    print(\"Downloading soma_subgraph_synapses_spines_v185 ...\")\n",
    "    resp = wget.download(\"https://zenodo.org/record/3710459/files/soma_subgraph_synapses_spines_v185.csv?download=1\", \"MICrONS_data/soma_subgraph_synapses_spines_v185.csv\")\n",
    "    print(\"... Done: \"+resp)\n",
    "\n",
    "with open(\"MICrONS_data/Neuron.pkl\", 'rb') as handle:\n",
    "    Neuron = pickle.load(handle)\n",
    "with open(\"MICrONS_data/Soma.pkl\", 'rb') as handle:\n",
    "    Soma = pickle.load(handle)\n",
    "if os.path.exists(\"MICrONS_data/calcium_trace.pkl\"):\n",
    "    calcium_trace = pd.read_pickle(\"MICrONS_data/calcium_trace.pkl\")\n",
    "# print(calcium_trace)\n",
    "\n",
    "syn_spines_df = pd.read_csv('MICrONS_data/soma_subgraph_synapses_spines_v185.csv')\n",
    "# id, pre_root_id, post_root_id, cleft_vx, spine_vol_um3\n",
    "print(syn_spines_df.shape)\n",
    "\n",
    "syn_df = pd.read_csv('MICrONS_data/pni_synapses_v185.csv')\n",
    "print(syn_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the IDs and number of recorded pyramidal neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyc_list = Neuron[\"segment_id\"]\n",
    "n_pyc = pyc_list.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the folder to which all results will be saved, and the frame duration (from the MICrONS docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = os.getcwd()\n",
    "frame_duration = 0.0674 # sec, 14.8313 frames per second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Accessing 2-photon Calcium imaging data subset\n",
    "\n",
    "We are interested in reading only the Ca-imaging data of the cells for which also the EM reconstruction is available.   \n",
    "\n",
    "##### CAUTION: next cell can take some time to load all calcium imaging data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pyramidal neurons recorded with 2-photon Calcium imaging:  112\n",
      "... producing spike rasterplot\n"
     ]
    }
   ],
   "source": [
    "print(\"Pyramidal neurons recorded with 2-photon Calcium imaging: \",len(calcium_trace))\n",
    "ophys_cell_ids = list(calcium_trace.keys())\n",
    "n_frames = len(calcium_trace[ophys_cell_ids[0]]['spike'])\n",
    "start_time = 200*frame_duration # 200 frames of blank screen\n",
    "stop_time = (200+n_frames)*frame_duration\n",
    "time = np.arange(start_time,stop_time,frame_duration)\n",
    "\n",
    "decs = []\n",
    "for ocell_id in ophys_cell_ids:\n",
    "    decs.append(calcium_trace[ocell_id][\"spike\"]) # deconvolved Ca spiketrains\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(n_frames), decs[0])\n",
    "fig.savefig(exp_path+'/results/deconvolved_Ca_spikes0.png', dpi=300, transparent=True)\n",
    "plt.close()\n",
    "fig.clf()\n",
    "spiketrains = []\n",
    "for decst in decs:\n",
    "    spiketrains.append( time[:][np.nonzero(decst)] )\n",
    "\n",
    "print(\"... producing spike rasterplot\")\n",
    "fig = plt.figure(figsize=[12.8,4.8])\n",
    "for row,train in enumerate(spiketrains):\n",
    "    plt.scatter( train, [row]*len(train), marker='o', edgecolors='none', s=1, c='k' )\n",
    "plt.ylabel(\"cell IDs\")\n",
    "plt.xlabel(\"time (s)\")\n",
    "fig.savefig(exp_path+'/results/rasterplot.png', transparent=False, dpi=800)\n",
    "plt.close()\n",
    "fig.clear()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the cell indexes from the list of IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ophys_cell_indexes = range(len(ophys_cell_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get soma center locations\n",
    "\n",
    "They are provided in voxels coordinates of 4,4,40 nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyc_soma_loc = np.zeros((n_pyc, 3))\n",
    "for i in range(n_pyc):\n",
    "    seg_id = pyc_list[i]\n",
    "    pyc_soma_loc[i,:] = get_soma_loc(Soma, seg_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join cell indexes with their position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyc_ca_soma_loc = np.zeros((len(ophys_cell_indexes), 3))\n",
    "for i in ophys_cell_indexes:\n",
    "    seg_id = ophys_cell_ids[i]\n",
    "    idx = np.where(pyc_list==seg_id)[0][0]\n",
    "    pyc_ca_soma_loc[i,:] = pyc_soma_loc[idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Structural Analysis\n",
    "\n",
    "First, we build an adjacency matrix of the 2p/EM-imaged neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.zeros((len(ophys_cell_indexes), len(ophys_cell_indexes)))\n",
    "for i in ophys_cell_indexes:\n",
    "    root_id = ophys_cell_ids[i]\n",
    "    root_id_postsyn_list = syn_df[syn_df['pre_root_id'] == root_id]['post_root_id'].tolist()\n",
    "    # print(root_id_postsyn_list)\n",
    "    for ps in root_id_postsyn_list:\n",
    "        if ps in ophys_cell_ids:\n",
    "            # ips = np.argwhere(ophys_cell_ids==ps)[0][0]\n",
    "            ips = ophys_cell_ids.index(ps)\n",
    "            # print(ps, ips)\n",
    "            adjacency_matrix[i][ips]=1\n",
    "np.save(exp_path+'/results/adjacency_matrix.npy', adjacency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several global purely structural measures.    \n",
    "This includes **panel 2B** (with inset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... adjacency matrix\n",
      "... loaded\n",
      "    number of vertices: 112\n",
      "... Network nodes degrees\n",
      "... Degree distributions\n",
      "... Betweenness centrality\n",
      "... Motifs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:150: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "global_degree_counts = []\n",
    "global_degree_distribution = []\n",
    "global_structural_betweeness = []\n",
    "global_structural_motifs = []\n",
    "global_structural_motifsratio = []\n",
    "global_structural_motifsurrogates = []\n",
    "\n",
    "exec(open(\"./structural_analysis.py\").read())\n",
    "\n",
    "global_structural_betweeness.append(betweenness_centrality)\n",
    "global_degree_counts.append(degree_counts)\n",
    "global_degree_distribution.append(degrees)\n",
    "global_structural_motifs.append(motifs)\n",
    "global_structural_motifsurrogates.append(surrogate_motifs)\n",
    "global_structural_motifsratio.append(motifsratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamical Analysis\n",
    "\n",
    "Here we first population events, we quantify them, and we extract their core neurons.   \n",
    "This analysis extends (from step 5 on) that performed by Filipchuk et al. 2022:\n",
    "1. Compute population instantaneous firing rate (bin)\n",
    "\n",
    "2. Establish significance threshold for population events   \n",
    "    2.1 compute Inter-Spike Intervals (ISI) of the original spiketrains   \n",
    "    2.2 reshuffle ISI to create (1000) surrogates   \n",
    "    2.3 compute the population instantaneous firing rate for each surrogate time-binned rasterplot   \n",
    "\n",
    "3. Find population events   \n",
    "    3.1 smoothed firing rate   \n",
    "    3.2 instantaneous threshold is the 99% of the surrogate population instantaneous firing rate   \n",
    "    3.3 the peaks above intersections of smoothed fr and threshold mark population events   \n",
    "    3.4 the minima before and after a peak are taken as start and end times of the population event   \n",
    "    \n",
    "4. Find clusters of events   \n",
    "    4.1 produce a cell id signature vector of each population event   \n",
    "    4.2 perform clustering linkage by complete cross-correlation of event vectors   \n",
    "    4.3 produce surrogates clusters to establish a cluster significance threshold     \n",
    "    4.4 find the event reproducibility within each cluster (cluster events cross-correlation)   \n",
    "\n",
    "5. Find core neurons   \n",
    "    5.1 take all neurons participating to a cluster of events   \n",
    "    5.2 use the 99% of the cluster event reproducibility as significance threshold   \n",
    "    5.3 if the occurrence frequency of a neuron is beyond threshold, then the neuron is taken as core   \n",
    "    5.4 remove core neurons if firing unspecifically within and outside their cluster   \n",
    "    \n",
    "### All panels of Figure 1\n",
    "\n",
    "are produced in the next cell by the file `dynamical_analysis.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... firing statistics\n",
      "    population firing: 1.23±1.14 sp/frame\n",
      "    smoothing\n",
      "... generating surrogates to establish population event threshold\n",
      "    cells firing rate: 0.01±0.10 sp/s\n",
      "    event size threshold (mean): 3.2139256164294947\n",
      "... find population events in the trial\n",
      "... signatures of population events\n",
      "    number of events: 225\n",
      "    number of events per sec: 0.12228127955130923\n",
      "    events duration: 0.674±0.255\n",
      "    events size: 8.000±3.919\n",
      "... Similarity of events matrix\n",
      "... clustering\n",
      "    linkage\n",
      "    surrogate events signatures for clustering threshold\n",
      "    cluster reproducibility threshold: 0.25135164220675643\n",
      "    cluster size threshold: 2\n",
      "    Total number of clusters: 91\n",
      "    removing below size threshold clusters: 3\n",
      "    removing below reproducibility threshold clusters: 86\n",
      "... finding cluster cores\n",
      "    removing cores firing unspecifically\n",
      "    gathering cores from all clusters\n",
      "    # cores: 19\n",
      "    # non-cores: 93\n",
      "    plotting single events rasterplots ...\n"
     ]
    }
   ],
   "source": [
    "global_structural_motif_cores = {k: 0 for k in range(16)}\n",
    "global_structural_motif_others = {k: 0 for k in range(16)}\n",
    "global_events_sec = []\n",
    "global_events_duration = []\n",
    "global_cluster_number = []\n",
    "global_cluster_selfsimilarity = []\n",
    "\n",
    "core_reproducibility_perc = 85 # change this to relax the threshold for detecting cores\n",
    "exec(open(\"./dynamical_analysis.py\").read())\n",
    "\n",
    "global_events_sec.append(events_sec)\n",
    "global_events_duration.extend(events_durations_f)\n",
    "global_cluster_number.append(nclusters)\n",
    "global_cluster_selfsimilarity.extend(reproducibility_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Mixing structural and dynamical analyses results to characterize core connectivity\n",
    "\n",
    "Here, we collect the evidence contrasting the hypothesis that core neurons are strongly connected.   \n",
    "We tested two fundamental attractor-driven assumptions:\n",
    "- synapses between cores are more numerous and stronger compared to others   \n",
    "- circuits made by cores involve more recursive connections toward cores\n",
    "\n",
    "### Spine number and volume (panel 2A, 2B)\n",
    "\n",
    "We can take the **number** (2A) and **volume** (2B) of post-synaptic spines as proxy for their functional efficacy.   \n",
    "The number of cores and non-cores for each cluster is different. Therefore we have to normalize this count to evaluate.\n",
    "\n",
    "For each set of reproducible cluster we count:    \n",
    "- the number of synapses made by a cell type (core or not) towards others, weighted by the squared number of target cells    \n",
    "    - the expectation is that core-to-core and core-to-other synapses should be numerous in order to pull the dynamics\n",
    "- the post-synaptic spine volume of synapses made by a cell type (core or not) towards others.   \n",
    "    - the expectation is that core-to-core and core-to-other spines should be larger in order to pull the dynamics\n",
    "\n",
    "**Synapses between core neurons of each cluster are less than every other combination.**    \n",
    "Note that the resulting normalized synapse counts (for the others) check with the network density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the density of the directed graph.\n",
    "network_density = dgraph.density(loops=True)\n",
    "print(\"... network density (ratio between the edges present and the maximum number of edges that the graph can contain):\", network_density )\n",
    "# spine number\n",
    "core2core_spine_num = 0.0 # to be normalized\n",
    "core2other_spine_num = 0.0\n",
    "other2core_spine_num = 0.0\n",
    "other2other_spine_num = 0.0\n",
    "# spine volume\n",
    "core2core_spine_vol = [] # µm3\n",
    "core2other_spine_vol = []\n",
    "other2core_spine_vol = []\n",
    "other2other_spine_vol = []\n",
    "\n",
    "set_ids = set(ophys_cell_ids)\n",
    "for dyn_core_ids in clusters_cores:\n",
    "    dyn_other_ids = set_ids.symmetric_difference(dyn_core_ids)\n",
    "\n",
    "    # id, pre_root_id, post_root_id, cleft_vx, spine_vol_um3\n",
    "    core2core_synapse_df = syn_spines_df.query(f'(pre_root_id in {list(dyn_core_ids)}) and (post_root_id in {list(dyn_core_ids)})')\n",
    "    if not core2core_synapse_df.empty:\n",
    "        core2core_spine_vol.extend( core2core_synapse_df['spine_vol_um3'].tolist() )\n",
    "        core2core_spine_num += len(core2core_synapse_df['spine_vol_um3'].tolist())/(len(dyn_core_ids)*len(dyn_core_ids)) # normalized by target\n",
    "    \n",
    "    core2other_synapse_df = syn_spines_df.query(f'(pre_root_id in {list(dyn_core_ids)}) and (post_root_id in {list(dyn_other_ids)})')\n",
    "    if not core2other_synapse_df.empty:\n",
    "        core2other_spine_vol.extend( core2other_synapse_df['spine_vol_um3'].tolist() )\n",
    "        core2other_spine_num += len(core2other_synapse_df['spine_vol_um3'].tolist())/(len(dyn_core_ids)*len(dyn_other_ids)) \n",
    "    \n",
    "    other2core_synapse_df = syn_spines_df.query(f'(pre_root_id in {list(dyn_other_ids)}) and (post_root_id in {list(dyn_core_ids)})')\n",
    "    if not other2core_synapse_df.empty:\n",
    "        other2core_spine_vol.extend( other2core_synapse_df['spine_vol_um3'].tolist() )\n",
    "        other2core_spine_num += len(other2core_synapse_df['spine_vol_um3'].tolist())/(len(dyn_core_ids)*len(dyn_other_ids)) \n",
    " \n",
    "    other2other_synapse_df = syn_spines_df.query(f'(pre_root_id in {list(dyn_other_ids)}) and (post_root_id in {list(dyn_other_ids)})')\n",
    "    if not other2other_synapse_df.empty:\n",
    "        other2other_spine_vol.extend( other2other_synapse_df['spine_vol_um3'].tolist() )\n",
    "        other2other_spine_num += len(other2other_synapse_df['spine_vol_um3'].tolist())/(len(dyn_other_ids)*len(dyn_other_ids)) \n",
    "\n",
    "# description\n",
    "# number\n",
    "print(\"... Normalized number of spines\")\n",
    "print(\"    {:f} core2core normalized spines number\".format((core2core_spine_num)) )\n",
    "print(\"    {:f} core2other normalized spines number\".format((core2other_spine_num)) )\n",
    "print(\"    {:f} other2core normalized spines number\".format((other2core_spine_num)) )\n",
    "print(\"    {:f} other2other normalized spines number\".format((other2other_spine_num)) )\n",
    "\n",
    "# spines\n",
    "print(\"... Spine volumes\")\n",
    "print(\"    {:d} core2core spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(core2core_spine_vol), np.mean(core2core_spine_vol),np.std(core2core_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(core2core_spine_vol)) )\n",
    "print(\"    {:d} core2other spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(core2other_spine_vol), np.mean(core2other_spine_vol),np.std(core2other_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(core2other_spine_vol)) )\n",
    "print(\"    {:d} other2core spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(other2core_spine_vol), np.mean(other2core_spine_vol),np.std(other2core_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(other2core_spine_vol)) )\n",
    "print(\"    {:d} other2other spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(other2other_spine_vol), np.mean(other2other_spine_vol),np.std(other2other_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(other2other_spine_vol)) )\n",
    "\n",
    "# plotting\n",
    "# all spine number by type\n",
    "x = np.array([\"core-core\", \"core-other\", \"other-core\", \"other-other\"])\n",
    "y = np.array([core2core_spine_num, core2other_spine_num, other2core_spine_num, other2other_spine_num])\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x, y, color=['forestgreen','forestgreen','silver','silver'])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Normalized number of spines')\n",
    "fig.savefig(exp_path+'/results/global_cores_others_spine_num.svg', transparent=True)\n",
    "fig.clf()\n",
    "plt.close()\n",
    "\n",
    "# all spine volumes by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(0, 0.04, len(core2other_spine_vol))\n",
    "plt.scatter(xs, core2other_spine_vol, edgecolor='forestgreen', facecolor=('#228B224d'))\n",
    "xs = np.random.normal(1, 0.04, len(other2core_spine_vol))\n",
    "plt.scatter(xs, other2core_spine_vol, edgecolor='silver', facecolor=('#D3D3D34d'))\n",
    "xs = np.random.normal(2, 0.04, len(other2other_spine_vol))\n",
    "plt.scatter(xs, other2other_spine_vol, edgecolor='silver', facecolor=('#D3D3D34d'))\n",
    "vp = ax.violinplot([core2other_spine_vol,other2core_spine_vol,other2other_spine_vol], [0,1,2], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc in vp['bodies'][0:1]:\n",
    "    pc.set_facecolor('#228B224d')\n",
    "for pc in vp['bodies'][1:]:\n",
    "    pc.set_facecolor('#D3D3D34d')\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Spine Volume (µm^3)')\n",
    "plt.xticks([0, 1, 2], [ \"core-other\\n(n={:d})\".format(len(core2other_spine_vol)),\"other-core\\n(n={:d})\".format(len(other2core_spine_vol)),\"other-other\\n(n={:d})\".format(len(other2other_spine_vol))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_spine_vol.svg', transparent=True)\n",
    "fig.savefig(exp_path+'/results/global_cores_others_spine_vol.png', transparent=True, dpi=1200)\n",
    "fig.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Ca-imaged and outside EM volume inputs (panel 2B, last two boxes)\n",
    "\n",
    "Core responses could be due to non-imaged and outside volume sources. How can we rule this out (or reduce our lack of knowledge)?   \n",
    "We can ask *Are there more or stronger spines made by non-imaged neurons (either local or far) on cores or others?*   \n",
    "We have this information since we know the cell ID of all somas in the volume. We can take the spines having presynaptic ID different from the known Ca-imaged IDs or different from the somas within the EM volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"... postsynaptic spines on cores or others from sources non-imaged or without soma in the volume\")\n",
    "far2core_spine_vol = [] # µm3\n",
    "far2other_spine_vol = []\n",
    "set_ids = set(ophys_cell_ids)\n",
    "for dyn_core_ids in clusters_cores:\n",
    "    dyn_other_ids = set_ids.symmetric_difference(dyn_core_ids)\n",
    "    # searching\n",
    "    # id, pre_root_id, post_root_id, cleft_vx, spine_vol_um3\n",
    "    far2core_synapse_df = syn_spines_df.query(f'(pre_root_id not in {list(set_ids)}) and (post_root_id in {list(dyn_core_ids)})')\n",
    "    if not far2core_synapse_df.empty:\n",
    "        far2core_spine_vol.extend( far2core_synapse_df['spine_vol_um3'].tolist() )\n",
    "    far2other_synapse_df = syn_spines_df.query(f'(pre_root_id not in {list(set_ids)}) and (post_root_id in {list(dyn_other_ids)})')\n",
    "    if not far2other_synapse_df.empty:\n",
    "        far2other_spine_vol.extend( far2other_synapse_df['spine_vol_um3'].tolist() )\n",
    "        \n",
    "# description\n",
    "print(\"    {:d} far2core spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(far2core_spine_vol), np.mean(far2core_spine_vol),np.std(far2core_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(far2core_spine_vol)) )\n",
    "print(\"    {:d} far2other spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(far2other_spine_vol), np.mean(far2other_spine_vol),np.std(far2other_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(far2other_spine_vol)) )\n",
    "\n",
    "# significativity\n",
    "kwstat,pval = stats.kruskal(far2core_spine_vol, far2other_spine_vol)\n",
    "print(\"    far-core vs far-other spine size Kruskal-Wallis test results:\",kwstat,pval)\n",
    "if len(far2core_spine_vol)>0 and len(far2other_spine_vol)>0:\n",
    "    d,_ = stats.ks_2samp(far2core_spine_vol, far2other_spine_vol) # non-parametric measure of effect size [0,1]\n",
    "    print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "# all spine volumes by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(far2core_spine_vol))\n",
    "plt.scatter(xs, far2core_spine_vol, edgecolor='forestgreen', facecolor=('#228B224d'))\n",
    "xs = np.random.normal(2, 0.04, len(far2other_spine_vol))\n",
    "plt.scatter(xs, far2other_spine_vol, edgecolor='silver', facecolor=('#D3D3D34d'))\n",
    "vp = ax.violinplot([far2core_spine_vol,far2other_spine_vol], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Spine Volume (µm^3)')\n",
    "plt.xticks([1, 2], [\"far-core\\n(n={:d})\".format(len(far2core_spine_vol)), \"far-other\\n(n={:d})\".format(len(far2other_spine_vol))])\n",
    "fig.savefig(exp_path+'/results/global_far_cores_others_spine_vol.svg', transparent=True)\n",
    "fig.savefig(exp_path+'/results/global_far_cores_others_spine_vol.png', transparent=True, dpi=1200)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are core more mutually connected than others?\n",
    "\n",
    "We started by asking whether a global measure such as assortativity - - gives a clear summary of mutuality between all cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgraph.vs[\"ophys_cell_id\"] = ophys_cell_ids\n",
    "is_id_core = np.array( [0] * len(ophys_cell_ids) )\n",
    "is_id_core[core_indexes] = 1\n",
    "dgraph.vs[\"is_core\"] = is_id_core.tolist()\n",
    "pyc_ca_syn_df = syn_df.query(f'(pre_root_id in {ophys_cell_ids}) and (post_root_id in {ophys_cell_ids})')\n",
    "is_syn_core = np.array( [0] * len(pyc_ca_syn_df) )\n",
    "for cid in [item for sublist in clusters_cores for item in sublist]:\n",
    "    is_syn_core[pyc_ca_syn_df['pre_root_id'] == cid] = 1\n",
    "dgraph.es[\"is_core\"] = is_syn_core.tolist()\n",
    "color_dict = {0: \"gray\", 1: \"green\"}\n",
    "ig.plot(dgraph, exp_path+'/results/all_ring.svg', layout=dgraph.layout(\"circle\"),\n",
    "        edge_curved=0.2,\n",
    "        edge_color=[color_dict[is_core] for is_core in dgraph.es[\"is_core\"]],\n",
    "        edge_width=0.5,\n",
    "        edge_arrow_size=0.1,\n",
    "        vertex_size=5,\n",
    "        vertex_color=[color_dict[is_core] for is_core in dgraph.vs[\"is_core\"]],\n",
    "        vertex_frame_color=[color_dict[is_core] for is_core in dgraph.vs[\"is_core\"]],\n",
    "        margin=50)\n",
    "\n",
    "print('... assortativity')\n",
    "# is a preference for a network's nodes to attach to others that are similar in some way\n",
    "print(\"    overall:\", dgraph.assortativity_nominal(\"is_core\", directed=True) )\n",
    "# cores degree distro vs others degree distro\n",
    "# biological networks typically show negative assortativity, or disassortative mixing, or disassortativity, as high degree nodes tend to attach to low degree nodes.\n",
    "print(\"    assortativity degree:\", dgraph.assortativity_degree(directed=True) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Motif connectivity of cores and others (panel 2D)\n",
    "\n",
    "This measure of the network reports the participation of cores (or non-cores) in triplet motifs.    \n",
    "Note that the triplets are not exclusively made of cores (or non-cores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each set of reproducible cluster cores we count their connectivity motifs.\n",
    "set_indexes = set(ophys_cell_indexes)\n",
    "for dyn_core_ids in clusters_cores:\n",
    "    dyn_core_indexes = set([ophys_cell_ids.index(strid) for strid in dyn_core_ids])\n",
    "    dyn_other_indexes = set_indexes.symmetric_difference(dyn_core_indexes)\n",
    "    for mclass, mlist in motif_vertices.items():\n",
    "        for mtriplet in mlist:\n",
    "            intersection_cores = len(list(dyn_core_indexes.intersection(mtriplet)))\n",
    "            intersection_others = len(list(dyn_other_indexes.intersection(mtriplet)))\n",
    "            global_structural_motif_cores[mclass] += intersection_cores\n",
    "            global_structural_motif_others[mclass] += intersection_others\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.bar(global_structural_motif_cores.keys(), global_structural_motif_cores.values(), color='forestgreen')\n",
    "plt.ylabel('cores occurrences')\n",
    "plt.yscale('log')\n",
    "plt.ylim([0.7,plt.ylim()[1]])\n",
    "plt.xlabel('motifs types')\n",
    "fig.savefig(exp_path+'/results/global_motifs_cores.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clear()\n",
    "fig.clf()\n",
    "fig = plt.figure()\n",
    "plt.bar(global_structural_motif_others.keys(), global_structural_motif_others.values(), color='silver')\n",
    "plt.ylabel('non-cores occurrences')\n",
    "plt.yscale('log')\n",
    "plt.ylim([0.7,plt.ylim()[1]])\n",
    "plt.xlabel('motifs types')\n",
    "fig.savefig(exp_path+'/results/global_motifs_others.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clear()\n",
    "fig.clf()\n",
    "print(\"... saved mutual connectivity of cores and others\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dgraph is already defined from the structural_analysis included file\n",
    "print(\"    graph diameter (#vertices):\", dgraph.diameter(directed=True, unconn=True, weights=None))\n",
    "print(\"    graph average path length (#vertices):\", dgraph.average_path_length(directed=True, unconn=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Do the cores of each cluster form a clique? (panel E)\n",
    "\n",
    "If the cores of each cluster are pattern completion units, they should participate in more cliques (set of vertices where an edge is present between any two of them) than other non-core neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliques = dgraph.cliques(min=2)\n",
    "\n",
    "cliques_cores = []\n",
    "cliques_others = []\n",
    "\n",
    "for cluster_cids in clustered_spectrums:\n",
    "    cluster_core_indices = []\n",
    "    # we take the index of the cell participating in this cluster\n",
    "    cluster_indices = [ophys_cell_ids.index(strid) for strid in cluster_cids]\n",
    "    # we take the cores of this cluster\n",
    "    cluster_core_indices = list(set(core_indexes).intersection(cluster_indices))\n",
    "    cluster_other_indices = list(set(other_indexes).intersection(cluster_indices))\n",
    "    # we take the edges between the cores\n",
    "    for clique in cliques:\n",
    "        if set(clique).issubset(cluster_core_indices):\n",
    "            cliques_cores.append(clique)\n",
    "        if set(clique).issubset(cluster_other_indices):\n",
    "            cliques_others.append(clique)\n",
    "\n",
    "cores_cliques_count = len(cliques_cores)\n",
    "others_cliques_count = len(cliques_others)\n",
    "\n",
    "print(\"    cliques made by cores:\",cores_cliques_count)\n",
    "print(\"    cliques made by others:\",others_cliques_count)\n",
    "\n",
    "# print(core_edges)\n",
    "x = np.array([\"cores\", \"others\"])\n",
    "y = np.array([cores_cliques_count, others_cliques_count])\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x, y, color=['forestgreen','silver'])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Count of cliques')\n",
    "plt.xticks([0, 1], [\"core\\n(n={:d})\".format(cores_cliques_count), \"other\\n(n={:d})\".format(others_cliques_count)])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_cliques.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality of cores\n",
    "\n",
    "If cores are not more mutually connected compared to others, then what is their characterizing feature?    \n",
    "In the cells above, we saw indications of more interconnections between cores and others than within the same type.     \n",
    "This could hint at some form of centrality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The simple measures of centrality of cores are not different from others (panel 2F)\n",
    "\n",
    "But the pagerank centrality is a generalization of degree centrality. Simple degree centrality measures the number of direct neighbors, while pagerank centrality measures the number of all nodes that can be connected through a path, with the contributions of distant nodes penalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('... degree centrality')\n",
    "degree_centrality_cores = dgraph.degree(core_indexes, mode='out', loops=True)\n",
    "degree_centrality_others = dgraph.degree(other_indexes, mode='out', loops=True)\n",
    "# description\n",
    "print(\"    cores: \"+str(stats.describe(degree_centrality_cores)) )\n",
    "print(\"    others: \"+str(stats.describe(degree_centrality_others)) )\n",
    "# significativity\n",
    "print(\"    Welch t test:  %.3f p= %.3f\" % stats.ttest_ind(degree_centrality_cores, degree_centrality_others, equal_var=False))\n",
    "d,_ = stats.ks_2samp(degree_centrality_cores, degree_centrality_others) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(degree_centrality_cores))\n",
    "plt.scatter(xs, degree_centrality_cores, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(degree_centrality_others))\n",
    "plt.scatter(xs, degree_centrality_others, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([degree_centrality_cores,degree_centrality_others], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Degree')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(degree_centrality_cores)), \"other\\n(n={:d})\".format(len(degree_centrality_others))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_degree.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Betweenness of cores and others (panel 2G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('... betweenness')\n",
    "cores_betweenness = np.array(dgraph.betweenness(vertices=core_indexes, directed=True))\n",
    "others_betweenness = np.array(dgraph.betweenness(vertices=other_indexes, directed=True))\n",
    "print(\"    cores: \"+str(stats.describe(cores_betweenness)) )\n",
    "print(\"    others: \"+str(stats.describe(others_betweenness)) )\n",
    "# significativity\n",
    "print(\"    Welch t test:  %.3f p= %.3f\" % stats.ttest_ind(cores_betweenness, others_betweenness, equal_var=False))\n",
    "d,_ = stats.ks_2samp(cores_betweenness, others_betweenness) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(cores_betweenness))\n",
    "plt.scatter(xs, cores_betweenness, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(others_betweenness))\n",
    "plt.scatter(xs, others_betweenness, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([cores_betweenness,others_betweenness], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Betweenness')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(cores_betweenness)), \"other\\n(n={:d})\".format(len(others_betweenness))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_betweenness.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hub scores of cores and others (panel 2H)\n",
    "\n",
    "Are the cores also hubs of the network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"... hub score\")\n",
    "# what is the overlap of cores and hubs?\n",
    "# Hub\n",
    "hub_scores = np.array(dgraph.hub_score(weights=None, scale=True, return_eigenvalue=False))\n",
    "hub_scores_cores = hub_scores[core_indexes]\n",
    "hub_scores_others = hub_scores[other_indexes]\n",
    "print(\"    hub cores: \"+str(stats.describe(hub_scores_cores)) )\n",
    "print(\"    hub others: \"+str(stats.describe(hub_scores_others)) )\n",
    "# significativity\n",
    "print(\"    Kruskal-Wallis test:  %.3f p= %.3f\" % stats.ttest_ind(hub_scores_cores, hub_scores_others))\n",
    "d,_ = stats.ks_2samp(hub_scores_cores, hub_scores_others) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "# all eccentricity by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(hub_scores_cores))\n",
    "plt.scatter(xs, hub_scores_cores, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(hub_scores_others))\n",
    "plt.scatter(xs, hub_scores_others, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([hub_scores_cores,hub_scores_others], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Hub score')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(hub_scores_cores)), \"other\\n(n={:d})\".format(len(hub_scores_others))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_hub_score.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cores control the flow of cortical activity\n",
    "\n",
    "So far, we used structural (graph) measures of neurons selected by looking at their reproducibility (a form of regular activity). In a sense, we were already crossing structural and dynamical information about the network.    \n",
    "\n",
    "However, we could push this further.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structural underpinnings of clusters (panel 2XXX)\n",
    "\n",
    "What is the origin of pattern reproducibility?    \n",
    "We can look at the underlying connectivity structure. \n",
    "\n",
    "Given a state in which a certain cell fires, we should be able to predict which cell will fire next based on the connectivity graph, e.g. the most frequent (shortest or simple) path, or max flow (assigning a capacity proportional to the spine volume).   \n",
    "\n",
    "Take the full list of cells, with the full list of synapses and spine volumes. \n",
    "For each event, compute (a combination of) the max flow (considering spine volumes as weights), and number of shortest paths, between the current state (reduced to just one cid, if possible) and the next state (just one cid).    \n",
    "Do we get a good prediction?    \n",
    "Do core neurons have more shortest paths leading to them compared to others? (If yes, this can be also quantified using pagerank. It already works).\n",
    "\n",
    "Another way will be to look at the min cuts of the flow. It already works.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... cluster pathways\n",
      "\n",
      "\n",
      "#ff5f30 [[107, 35, 39, 41, 94], [94, 39, 42, 45, 13, 29, 41, 21, 92, 35], [35, 74, 10, 94, 31], [86, 39, 21, 53, 18, 94, 35, 10]]\n",
      "107 35 648518346349537741 648518346349539862\n",
      "Graph flow (68 edges, 41 vs 40 vertices, value=7.1815)\n",
      "7.181497876857552\n",
      "64 27 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 27, {'name': 6.485183463495313e+17, 'is_core': 0})\n",
      "64 69 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 69, {'name': 6.485183463495384e+17, 'is_core': 0})\n",
      "64 75 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 75, {'name': 6.485183463495395e+17, 'is_core': 0})\n",
      "64 75 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 75, {'name': 6.485183463495395e+17, 'is_core': 0})\n",
      "64 75 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 75, {'name': 6.485183463495395e+17, 'is_core': 0})\n",
      "64 69 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 69, {'name': 6.485183463495384e+17, 'is_core': 0})\n",
      "64 80 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 80, {'name': 6.485183463495401e+17, 'is_core': 0})\n",
      "64 73 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 73, {'name': 6.485183463495391e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 76 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 76, {'name': 6.485183463495396e+17, 'is_core': 0})\n",
      "64 67 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 67, {'name': 6.485183463495382e+17, 'is_core': 0})\n",
      "64 66 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 66, {'name': 6.48518346349538e+17, 'is_core': 0})\n",
      "64 38 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 38, {'name': 6.485183463495333e+17, 'is_core': 0})\n",
      "64 67 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 67, {'name': 6.485183463495382e+17, 'is_core': 0})\n",
      "64 66 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 66, {'name': 6.48518346349538e+17, 'is_core': 0})\n",
      "64 66 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 66, {'name': 6.48518346349538e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 36 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 36, {'name': 6.48518346349533e+17, 'is_core': 0})\n",
      "64 37 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 37, {'name': 6.485183463495332e+17, 'is_core': 0})\n",
      "64 65 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 65, {'name': 6.485183463495379e+17, 'is_core': 0})\n",
      "64 65 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 65, {'name': 6.485183463495379e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 68 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 68, {'name': 6.485183463495383e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 68 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 68, {'name': 6.485183463495383e+17, 'is_core': 0})\n",
      "64 66 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 66, {'name': 6.48518346349538e+17, 'is_core': 0})\n",
      "64 66 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 66, {'name': 6.48518346349538e+17, 'is_core': 0})\n",
      "64 63 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 63, {'name': 6.485183463495377e+17, 'is_core': 0})\n",
      "64 63 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 63, {'name': 6.485183463495377e+17, 'is_core': 0})\n",
      "64 74 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 74, {'name': 6.485183463495393e+17, 'is_core': 0})\n",
      "64 73 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 73, {'name': 6.485183463495391e+17, 'is_core': 0})\n",
      "64 69 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 69, {'name': 6.485183463495384e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 65 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 65, {'name': 6.485183463495379e+17, 'is_core': 0})\n",
      "64 69 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 69, {'name': 6.485183463495384e+17, 'is_core': 0})\n",
      "64 69 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 69, {'name': 6.485183463495384e+17, 'is_core': 0})\n",
      "64 71 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 71, {'name': 6.485183463495387e+17, 'is_core': 0})\n",
      "64 69 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 69, {'name': 6.485183463495384e+17, 'is_core': 0})\n",
      "64 69 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 69, {'name': 6.485183463495384e+17, 'is_core': 0})\n",
      "64 77 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 77, {'name': 6.485183463495397e+17, 'is_core': 0})\n",
      "64 3 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 3, {'name': 6.485183463494927e+17, 'is_core': 0})\n",
      "64 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "64 79 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 79, {'name': 6.4851834634954e+17, 'is_core': 1})\n",
      "64 63 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 63, {'name': 6.485183463495377e+17, 'is_core': 0})\n",
      "64 73 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 73, {'name': 6.485183463495391e+17, 'is_core': 0})\n",
      "64 67 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 67, {'name': 6.485183463495382e+17, 'is_core': 0})\n",
      "64 62 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 62, {'name': 6.485183463495375e+17, 'is_core': 0})\n",
      "64 76 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 76, {'name': 6.485183463495396e+17, 'is_core': 0})\n",
      "64 67 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 67, {'name': 6.485183463495382e+17, 'is_core': 0})\n",
      "64 67 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 67, {'name': 6.485183463495382e+17, 'is_core': 0})\n",
      "64 67 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 67, {'name': 6.485183463495382e+17, 'is_core': 0})\n",
      "64 45 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 45, {'name': 6.485183463495348e+17, 'is_core': 0})\n",
      "64 55 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 55, {'name': 6.485183463495366e+17, 'is_core': 0})\n",
      "64 76 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 76, {'name': 6.485183463495396e+17, 'is_core': 0})\n",
      "64 75 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 75, {'name': 6.485183463495395e+17, 'is_core': 0})\n",
      "64 73 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 73, {'name': 6.485183463495391e+17, 'is_core': 0})\n",
      "64 68 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 68, {'name': 6.485183463495383e+17, 'is_core': 0})\n",
      "64 56 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 56, {'name': 6.485183463495368e+17, 'is_core': 0})\n",
      "64 56 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 56, {'name': 6.485183463495368e+17, 'is_core': 0})\n",
      "64 69 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 69, {'name': 6.485183463495384e+17, 'is_core': 0})\n",
      "\n",
      "#3c68f9 [[8, 5, 50, 9, 43, 47, 81], [81, 111, 10, 8, 50, 47], [81, 99, 65, 8, 51, 36, 63, 15, 20]]\n",
      "8 5 648518346349539852 648518346349492682\n",
      "Graph flow (3 edges, 80 vs 1 vertices, value=0.1775)\n",
      "0.1774612022459326\n",
      "63 3 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 3, {'name': 6.485183463494927e+17, 'is_core': 0})\n",
      "64 3 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 3, {'name': 6.485183463494927e+17, 'is_core': 0})\n",
      "76 3 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 3, {'name': 6.485183463494927e+17, 'is_core': 0})\n",
      "\n",
      "#68fcc1 [[5, 21, 24], [21, 22, 81, 95, 24, 30], [5, 21, 24, 83, 50, 51, 30], [24, 80, 21, 44]]\n",
      "5 21 648518346349492682 648518346349537487\n",
      "Graph flow (14 edges, 41 vs 40 vertices, value=1.2330)\n",
      "1.233024908650755\n",
      "3 80 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 80, {'name': 6.485183463495401e+17, 'is_core': 0})\n",
      "3 76 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 76, {'name': 6.485183463495396e+17, 'is_core': 0})\n",
      "3 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "3 75 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 75, {'name': 6.485183463495395e+17, 'is_core': 0})\n",
      "3 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "3 67 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 67, {'name': 6.485183463495382e+17, 'is_core': 0})\n",
      "3 64 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 64, {'name': 6.485183463495378e+17, 'is_core': 0})\n",
      "3 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "3 78 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 78, {'name': 6.485183463495398e+17, 'is_core': 0})\n",
      "3 73 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 73, {'name': 6.485183463495391e+17, 'is_core': 0})\n",
      "3 62 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 62, {'name': 6.485183463495375e+17, 'is_core': 0})\n",
      "3 62 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 62, {'name': 6.485183463495375e+17, 'is_core': 0})\n",
      "3 75 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 75, {'name': 6.485183463495395e+17, 'is_core': 0})\n",
      "3 63 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 63, {'name': 6.485183463495377e+17, 'is_core': 0})\n",
      "\n",
      "#ff964f [[17, 15, 20, 91, 41, 4, 0, 92, 51], [4, 9, 105, 0, 20, 79, 91, 92, 89, 14, 46, 72, 15], [4, 105, 92, 71, 79, 94, 17, 90, 9, 20, 64, 15, 77]]\n",
      "17 15 648518346349539840 648518346349537153\n",
      "Graph flow (19 edges, 80 vs 1 vertices, value=2.1015)\n",
      "2.101494680017182\n",
      "65 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "78 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "80 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "76 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "78 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "78 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "40 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "43 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "35 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "63 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "73 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "55 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "69 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "62 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "71 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "37 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "61 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "40 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "35 59 igraph.Vertex(<igraph.Graph object at 0x7f362a1867a0>, 59, {'name': 6.485183463495372e+17, 'is_core': 0})\n",
      "\n",
      "#9cfba4 [[93, 92], [16, 93, 71, 92, 73], [16, 92, 93, 32, 42, 101], [92, 93, 100]]\n",
      "93 92 648518346349534945 648518346349532050\n",
      "Graph flow (0 edges, 39 vs 42 vertices, value=0.0000)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# print(syn_spines_df.shape)\n",
    "# print(syn_spines_df.columns)\n",
    "# print(syn_spines_df.head())\n",
    "\n",
    "pre_root_ids = syn_spines_df.pre_root_id.unique().tolist()\n",
    "# print(\"pre_root_ids\",len(pre_root_ids))\n",
    "post_root_ids = syn_spines_df.post_root_id.unique().tolist()\n",
    "# print(\"post_root_ids\",len(post_root_ids))\n",
    "\n",
    "# print(\"intersections pre post\")\n",
    "# print( len(list(set(pre_root_ids).intersection(post_root_ids))) )\n",
    "# print( len(list(set(post_root_ids).intersection(pre_root_ids))) )\n",
    "# # so, post_root_ids contain all others\n",
    "\n",
    "# print(\"intersections ophys pre post\")\n",
    "# print( len(list(set(ophys_cell_ids).intersection(post_root_ids))) )\n",
    "# print( len(list(set(ophys_cell_ids).intersection(pre_root_ids))) )\n",
    "\n",
    "# creating a larger graph containing all synapses with measured spines \n",
    "# def index_from_postid(row):\n",
    "#     if row['post_root_id'] in ophys_cell_ids:\n",
    "#         return ophys_cell_ids.index(row['post_root_id'])\n",
    "#     else:\n",
    "#         return post_root_ids.index(row['post_root_id'])+1000\n",
    "# def index_from_preid(row):\n",
    "#     if row['pre_root_id'] in ophys_cell_ids:\n",
    "#         return ophys_cell_ids.index(row['pre_root_id'])\n",
    "#     else:\n",
    "#         return post_root_ids.index(row['pre_root_id'])+1000\n",
    "# # print(syn_spines_df.apply(lambda row: index_from_postid(row), axis=1))\n",
    "# syn_spines_df['source'] = syn_spines_df.apply(lambda row: index_from_preid(row), axis=1)\n",
    "# syn_spines_df['target'] = syn_spines_df.apply(lambda row: index_from_postid(row), axis=1)\n",
    "# print(syn_spines_df[[\"source\", \"pre_root_id\"]])\n",
    "# print(list(zip(ophys_cell_ids,list(ophys_cell_indexes))))\n",
    "# print(sorted(syn_spines_df.source.unique()))\n",
    "# print(sorted(syn_spines_df.target.unique()))\n",
    "# print(syn_spines_df.columns)\n",
    "\n",
    "spinesgraph = ig.Graph.DataFrame(syn_spines_df[[\"pre_root_id\", \"post_root_id\", \"spine_vol_um3\"]], directed=True)\n",
    "# plotting\n",
    "is_id_core = np.array( [0] * len(ophys_cell_ids) )\n",
    "is_id_core[core_indexes] = 1\n",
    "spinesgraph.vs[\"is_core\"] = is_id_core.tolist()\n",
    "color_dict = {0: \"gray\", 1: \"green\"}\n",
    "ig.plot(spinesgraph, exp_path+'/results/spines_ring.svg', layout=spinesgraph.layout(\"circle\"),\n",
    "        edge_curved=0.2,\n",
    "        edge_width = spinesgraph.es['spine_vol_um3'],\n",
    "        edge_arrow_size=0.1,\n",
    "        vertex_size=5,\n",
    "        vertex_color=[color_dict[is_core] for is_core in spinesgraph.vs[\"is_core\"]],\n",
    "        vertex_frame_color=[color_dict[is_core] for is_core in spinesgraph.vs[\"is_core\"]],\n",
    "        margin=50)\n",
    "# print(spinesgraph)\n",
    "\n",
    "# for each event in a cluster, take each cellindex as source and search the graph for the path to the next cell firing\n",
    "print(\"... cluster pathways\")\n",
    "# print(sorted_events_indexes)\n",
    "\n",
    "# we do not want the sorted_events_indexes... we want the id/idx in the temporal sequence\n",
    "\n",
    "for cluster_k,events_cellindexes in sorted_events_indexes.items():\n",
    "    print()\n",
    "    # level of sequence regularity\n",
    "    middle_paths = []\n",
    "    if cluster_k == 'gray':\n",
    "        continue\n",
    "    print(cluster_k,events_cellindexes)\n",
    "    for vnt in events_cellindexes:\n",
    "        for posi,vidj in enumerate(vnt[1:]):\n",
    "            vidi = vnt[posi]\n",
    "            \n",
    "            print(vidi, vidj, ophys_cell_ids[vidi],ophys_cell_ids[vidj])\n",
    "            \n",
    "            # Take the maximum flow between the source and target vertices\n",
    "            mfres = spinesgraph.maxflow(spinesgraph.vs.find(name=ophys_cell_ids[vidi]).index, spinesgraph.vs.find(name=ophys_cell_ids[vidj]).index, capacity='spine_vol_um3')\n",
    "            # returns a tuple containing the following: \n",
    "            # graph - the graph on which this flow is defined\n",
    "            # value - the value (capacity) of the maximum flow between the given vertices\n",
    "            # flow - the flow values on each edge. For directed graphs, this is simply a list where element i corresponds to the flow on edge i.\n",
    "            # cut - edge IDs in the minimal cut corresponding to the flow.\n",
    "            # partition - vertex IDs in the parts created after removing edges in the cut\n",
    "            # es - an edge selector restricted to the edges in the cut.\n",
    "            print(mfres)\n",
    "            print(mfres.value)\n",
    "            # print(mfres.flow)\n",
    "            # print(sum(mfres.flow))\n",
    "            \n",
    "            # Iterate over the edges identified by the flow.\n",
    "            # count the edges sourcing from cores, and those targeting cores. Which is more?\n",
    "            for edge in mfres.es:\n",
    "                print(edge.source, edge.target, spinesgraph.vs[edge.target])\n",
    "\n",
    "            \n",
    "            \n",
    "            break\n",
    "        break\n",
    "        \n",
    "            # spaths = spinesgraph.get_all_shortest_paths(spinesgraph.vs.find(name=ophys_cell_ids[vidi]), to=spinesgraph.vs.find(name=ophys_cell_ids[vidj]), mode='out')\n",
    "            # spaths = spinesgraph.get_all_simple_paths(spinesgraph.vs.find(name=ophys_cell_ids[vidi]), spinesgraph.vs.find(name=ophys_cell_ids[vidj]), mode='out')\n",
    "            # print(spaths)\n",
    "\n",
    "            # for spts in spaths:\n",
    "            #     # print(spts, spts[1:-1])\n",
    "            #     middle_paths.extend(spts[1:-1])\n",
    "\n",
    "# print(middle_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow of cores vs others (panel 2J)\n",
    "\n",
    "To understand how core centrality could affect population events, we considered the flow – number and identity of connections to cut to interrupt the circuit between the first and the last firing neuron of each population event (e.g. the subgraphs made by neurons active in the events depicted in Fig. 1E). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('... flow between beginning and end of event cells')\n",
    "# Flow\n",
    "# Returns all the cuts between the source and target vertices in a directed graph.\n",
    "# This function lists all edge-cuts between a source and a target vertex. Every cut is listed exactly once.\n",
    "core_edges = []\n",
    "other_edges = []\n",
    "for sts,stscol in zip(source_target_cidx,source_target_color):\n",
    "    cuts = dgraph.all_st_cuts(source=sts[0], target=sts[1])\n",
    "    for cut in cuts:\n",
    "        for edge in cut.es:\n",
    "            source_vertex_id = edge.source\n",
    "            target_vertex_id = edge.target\n",
    "            if source_vertex_id in core_indexes:\n",
    "                core_edges.append(source_vertex_id)\n",
    "            elif target_vertex_id in core_indexes:\n",
    "                core_edges.append(target_vertex_id)\n",
    "            else:\n",
    "                other_edges.append(source_vertex_id)\n",
    "                other_edges.append(target_vertex_id)\n",
    "# clusters_cores_by_color\n",
    "cores_edges_count = sum(np.unique(core_edges, return_counts=True)[1])\n",
    "others_edges_count = sum(np.unique(other_edges, return_counts=True)[1])\n",
    "print(\"    cores in the edges removed to stop the flow:\",cores_edges_count)\n",
    "print(\"    others in the edges removed to stop the flow:\",others_edges_count)\n",
    "\n",
    "# print(core_edges)\n",
    "x = np.array([\"cores\", \"others\"])\n",
    "y = np.array([cores_edges_count, others_edges_count])\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x, y, color=['forestgreen','silver'])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Count of cutting-flow edges')\n",
    "plt.xticks([0, 1], [\"core\\n(n={:d})\".format(cores_edges_count), \"other\\n(n={:d})\".format(others_edges_count)])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_flow.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cores are crossroads of multiple paths\n",
    "\n",
    "If cores are more often than others part of the paths, it means that they might not be central by virtue of their degree, but by how many event trajectory path (not just any path as in the betweenness, or hubness) pass through them.     \n",
    "Their **pagerank** is a closer approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('... PageRank centrality')\n",
    "pagerank_cores = np.array(dgraph.personalized_pagerank(vertices=core_indexes, directed=True, damping=0.85, reset=\"is_core\"))\n",
    "pagerank_others = np.array(dgraph.personalized_pagerank(vertices=other_indexes, directed=True, damping=0.85, reset=\"is_core\"))\n",
    "# description\n",
    "print(\"    cores: \"+str(stats.describe(pagerank_cores)) )\n",
    "print(\"    others: \"+str(stats.describe(pagerank_others)) )\n",
    "# significativity\n",
    "print(\"    Welch t test:  %.3f p= %.3f\" % stats.kruskal(pagerank_cores, pagerank_others))\n",
    "d,_ = stats.ks_2samp(pagerank_cores, pagerank_others) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(pagerank_cores))\n",
    "plt.scatter(xs, pagerank_cores, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(pagerank_others))\n",
    "plt.scatter(xs, pagerank_others, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([pagerank_cores,pagerank_others], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Degree')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(pagerank_cores)), \"other\\n(n={:d})\".format(len(pagerank_others))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_pagerank.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Supplementary figure 3\n",
    "   \n",
    "To have keep cores within the attractor framework, cores activity could be sustained by indirect synaptic feedback, through highly connected secondary paths.   \n",
    "To back up the attractor idea, one would expect that core neurons would have shorter paths or cycles, compared to others. \n",
    "\n",
    "### Shortest paths of cores and others (panel S3A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"... number of paths in a complete graph of the same size:\", (np.math.factorial(112-2)*np.e))\n",
    "print('... number of shortest paths between cores')\n",
    "core_shortestpaths = []\n",
    "for coreidx in core_indexes:\n",
    "    othercores = list(core_indexes)\n",
    "    othercores.remove(coreidx)\n",
    "    shrtpth = dgraph.get_shortest_paths(coreidx, to=othercores, weights=None, mode='out', output='vpath')\n",
    "    for strp in shrtpth:\n",
    "        core_shortestpaths.append(len(strp))\n",
    "other_shortestpaths = []\n",
    "for otheridx in other_indexes:\n",
    "    otherothers = list(other_indexes)\n",
    "    otherothers.remove(otheridx)\n",
    "    shrtpth = dgraph.get_shortest_paths(otheridx, to=otherothers, weights=None, mode='out', output='vpath')\n",
    "    for strp in shrtpth:\n",
    "        other_shortestpaths.append(len(strp))\n",
    "print(\"    cores shortest paths: \"+str(stats.describe(core_shortestpaths)) )\n",
    "print(\"    others shortest paths: \"+str(stats.describe(other_shortestpaths)) )\n",
    "print(\"    equal variances? \"+str(stats.levene(core_shortestpaths, other_shortestpaths)) )\n",
    "# significativity\n",
    "print(\"    Welch t test:  %.3f p= %.3f\" % stats.ttest_ind(core_shortestpaths, other_shortestpaths, equal_var=False))\n",
    "d,_ = stats.ks_2samp(core_shortestpaths, other_shortestpaths) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(core_shortestpaths))\n",
    "plt.scatter(xs, core_shortestpaths, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(other_shortestpaths))\n",
    "plt.scatter(xs, other_shortestpaths, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([core_shortestpaths,other_shortestpaths], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Shortest path length')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(core_shortestpaths)), \"other\\n(n={:d})\".format(len(other_shortestpaths))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_shortestpath.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycles between cores or others (panel S3B)\n",
    "\n",
    "Cycles are built starting from a core (or other) and iterating neighbors of different lenghts, where the last vertex is the starting one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('... cycles')\n",
    "# breadth first search of paths and unique cycles\n",
    "def get_cycles(adj, paths, maxlen):\n",
    "    # tracking the actual path length:\n",
    "    maxlen -= 1\n",
    "    nxt_paths = []\n",
    "    # iterating over all paths:\n",
    "    for path in paths['paths']:\n",
    "        # iterating neighbors of the last vertex in the path:\n",
    "        for nxt in adj[path[-1]]:\n",
    "            # attaching the next vertex to the path:\n",
    "            nxt_path = path + [nxt]\n",
    "            if path[0] == nxt and min(path) == nxt:\n",
    "                # the next vertex is the starting vertex, we found a cycle\n",
    "                # we keep the cycle only if the starting vertex has the\n",
    "                # lowest vertex id, to avoid having the same cycles\n",
    "                # more than once\n",
    "                paths['cycles'].append(nxt_path)\n",
    "                # if you don't need the starting vertex\n",
    "                # included at the end:\n",
    "                # paths$cycles <- c(paths$cycles, list(path))\n",
    "            elif nxt not in path:\n",
    "                # keep the path only if we don't create\n",
    "                # an internal cycle in the path\n",
    "                nxt_paths.append(nxt_path)\n",
    "    # paths grown by one step:\n",
    "    paths['paths'] = nxt_paths\n",
    "    if maxlen == 0:\n",
    "        # the final return when maximum search length reached\n",
    "        return paths\n",
    "    else:\n",
    "        # recursive return, to grow paths further\n",
    "        return get_cycles(adj, paths, maxlen)\n",
    "# Comparison of core based cycles vs other based cycles\n",
    "maxlen = 10 # the maximum length to limit computation time\n",
    "# creating an adjacency list\n",
    "adj = [[n.index for n in v.neighbors()] for v in dgraph.vs]\n",
    "# recursive search of cycles\n",
    "# for each core vertex as candidate starting point\n",
    "core_cycles = []\n",
    "for start in core_indexes:\n",
    "    core_cycles += get_cycles(adj,{'paths': [[start]], 'cycles': []}, maxlen)['cycles']\n",
    "print(\"    # core-based cycles:\", len(core_cycles) )\n",
    "# count the length of loops involving 1 core\n",
    "core_cycles_lens = [len(cycle) for cycle in core_cycles]\n",
    "print(\"    core-based cycles length: \"+str(stats.describe(core_cycles_lens)) )\n",
    "\n",
    "other_cycles = []\n",
    "for start in other_indexes:\n",
    "    other_cycles += get_cycles(adj,{'paths': [[start]], 'cycles': []}, maxlen)['cycles']\n",
    "print(\"    # other-based cycles:\", len(other_cycles) )\n",
    "# count the length of loops involving 1 core\n",
    "other_cycles_lens = [len(cycle) for cycle in other_cycles]\n",
    "print(\"    other-based cycles length: \"+str(stats.describe(other_cycles_lens)) )\n",
    "\n",
    "d,_ = stats.ks_2samp(core_cycles_lens, other_cycles_lens) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "# all cycles by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(core_cycles_lens))\n",
    "plt.scatter(xs, core_cycles_lens, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(other_cycles_lens))\n",
    "plt.scatter(xs, other_cycles_lens, alpha=0.3, c='silver')\n",
    "bp = ax.boxplot([core_cycles_lens,other_cycles_lens], notch=0, sym='', showcaps=False, zorder=10)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Cycles length')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(core_cycles_lens)), \"other\\n(n={:d})\".format(len(other_cycles_lens))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_cyclelens.png', transparent=True, dpi=1500)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters of events are not reproducible trajectories of the population dynamics\n",
    "\n",
    "Clusters of population events are found by correlating population vectors, which only retain the cell IDs while ignoring the time of firing.    \n",
    "We can consider also time.\n",
    "\n",
    "Each recorded frame (~67ms) is an instantaneous population state defined by all its cells (112 of them are known for their firing, the others are unkown).    \n",
    "A sequence of population states is a trajectory in the population dynamical state space.    \n",
    "In this space, clusters of reproducible population events are represented by reproducible trajectories. \n",
    "\n",
    "We can compare the event trajectories visited within a cluster by comparing their patterns.    \n",
    "Events are made by cells firing (often multiple times) during the event interval, so each sequence is a 2D submatrix of the population rasterplot. This gives a measure of trajectory reproducibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(cluster_events_spiketrains) # already expressed in integer (ms)\n",
    "\n",
    "print(\"... sequence internal consistency\")\n",
    "\n",
    "# cycle over clusters\n",
    "for cluster_k, events_cellindexes in sorted_events_indexes.items():\n",
    "    if cluster_k == 'gray':\n",
    "        continue\n",
    "    print()\n",
    "\n",
    "    # We want to compare the trajectories of this cluster.\n",
    "    # Trajectories should have same shape. We will subract them to get the difference (/num of events).\n",
    "    \n",
    "    # Finding the common-shape trajectory\n",
    "    # n is the maximal number of cells participating to events in this cluster\n",
    "    maxcells = max(events_cellindexes, key = lambda i: len(i))\n",
    "    # m is the largest interval between the first min spiketrain and the last max spiketrain of all events in the cluster\n",
    "    events_spiketrains = cluster_events_spiketrains[cluster_k]\n",
    "    # print(events_spiketrains)\n",
    "    maxinterval = 0 # \n",
    "    for evt_spktrains in events_spiketrains:\n",
    "        mint = np.amin([x for xs in evt_spktrains for x in xs]) # for cases of just one spiketinme in list\n",
    "        if isinstance(mint, list): mint = mint[0] # for cases of list\n",
    "        maxt = np.amax([x for xs in evt_spktrains for x in xs])\n",
    "        if isinstance(maxt, list): maxt = maxt[-1]\n",
    "        if maxt-mint > maxinterval:\n",
    "            maxinterval = maxt-mint\n",
    "    print(\"    common trajectory pattern with n cells:\", len(maxcells), \" and m intervals:\", maxinterval)\n",
    "    \n",
    "    # cluster trajectories, one per event, all same shape\n",
    "    cluster_trajectories = []\n",
    "    for evt_indexes,evt_spktrains in zip(events_cellindexes,events_spiketrains):\n",
    "        # create empty trajectory of shape n cell, m interval\n",
    "        trajectory = np.zeros((len(maxcells),maxinterval+1))\n",
    "        mint = np.amin([x for xs in evt_spktrains for x in xs]) # take local mintime to find the trajectory m index\n",
    "        if isinstance(mint, list): mint = mint[0] # for cases of just one spiketinme in list\n",
    "        for ncell,spktrain in enumerate(evt_spktrains):\n",
    "            trajectory[ncell][spktrain-mint] = 1\n",
    "        cluster_trajectories.append(trajectory)\n",
    "    \n",
    "    # correlation between trajectories\n",
    "    # very simple (probably too much) measure of trajectory correspondence\n",
    "    trajR = []\n",
    "    for itr,itrajectory in enumerate(cluster_trajectories):\n",
    "        for jtr,jtrajectory in enumerate(cluster_trajectories):\n",
    "            if itr!=jtr:\n",
    "                trajR.append( np.nanmean(np.corrcoef(itrajectory,jtrajectory)) )\n",
    "    print(\"    correlation across all trajectories: {:1.3f}±{:1.2f}\".format(np.mean(trajR),np.std(trajR)))\n",
    "\n",
    "    print(\"... searching for repeating sequences in the ordered firing of cell IDs\")\n",
    "    size = 2\n",
    "    # size = 3\n",
    "    cluster_sequences = [x for xs in events_cellindexes for x in xs]\n",
    "    # print(cluster_sequences)\n",
    "    windows = [\n",
    "        tuple(window)\n",
    "        for window in more_itertools.windowed(cluster_sequences, size)\n",
    "    ]\n",
    "    counter = collections.Counter(windows)\n",
    "    for window, count in counter.items():\n",
    "        if count > 1:\n",
    "            print(\"   \",window, count)\n",
    "            print(core_indexes)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
