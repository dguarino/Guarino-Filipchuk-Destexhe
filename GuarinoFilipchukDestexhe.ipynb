{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How-to: core neurons are crossroads of cortical dynamics \n",
    "\n",
    "Analysis code to reproduce all panels in figures 1 and 2 of the paper by Guarino, Filipchuk, Destexhe (2022)   \n",
    "preprint link: https://www.biorxiv.org/content/10.1101/2022.05.24.493230v2\n",
    "\n",
    "All this code is hosted on a github [repository](https://github.com/dguarino/Guarino-Filipchuk-Destexhe) (with a Zenodo DOI persistent identifier [here](https://zenodo.org)) and can be interactively executed here.  \n",
    "The repository also contains a copy of the required data files from the [MICrONS project phase1](https://www.microns-explorer.org/phase1) (freely available on the project website), to ease the setup on Binder. \n",
    "\n",
    "This notebook performs loading and selection of the MICrONS data, structural and dynamical analyses, and plots the results as in the paper panels.\n",
    "\n",
    "We divided the analysis code into:\n",
    "- `imports_functions.py` : performs the imports and definition of various helper functions.\n",
    "- `structural_analysis.py` : creates a graph from the connectivity matrix and computes several graph measures (using [igraph](https://igraph.org)).\n",
    "- `dynamical_analysis.py` : performs the same population event analysis as in [Filipchuk et al. 2022](https://www.biorxiv.org/content/10.1101/2021.08.31.458322v2) and then also extracts the core neurons of the events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "from builtins import exec\n",
    "exec(open(\"./imports_functions.py\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading curated data from MICrONS project phase 1\n",
    "\n",
    "The following code for data loading and selection is taken from   \n",
    "https://github.com/AllenInstitute/MicronsBinder/blob/master/notebooks/intro/MostSynapsesInAndOut.ipynb   \n",
    "https://github.com/AllenInstitute/MicronsBinder/blob/master/notebooks/vignette_analysis/function/structure_function_analysis.ipynb\n",
    "\n",
    "`Neurons.pkl` contains the `segment_id` for each pyramidal neuron in the EM volume.    \n",
    "`Soma.pkl` contains the soma position for all the cells in the EM volume.   \n",
    "`calcium_trace.pkl` contains the calcium imaging traces (including deconvolved spikes).    \n",
    "`soma_subgraph_synapses_spines_v185.csv` contains the list of synapses with root pre-/post-synaptic somas.\n",
    "\n",
    "**CAUTION: The cell below might take some time to load the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1961, 17)\n",
      "(3239275, 16)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"MICrONS_data/calcium_trace.pkl\"):\n",
    "    print(\"Downloading 2photon calcium traces ...\")\n",
    "    resp = wget.download(\"https://zenodo.org/record/5646567/files/calcium_trace.pkl?download=1\", \"MICrONS_data/calcium_trace.pkl\")\n",
    "    print(\"... Done: \"+resp)\n",
    "\n",
    "if not os.path.exists(\"MICrONS_data/pni_synapses_v185.csv\"):\n",
    "    print(\"Downloading Synapse table ...\")\n",
    "    resp = wget.download(\"https://zenodo.org/record/3710459/files/pni_synapses_v185.csv?download=1\", \"MICrONS_data/pni_synapses_v185.csv\")\n",
    "    print(\"... Done: \"+resp)\n",
    "\n",
    "if not os.path.exists(\"MICrONS_data/calcium_trace.pkl\"):\n",
    "    print(\"Downloading soma_subgraph_synapses_spines_v185 ...\")\n",
    "    resp = wget.download(\"https://zenodo.org/record/3710459/files/soma_subgraph_synapses_spines_v185.csv?download=1\", \"MICrONS_data/soma_subgraph_synapses_spines_v185.csv\")\n",
    "    print(\"... Done: \"+resp)\n",
    "\n",
    "with open(\"MICrONS_data/Neuron.pkl\", 'rb') as handle:\n",
    "    Neuron = pickle.load(handle)\n",
    "with open(\"MICrONS_data/Soma.pkl\", 'rb') as handle:\n",
    "    Soma = pickle.load(handle)\n",
    "if os.path.exists(\"MICrONS_data/calcium_trace.pkl\"):\n",
    "    calcium_trace = pd.read_pickle(\"MICrONS_data/calcium_trace.pkl\")\n",
    "# print(calcium_trace)\n",
    "\n",
    "syn_spines_df = pd.read_csv('MICrONS_data/soma_subgraph_synapses_spines_v185.csv')\n",
    "# id, pre_root_id, post_root_id, cleft_vx, spine_vol_um3\n",
    "print(syn_spines_df.shape)\n",
    "\n",
    "syn_df = pd.read_csv('MICrONS_data/pni_synapses_v185.csv')\n",
    "print(syn_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the IDs and number of recorded pyramidal neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyc_list = Neuron[\"segment_id\"]\n",
    "n_pyc = pyc_list.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the folder to which all results will be saved, and the frame duration (from the MICrONS docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = os.getcwd()\n",
    "frame_duration = 0.0674 # sec, 14.8313 frames per second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Accessing 2-photon Calcium imaging data subset\n",
    "\n",
    "We are interested in reading only the Ca-imaging data of the cells for which also the EM reconstruction is available.   \n",
    "\n",
    "##### CAUTION: next cell can take some time to load all calcium imaging data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pyramidal neurons recorded with 2-photon Calcium imaging:  112\n",
      "... producing spike rasterplot\n"
     ]
    }
   ],
   "source": [
    "print(\"Pyramidal neurons recorded with 2-photon Calcium imaging: \",len(calcium_trace))\n",
    "ophys_cell_ids = list(calcium_trace.keys())\n",
    "n_frames = len(calcium_trace[ophys_cell_ids[0]]['spike'])\n",
    "start_time = 200*frame_duration # 200 frames of blank screen\n",
    "stop_time = (200+n_frames)*frame_duration\n",
    "time = np.arange(start_time,stop_time,frame_duration)\n",
    "\n",
    "decs = []\n",
    "for ocell_id in ophys_cell_ids:\n",
    "    decs.append(calcium_trace[ocell_id][\"spike\"]) # deconvolved Ca spiketrains\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(n_frames), decs[0])\n",
    "fig.savefig(exp_path+'/results/deconvolved_Ca_spikes0.png', dpi=300, transparent=True)\n",
    "plt.close()\n",
    "fig.clf()\n",
    "spiketrains = []\n",
    "for decst in decs:\n",
    "    spiketrains.append( time[:][np.nonzero(decst)] )\n",
    "\n",
    "print(\"... producing spike rasterplot\")\n",
    "fig = plt.figure(figsize=[12.8,4.8])\n",
    "for row,train in enumerate(spiketrains):\n",
    "    plt.scatter( train, [row]*len(train), marker='o', edgecolors='none', s=1, c='k' )\n",
    "plt.ylabel(\"cell IDs\")\n",
    "plt.xlabel(\"time (s)\")\n",
    "fig.savefig(exp_path+'/results/rasterplot.png', transparent=False, dpi=800)\n",
    "plt.close()\n",
    "fig.clear()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the cell indexes from the list of IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ophys_cell_indexes = range(len(ophys_cell_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get soma center locations\n",
    "\n",
    "They are provided in voxels coordinates of 4,4,40 nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyc_soma_loc = np.zeros((n_pyc, 3))\n",
    "for i in range(n_pyc):\n",
    "    seg_id = pyc_list[i]\n",
    "    pyc_soma_loc[i,:] = get_soma_loc(Soma, seg_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join cell indexes with their position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyc_ca_soma_loc = np.zeros((len(ophys_cell_indexes), 3))\n",
    "for i in ophys_cell_indexes:\n",
    "    seg_id = ophys_cell_ids[i]\n",
    "    idx = np.where(pyc_list==seg_id)[0][0]\n",
    "    pyc_ca_soma_loc[i,:] = pyc_soma_loc[idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Structural Analysis\n",
    "\n",
    "First, we build an adjacency matrix of the 2p/EM-imaged neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.zeros((len(ophys_cell_indexes), len(ophys_cell_indexes)))\n",
    "for i in ophys_cell_indexes:\n",
    "    root_id = ophys_cell_ids[i]\n",
    "    root_id_postsyn_list = syn_df[syn_df['pre_root_id'] == root_id]['post_root_id'].tolist()\n",
    "    # print(root_id_postsyn_list)\n",
    "    for ps in root_id_postsyn_list:\n",
    "        if ps in ophys_cell_ids:\n",
    "            # ips = np.argwhere(ophys_cell_ids==ps)[0][0]\n",
    "            ips = ophys_cell_ids.index(ps)\n",
    "            # print(ps, ips)\n",
    "            adjacency_matrix[i][ips]=1\n",
    "np.save(exp_path+'/results/adjacency_matrix.npy', adjacency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several global purely structural measures.    \n",
    "This includes **panel 2B** (with inset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... adjacency matrix\n",
      "... loaded\n",
      "    number of vertices: 112\n",
      "... Network nodes degrees\n",
      "... Degree distributions\n",
      "... Betweenness centrality\n",
      "... Motifs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:151: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "global_degree_counts = []\n",
    "global_degree_distribution = []\n",
    "global_structural_betweeness = []\n",
    "global_structural_motifs = []\n",
    "global_structural_motifsratio = []\n",
    "global_structural_motifsurrogates = []\n",
    "\n",
    "exec(open(\"./structural_analysis.py\").read())\n",
    "\n",
    "global_structural_betweeness.append(betweenness_centrality)\n",
    "global_degree_counts.append(degree_counts)\n",
    "global_degree_distribution.append(degrees)\n",
    "global_structural_motifs.append(motifs)\n",
    "global_structural_motifsurrogates.append(surrogate_motifs)\n",
    "global_structural_motifsratio.append(motifsratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamical Analysis\n",
    "\n",
    "Here we first population events, we quantify them, and we extract their core neurons.   \n",
    "This analysis extends (from step 5 on) that performed by Filipchuk et al. 2022:\n",
    "1. Compute population instantaneous firing rate (bin)\n",
    "\n",
    "2. Establish significance threshold for population events   \n",
    "    2.1 compute Inter-Spike Intervals (ISI) of the original spiketrains   \n",
    "    2.2 reshuffle ISI to create (1000) surrogates   \n",
    "    2.3 compute the population instantaneous firing rate for each surrogate time-binned rasterplot   \n",
    "\n",
    "3. Find population events   \n",
    "    3.1 smoothed firing rate   \n",
    "    3.2 instantaneous threshold is the 99% of the surrogate population instantaneous firing rate   \n",
    "    3.3 the peaks above intersections of smoothed fr and threshold mark population events   \n",
    "    3.4 the minima before and after a peak are taken as start and end times of the population event   \n",
    "    \n",
    "4. Find clusters of events   \n",
    "    4.1 produce a cell id signature vector of each population event   \n",
    "    4.2 perform clustering linkage by complete cross-correlation of event vectors   \n",
    "    4.3 produce surrogates clusters to establish a cluster significance threshold     \n",
    "    4.4 find the event reproducibility within each cluster (cluster events cross-correlation)   \n",
    "\n",
    "5. Find core neurons   \n",
    "    5.1 take all neurons participating to a cluster of events   \n",
    "    5.2 use the a percentage (from 75 to 99%) of the cluster event reproducibility as core significance threshold   \n",
    "    5.3 if the occurrence frequency of a neuron is beyond threshold, then the neuron is taken as core   \n",
    "    5.4 remove core neurons if firing unspecifically within and outside their cluster   \n",
    "    \n",
    "### All panels of Figure 1\n",
    "\n",
    "are produced in the next cell by the file `dynamical_analysis.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... firing statistics\n",
      "    population firing: 1.23±1.14 sp/frame\n",
      "    smoothing\n",
      "... generating surrogates to establish population event threshold\n",
      "    cells firing rate: 0.01±0.10 sp/s\n",
      "    event size threshold (mean): 3.2139256165099335\n",
      "... find population events in the trial\n",
      "... signatures of population events\n",
      "    number of events: 226\n",
      "    number of events per sec: 0.1228247519048706\n",
      "    events duration: 0.674±0.229\n",
      "    events size: 8.000±3.775\n",
      "... Similarity of events matrix\n",
      "... clustering\n",
      "    linkage\n",
      "    surrogate events signatures for clustering threshold\n",
      "    cluster reproducibility threshold: 0.25542952676920067\n",
      "    cluster size threshold: 2\n",
      "    Total number of clusters: 97\n",
      "    removing below size threshold clusters: 8\n",
      "    removing below reproducibility threshold clusters: 93\n",
      "... finding cluster cores\n",
      "    removing cores firing unspecifically\n",
      "    gathering cores from all clusters\n",
      "    # cores: 11\n",
      "    # non-cores: 101\n",
      "    plotting single events rasterplots ...\n"
     ]
    }
   ],
   "source": [
    "global_structural_motif_cores = {k: 0 for k in range(16)}\n",
    "global_structural_motif_others = {k: 0 for k in range(16)}\n",
    "global_events_sec = []\n",
    "global_events_duration = []\n",
    "global_cluster_number = []\n",
    "global_cluster_selfsimilarity = []\n",
    "\n",
    "core_reproducibility_perc = 75 # change this to relax or stiff the threshold for detecting cores\n",
    "exec(open(\"./dynamical_analysis.py\").read())\n",
    "\n",
    "global_events_sec.append(events_sec)\n",
    "global_events_duration.extend(events_durations_f)\n",
    "global_cluster_number.append(nclusters)\n",
    "global_cluster_selfsimilarity.extend(reproducibility_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Mixing structural and dynamical analyses results to characterize core connectivity\n",
    "\n",
    "Here, we collect the evidence contrasting the hypothesis that core neurons are strongly connected.   \n",
    "We tested two fundamental attractor-driven assumptions:\n",
    "- synapses between cores are more numerous and stronger compared to others   \n",
    "- circuits made by cores involve more recursive connections toward cores\n",
    "\n",
    "### Spine number and volume (panel 2A, 2B)\n",
    "\n",
    "We can take the **number** (2A) and **volume** (2B) of post-synaptic spines as proxy for their functional efficacy.   \n",
    "The number of cores and non-cores for each cluster is different. Therefore we have to normalize this count to evaluate.\n",
    "\n",
    "For each set of reproducible cluster we count:    \n",
    "- the number of synapses made by a cell type (core or not) towards others, weighted by the squared number of target cells    \n",
    "    - the expectation is that core-to-core and core-to-other synapses should be numerous in order to pull the dynamics\n",
    "- the post-synaptic spine volume of synapses made by a cell type (core or not) towards others.   \n",
    "    - the expectation is that core-to-core and core-to-other spines should be larger in order to pull the dynamics\n",
    "\n",
    "**Synapses between core neurons of each cluster are less than every other combination.**    \n",
    "Note that the resulting normalized synapse counts (for the others) check with the network density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... network density (ratio between the edges present and the maximum number of edges that the graph can contain): 0.02431441326530612\n",
      "... Normalized number of spines\n",
      "    0.000000 core2core normalized spines number\n",
      "    0.076389 core2other normalized spines number\n",
      "    0.050842 other2core normalized spines number\n",
      "    0.033436 other2other normalized spines number\n",
      "... Spine volumes\n",
      "    0 core2core spines, volume: nan±nan µm3\n",
      "    23 core2other spines, volume: 0.087±0.08 µm3\n",
      "    9 other2core spines, volume: 0.116±0.05 µm3\n",
      "    196 other2other spines, volume: 0.073±0.06 µm3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:262: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:254: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# the density of the directed graph.\n",
    "network_density = dgraph.density(loops=True)\n",
    "print(\"... network density (ratio between the edges present and the maximum number of edges that the graph can contain):\", network_density )\n",
    "# spine number\n",
    "core2core_spine_num = 0.0 # to be normalized\n",
    "core2other_spine_num = 0.0\n",
    "other2core_spine_num = 0.0\n",
    "other2other_spine_num = 0.0\n",
    "# spine volume\n",
    "core2core_spine_vol = [] # µm3\n",
    "core2other_spine_vol = []\n",
    "other2core_spine_vol = []\n",
    "other2other_spine_vol = []\n",
    "\n",
    "set_ids = set(ophys_cell_ids)\n",
    "cluster_colors = [color for color in cluster_color_array if color!='gray']\n",
    "for cluster_k,dyn_core_ids in zip(cluster_colors,clusters_cores):\n",
    "    if cluster_k=='gray':\n",
    "        continue\n",
    "    dyn_other_ids = set_ids.symmetric_difference(dyn_core_ids)\n",
    "    \n",
    "    # we take the largest dataframe (syn_df) to avoid omitting any possible synapse, \n",
    "    # we are not interested in the spine volume at this stage\n",
    "    core2core_synapse_df = syn_df.query(f'(pre_root_id in {list(dyn_core_ids)}) and (post_root_id in {list(dyn_core_ids)})')\n",
    "    core2core_spine_num += len(core2core_synapse_df['id'].tolist())/(len(dyn_core_ids)*len(dyn_core_ids)) # normalized by target\n",
    "\n",
    "    core2other_synapse_df = syn_df.query(f'(pre_root_id in {list(dyn_core_ids)}) and (post_root_id in {list(dyn_other_ids)})')\n",
    "    core2other_spine_num += len(core2other_synapse_df['id'].tolist())/(len(dyn_core_ids)*len(dyn_other_ids)) \n",
    "\n",
    "    other2core_synapse_df = syn_df.query(f'(pre_root_id in {list(dyn_other_ids)}) and (post_root_id in {list(dyn_core_ids)})')\n",
    "    other2core_spine_num += len(other2core_synapse_df['id'].tolist())/(len(dyn_core_ids)*len(dyn_other_ids)) \n",
    "    \n",
    "    other2other_synapse_df = syn_df.query(f'(pre_root_id in {list(dyn_other_ids)}) and (post_root_id in {list(dyn_other_ids)})')\n",
    "    other2other_spine_num += len(other2other_synapse_df['id'].tolist())/(len(dyn_other_ids)*len(dyn_other_ids)) \n",
    "\n",
    "    # we take the dataframe containing the spine volume info (syn_spines_df)\n",
    "    # id, pre_root_id, post_root_id, cleft_vx, spine_vol_um3\n",
    "    core2core_synapse_df = syn_spines_df.query(f'(pre_root_id in {list(dyn_core_ids)}) and (post_root_id in {list(dyn_core_ids)})')\n",
    "    if not core2core_synapse_df.empty:\n",
    "        core2core_spine_vol.extend( core2core_synapse_df['spine_vol_um3'].tolist() )\n",
    "    \n",
    "    core2other_synapse_df = syn_spines_df.query(f'(pre_root_id in {list(dyn_core_ids)}) and (post_root_id in {list(dyn_other_ids)})')\n",
    "    if not core2other_synapse_df.empty:\n",
    "        core2other_spine_vol.extend( core2other_synapse_df['spine_vol_um3'].tolist() )\n",
    "    \n",
    "    other2core_synapse_df = syn_spines_df.query(f'(pre_root_id in {list(dyn_other_ids)}) and (post_root_id in {list(dyn_core_ids)})')\n",
    "    if not other2core_synapse_df.empty:\n",
    "        other2core_spine_vol.extend( other2core_synapse_df['spine_vol_um3'].tolist() )\n",
    " \n",
    "    other2other_synapse_df = syn_spines_df.query(f'(pre_root_id in {list(dyn_other_ids)}) and (post_root_id in {list(dyn_other_ids)})')\n",
    "    if not other2other_synapse_df.empty:\n",
    "        other2other_spine_vol.extend( other2other_synapse_df['spine_vol_um3'].tolist() )\n",
    "\n",
    "# description\n",
    "# number\n",
    "print(\"... Normalized number of spines\")\n",
    "print(\"    {:f} core2core normalized spines number\".format((core2core_spine_num)) )\n",
    "print(\"    {:f} core2other normalized spines number\".format((core2other_spine_num)) )\n",
    "print(\"    {:f} other2core normalized spines number\".format((other2core_spine_num)) )\n",
    "print(\"    {:f} other2other normalized spines number\".format((other2other_spine_num)) )\n",
    "\n",
    "# spines\n",
    "print(\"... Spine volumes\")\n",
    "print(\"    {:d} core2core spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(core2core_spine_vol), np.mean(core2core_spine_vol),np.std(core2core_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(core2core_spine_vol)) )\n",
    "print(\"    {:d} core2other spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(core2other_spine_vol), np.mean(core2other_spine_vol),np.std(core2other_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(core2other_spine_vol)) )\n",
    "print(\"    {:d} other2core spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(other2core_spine_vol), np.mean(other2core_spine_vol),np.std(other2core_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(other2core_spine_vol)) )\n",
    "print(\"    {:d} other2other spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(other2other_spine_vol), np.mean(other2other_spine_vol),np.std(other2other_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(other2other_spine_vol)) )\n",
    "\n",
    "# plotting\n",
    "# all spine number by type\n",
    "x = np.array([\"core-core\", \"core-other\", \"other-core\", \"other-other\"])\n",
    "y = np.array([core2core_spine_num, core2other_spine_num, other2core_spine_num, other2other_spine_num])\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x, y, color=['forestgreen','forestgreen','silver','silver'])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Normalized number of spines')\n",
    "fig.savefig(exp_path+'/results/global_cores_others_spine_num.svg', transparent=True)\n",
    "fig.clf()\n",
    "plt.close()\n",
    "\n",
    "# all spine volumes by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(0, 0.04, len(core2other_spine_vol))\n",
    "plt.scatter(xs, core2other_spine_vol, edgecolor='forestgreen', facecolor=('#228B224d'))\n",
    "xs = np.random.normal(1, 0.04, len(other2core_spine_vol))\n",
    "plt.scatter(xs, other2core_spine_vol, edgecolor='silver', facecolor=('#D3D3D34d'))\n",
    "xs = np.random.normal(2, 0.04, len(other2other_spine_vol))\n",
    "plt.scatter(xs, other2other_spine_vol, edgecolor='silver', facecolor=('#D3D3D34d'))\n",
    "vp = ax.violinplot([core2other_spine_vol,other2core_spine_vol,other2other_spine_vol], [0,1,2], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc in vp['bodies'][0:1]:\n",
    "    pc.set_facecolor('#228B224d')\n",
    "for pc in vp['bodies'][1:]:\n",
    "    pc.set_facecolor('#D3D3D34d')\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Spine Volume (µm^3)')\n",
    "plt.xticks([0, 1, 2], [ \"core-other\\n(n={:d})\".format(len(core2other_spine_vol)),\"other-core\\n(n={:d})\".format(len(other2core_spine_vol)),\"other-other\\n(n={:d})\".format(len(other2other_spine_vol))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_spine_vol.svg', transparent=True)\n",
    "fig.savefig(exp_path+'/results/global_cores_others_spine_vol.png', transparent=True, dpi=1200)\n",
    "fig.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Ca-imaged and outside EM volume inputs (panel 2B, last two boxes)\n",
    "\n",
    "Core responses could be due to non-imaged and outside volume sources. How can we rule this out (or reduce our lack of knowledge)?   \n",
    "We can ask *Are there more or stronger spines made by non-imaged neurons (either local or far) on cores or others?*   \n",
    "We have this information since we know the cell ID of all somas in the volume. We can take the spines having presynaptic ID different from the known Ca-imaged IDs or different from the somas within the EM volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... postsynaptic spines on cores or others from sources non-imaged or without soma in the volume\n",
      "    66 far2core spines, volume: 0.064±0.06 µm3\n",
      "    1926 far2other spines, volume: 0.082±0.09 µm3\n",
      "    far-core vs far-other spine size Kruskal-Wallis test results: 0.9170240458138655 0.3382575757961697\n",
      "    Kolmogorov-Smirnov Effect Size: 0.130\n"
     ]
    }
   ],
   "source": [
    "print(\"... postsynaptic spines on cores or others from sources non-imaged or without soma in the volume\")\n",
    "far2core_spine_vol = [] # µm3\n",
    "far2other_spine_vol = []\n",
    "set_ids = set(ophys_cell_ids)\n",
    "for dyn_core_ids in clusters_cores:\n",
    "    dyn_other_ids = set_ids.symmetric_difference(dyn_core_ids)\n",
    "    # searching\n",
    "    # id, pre_root_id, post_root_id, cleft_vx, spine_vol_um3\n",
    "    far2core_synapse_df = syn_spines_df.query(f'(pre_root_id not in {list(set_ids)}) and (post_root_id in {list(dyn_core_ids)})')\n",
    "    if not far2core_synapse_df.empty:\n",
    "        far2core_spine_vol.extend( far2core_synapse_df['spine_vol_um3'].tolist() )\n",
    "    far2other_synapse_df = syn_spines_df.query(f'(pre_root_id not in {list(set_ids)}) and (post_root_id in {list(dyn_other_ids)})')\n",
    "    if not far2other_synapse_df.empty:\n",
    "        far2other_spine_vol.extend( far2other_synapse_df['spine_vol_um3'].tolist() )\n",
    "        \n",
    "# description\n",
    "print(\"    {:d} far2core spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(far2core_spine_vol), np.mean(far2core_spine_vol),np.std(far2core_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(far2core_spine_vol)) )\n",
    "print(\"    {:d} far2other spines, volume: {:1.3f}±{:1.2f} µm3\".format(len(far2other_spine_vol), np.mean(far2other_spine_vol),np.std(far2other_spine_vol)) )\n",
    "# print(\"    \"+str(stats.describe(far2other_spine_vol)) )\n",
    "\n",
    "# significativity\n",
    "kwstat,pval = stats.kruskal(far2core_spine_vol, far2other_spine_vol)\n",
    "print(\"    far-core vs far-other spine size Kruskal-Wallis test results:\",kwstat,pval)\n",
    "if len(far2core_spine_vol)>0 and len(far2other_spine_vol)>0:\n",
    "    d,_ = stats.ks_2samp(far2core_spine_vol, far2other_spine_vol) # non-parametric measure of effect size [0,1]\n",
    "    print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "# all spine volumes by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(far2core_spine_vol))\n",
    "plt.scatter(xs, far2core_spine_vol, edgecolor='forestgreen', facecolor=('#228B224d'))\n",
    "xs = np.random.normal(2, 0.04, len(far2other_spine_vol))\n",
    "plt.scatter(xs, far2other_spine_vol, edgecolor='silver', facecolor=('#D3D3D34d'))\n",
    "vp = ax.violinplot([far2core_spine_vol,far2other_spine_vol], widths=0.15, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Spine Volume (µm^3)')\n",
    "plt.xticks([1, 2], [\"far-core\\n(n={:d})\".format(len(far2core_spine_vol)), \"far-other\\n(n={:d})\".format(len(far2other_spine_vol))])\n",
    "fig.savefig(exp_path+'/results/global_far_cores_others_spine_vol.svg', transparent=True)\n",
    "fig.savefig(exp_path+'/results/global_far_cores_others_spine_vol.png', transparent=True, dpi=1200)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are core more mutually connected than others?\n",
    "\n",
    "We started by asking whether a global measure such as assortativity - - gives a clear summary of mutuality between all cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... assortativity\n",
      "    preparing vertex labels for cores and others\n",
      "    overall: -0.06003996872013288\n",
      "    assortativity degree: -0.08993903571766572\n"
     ]
    }
   ],
   "source": [
    "print('... assortativity')\n",
    "print('    preparing vertex labels for cores and others')\n",
    "dgraph.vs[\"ophys_cell_id\"] = ophys_cell_ids\n",
    "is_id_core = np.array( [0] * len(ophys_cell_ids) )\n",
    "is_id_core[core_indexes] = 1\n",
    "dgraph.vs[\"is_core\"] = is_id_core.tolist()\n",
    "pyc_ca_syn_df = syn_df.query(f'(pre_root_id in {ophys_cell_ids}) and (post_root_id in {ophys_cell_ids})')\n",
    "is_syn_core = np.array( [0] * len(pyc_ca_syn_df) )\n",
    "for cid in [item for sublist in clusters_cores for item in sublist]:\n",
    "    is_syn_core[pyc_ca_syn_df['pre_root_id'] == cid] = 1\n",
    "dgraph.es[\"is_core\"] = is_syn_core.tolist()\n",
    "\n",
    "# is a preference for a network's nodes to attach to others that are similar in some way\n",
    "print(\"    overall:\", dgraph.assortativity_nominal(\"is_core\", directed=True) )\n",
    "# cores degree distro vs others degree distro\n",
    "# biological networks typically show negative assortativity, or disassortative mixing, or disassortativity, as high degree nodes tend to attach to low degree nodes.\n",
    "print(\"    assortativity degree:\", dgraph.assortativity_degree(directed=True) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Motif connectivity of cores and others (panel 2D)\n",
    "\n",
    "This measure of the network reports the participation of cores (or non-cores) in triplet motifs.    \n",
    "Note that the triplets are not exclusively made of cores (or non-cores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... saved mutual connectivity of cores and others\n"
     ]
    }
   ],
   "source": [
    "# For each set of reproducible cluster cores we count their connectivity motifs.\n",
    "set_indexes = set(ophys_cell_indexes)\n",
    "for dyn_core_ids in clusters_cores:\n",
    "    dyn_core_indexes = set([ophys_cell_ids.index(strid) for strid in dyn_core_ids])\n",
    "    dyn_other_indexes = set_indexes.symmetric_difference(dyn_core_indexes)\n",
    "    for mclass, mlist in motif_vertices.items():\n",
    "        for mtriplet in mlist:\n",
    "            intersection_cores = len(list(dyn_core_indexes.intersection(mtriplet)))\n",
    "            intersection_others = len(list(dyn_other_indexes.intersection(mtriplet)))\n",
    "            global_structural_motif_cores[mclass] += intersection_cores\n",
    "            global_structural_motif_others[mclass] += intersection_others\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.bar(global_structural_motif_cores.keys(), global_structural_motif_cores.values(), color='forestgreen')\n",
    "plt.ylabel('cores occurrences')\n",
    "plt.yscale('log')\n",
    "plt.ylim([0.7,plt.ylim()[1]])\n",
    "plt.xlabel('motifs types')\n",
    "fig.savefig(exp_path+'/results/global_motifs_cores.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clear()\n",
    "fig.clf()\n",
    "fig = plt.figure()\n",
    "plt.bar(global_structural_motif_others.keys(), global_structural_motif_others.values(), color='silver')\n",
    "plt.ylabel('non-cores occurrences')\n",
    "plt.yscale('log')\n",
    "plt.ylim([0.7,plt.ylim()[1]])\n",
    "plt.xlabel('motifs types')\n",
    "fig.savefig(exp_path+'/results/global_motifs_others.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clear()\n",
    "fig.clf()\n",
    "print(\"... saved mutual connectivity of cores and others\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    graph diameter (#vertices): 7\n",
      "    graph average path length (#vertices): 2.5824324324324324\n"
     ]
    }
   ],
   "source": [
    "# dgraph is already defined from the structural_analysis included file\n",
    "print(\"    graph diameter (#vertices):\", dgraph.diameter(directed=True, unconn=True, weights=None))\n",
    "print(\"    graph average path length (#vertices):\", dgraph.average_path_length(directed=True, unconn=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality of cores\n",
    "\n",
    "If cores are not more mutually connected compared to others, then what is their characterizing feature?    \n",
    "In the cells above, we saw indications of more interconnections between cores and others than within the same type.     \n",
    "This could hint at some form of centrality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree centrality of cores is not different from others (panel 2E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... degree centrality\n",
      "    cores: DescribeResult(nobs=11, minmax=(0, 12), mean=4.454545454545454, variance=20.872727272727268, skewness=0.6349774789784124, kurtosis=-1.1714912467068908)\n",
      "    others: DescribeResult(nobs=101, minmax=(0, 20), mean=2.5346534653465347, variance=15.531287128712869, skewness=2.3291170381219586, kurtosis=4.96879756585061)\n",
      "    Welch t test:  1.340 p= 0.206\n",
      "    Kolmogorov-Smirnov Effect Size: 0.316\n"
     ]
    }
   ],
   "source": [
    "print('... degree centrality')\n",
    "degree_centrality_cores = dgraph.degree(core_indexes, mode='out', loops=True)\n",
    "degree_centrality_others = dgraph.degree(other_indexes, mode='out', loops=True)\n",
    "# description\n",
    "print(\"    cores: \"+str(stats.describe(degree_centrality_cores)) )\n",
    "print(\"    others: \"+str(stats.describe(degree_centrality_others)) )\n",
    "# significativity\n",
    "print(\"    Welch t test:  %.3f p= %.3f\" % stats.ttest_ind(degree_centrality_cores, degree_centrality_others, equal_var=False))\n",
    "d,_ = stats.ks_2samp(degree_centrality_cores, degree_centrality_others) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(degree_centrality_cores))\n",
    "plt.scatter(xs, degree_centrality_cores, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(degree_centrality_others))\n",
    "plt.scatter(xs, degree_centrality_others, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([degree_centrality_cores,degree_centrality_others], widths=0.15, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Degree')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(degree_centrality_cores)), \"other\\n(n={:d})\".format(len(degree_centrality_others))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_degree.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Betweenness cenrality of cores is not different fdrom others (panel 2F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... betweenness\n",
      "    cores: DescribeResult(nobs=11, minmax=(0.0, 345.2711399711398), mean=42.6565033451397, variance=10640.152516976104, skewness=2.5966369354676053, kurtosis=5.172690324916742)\n",
      "    others: DescribeResult(nobs=101, minmax=(0.0, 617.3584776334777), mean=30.13642042775706, variance=9114.017309321269, skewness=4.48701313088047, kurtosis=21.95026890734329)\n",
      "    Welch t test:  0.385 p= 0.707\n",
      "    Kolmogorov-Smirnov Effect Size: 0.176\n"
     ]
    }
   ],
   "source": [
    "print('... betweenness')\n",
    "cores_betweenness = np.array(dgraph.betweenness(vertices=core_indexes, directed=True))\n",
    "others_betweenness = np.array(dgraph.betweenness(vertices=other_indexes, directed=True))\n",
    "print(\"    cores: \"+str(stats.describe(cores_betweenness)) )\n",
    "print(\"    others: \"+str(stats.describe(others_betweenness)) )\n",
    "# significativity\n",
    "print(\"    Welch t test:  %.3f p= %.3f\" % stats.ttest_ind(cores_betweenness, others_betweenness, equal_var=False))\n",
    "d,_ = stats.ks_2samp(cores_betweenness, others_betweenness) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(cores_betweenness))\n",
    "plt.scatter(xs, cores_betweenness, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(others_betweenness))\n",
    "plt.scatter(xs, others_betweenness, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([cores_betweenness,others_betweenness], widths=0.15, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Betweenness')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(cores_betweenness)), \"other\\n(n={:d})\".format(len(others_betweenness))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_betweenness.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hub scores of cores is not different from others (panel 2G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... authority score\n",
      "    authority cores: DescribeResult(nobs=11, minmax=(-0.0, 0.7675147860215232), mean=0.13064180474811657, variance=0.07271247357356375, skewness=1.7345932203345824, kurtosis=1.2146823450627249)\n",
      "    authority others: DescribeResult(nobs=101, minmax=(-0.0, 1.0), mean=0.10495690822853672, variance=0.05285478957134105, skewness=2.2737258702739935, kurtosis=4.045162242200936)\n",
      "    Kruskal-Wallis test:  0.346 p= 0.730\n",
      "    Kolmogorov-Smirnov Effect Size: 0.213\n",
      "... hub score\n",
      "    hub cores: DescribeResult(nobs=11, minmax=(0.0, 0.6213084815664704), mean=0.24035661146553355, variance=0.061454095726713176, skewness=0.7255018769591096, kurtosis=-1.121521818163497)\n",
      "    hub others: DescribeResult(nobs=101, minmax=(0.0, 1.0), mean=0.13882758754129756, variance=0.04617951806738232, skewness=2.1646314162268094, kurtosis=3.9110618002142363)\n",
      "    Kruskal-Wallis test:  1.466 p= 0.145\n",
      "    Kolmogorov-Smirnov Effect Size: 0.357\n"
     ]
    }
   ],
   "source": [
    "print(\"... authority score\")\n",
    "# what is the overlap of cores and hubs?\n",
    "# Hub\n",
    "authority_scores = np.array(dgraph.authority_score(weights=None, scale=True, return_eigenvalue=False))\n",
    "authority_scores_cores = authority_scores[core_indexes]\n",
    "authority_scores_others = authority_scores[other_indexes]\n",
    "print(\"    authority cores: \"+str(stats.describe(authority_scores_cores)) )\n",
    "print(\"    authority others: \"+str(stats.describe(authority_scores_others)) )\n",
    "# significativity\n",
    "print(\"    Kruskal-Wallis test:  %.3f p= %.3f\" % stats.ttest_ind(authority_scores_cores, authority_scores_others))\n",
    "d,_ = stats.ks_2samp(authority_scores_cores, authority_scores_others) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "# all eccentricity by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(authority_scores_cores))\n",
    "plt.scatter(xs, authority_scores_cores, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(authority_scores_others))\n",
    "plt.scatter(xs, authority_scores_others, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([authority_scores_cores,authority_scores_others], widths=0.15, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Hub score')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(authority_scores_cores)), \"other\\n(n={:d})\".format(len(authority_scores_others))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_authority_score.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()\n",
    "\n",
    "print(\"... hub score\")\n",
    "# what is the overlap of cores and hubs?\n",
    "# Hub\n",
    "hub_scores = np.array(dgraph.hub_score(weights=None, scale=True, return_eigenvalue=False))\n",
    "hub_scores_cores = hub_scores[core_indexes]\n",
    "hub_scores_others = hub_scores[other_indexes]\n",
    "print(\"    hub cores: \"+str(stats.describe(hub_scores_cores)) )\n",
    "print(\"    hub others: \"+str(stats.describe(hub_scores_others)) )\n",
    "# significativity\n",
    "print(\"    Kruskal-Wallis test:  %.3f p= %.3f\" % stats.ttest_ind(hub_scores_cores, hub_scores_others))\n",
    "d,_ = stats.ks_2samp(hub_scores_cores, hub_scores_others) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "# all eccentricity by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(hub_scores_cores))\n",
    "plt.scatter(xs, hub_scores_cores, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(hub_scores_others))\n",
    "plt.scatter(xs, hub_scores_others, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([hub_scores_cores,hub_scores_others], widths=0.15, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Hub score')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(hub_scores_cores)), \"other\\n(n={:d})\".format(len(hub_scores_others))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_hub_score.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cores control the flow of cortical activity\n",
    "\n",
    "So far, we used structural (graph) measures of neurons selected by looking at their reproducibility (a form of regular activity). In a sense, we were already crossing structural and dynamical information about the network.    \n",
    "\n",
    "However, we could push this further.    \n",
    "\n",
    "### Structural underpinnings of clusters (panel 2H)\n",
    "\n",
    "What is the origin of pattern reproducibility?    \n",
    "We can look at **how** the underlying connectivity structure supports each events activities.    \n",
    "\n",
    "We can consider each event as a _network flow problem_, in which the activity can be transferred through cells along the available connections.    \n",
    "\n",
    "For each event, we compute the max flow between the cells IDs according to their firing sequence.      \n",
    "**Do core neurons sustain more flow compared to others?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cores: DescribeResult(nobs=142, minmax=(0.0, 1.0), mean=0.12996158770806657, variance=0.06487285473582366, skewness=2.243819496058078, kurtosis=3.8662103801625305)\n",
      "    others: DescribeResult(nobs=100, minmax=(0.0, 0.0891089108910891), mean=0.007227722772277227, variance=0.00027498789482908683, skewness=2.960096273146175, kurtosis=8.88558952145802)\n",
      "    Welch t test:  5.725 p= 0.000\n",
      "    Kolmogorov-Smirnov Effect Size: 0.387\n"
     ]
    }
   ],
   "source": [
    "# each edge has a capacity and each edge receives a flow. \n",
    "# The amount of flow on an edge cannot exceed the capacity of the edge.\n",
    "# therefore, edges with high capacity will be more important for the flow.\n",
    "# here we test the hypothesis that edges towards cores have higher capacity\n",
    "# or that the sum of edges towards cores have a higher total capacity\n",
    "cell_total_capacity = {cid:list() for cid in ophys_cell_ids}\n",
    "edges_sourcing = {cid:0 for cid in ophys_cell_ids}\n",
    "edges_targeting = {cid:0 for cid in ophys_cell_ids}\n",
    "\n",
    "for cluster_k,events_cellids in sorted_events_cidlist.items():\n",
    "    if cluster_k == 'gray':\n",
    "        continue\n",
    "\n",
    "    for vnt in events_cellids:\n",
    "        for posi,vidj in enumerate(vnt[1:]):\n",
    "            vidi = vnt[posi] # enumerate will go from 0\n",
    "            # print(vidi, vidj)\n",
    "\n",
    "            # check beginning and end are not the same\n",
    "            if dgraph.vs.find(ophys_cell_id=vidi).index == dgraph.vs.find(ophys_cell_id=vidj).index:\n",
    "                continue\n",
    "            # # check there is a path between the two\n",
    "            # if len(spinesgraph.get_all_shortest_paths(spinesgraph.vs.find(name=vidi).index, to=spinesgraph.vs.find(name=vidj).index, weights=None, mode='out'))>0:\n",
    "            #     continue\n",
    "\n",
    "            # Take the maximum flow between the previous and next vertices\n",
    "            mfres = dgraph.maxflow(dgraph.vs.find(ophys_cell_id=vidi).index, dgraph.vs.find(ophys_cell_id=vidj).index)\n",
    "            # returns a tuple containing the following:\n",
    "            # graph - the graph on which this flow is defined\n",
    "            # value - the value (capacity) of the maximum flow between the given vertices\n",
    "            # flow - the flow values on each edge. For directed graphs, this is simply a list where element i corresponds to the flow on edge i.\n",
    "            # cut - edge IDs in the minimal cut corresponding to the flow.\n",
    "            # partition - vertex IDs in the parts created after removing edges in the cut\n",
    "            # es - an edge selector restricted to the edges in the cut.\n",
    "            # print(mfres)\n",
    "\n",
    "            # we get a flow value for each edge contributing to the flow.\n",
    "            mfres_value = mfres.value\n",
    "            if vidi in np.array(ophys_cell_ids)[core_indexes]:\n",
    "                mfres_value /= len(core_indexes)\n",
    "            else:\n",
    "                mfres_value /= len(other_indexes)\n",
    "            cell_total_capacity[vidi].append(mfres_value)\n",
    "            mfres_value = mfres.value\n",
    "            if vidj in np.array(ophys_cell_ids)[core_indexes]:\n",
    "                mfres_value /= len(core_indexes)\n",
    "            else:\n",
    "                mfres_value /= len(other_indexes)\n",
    "            cell_total_capacity[vidj].append(mfres_value)\n",
    "\n",
    "            # # Iterate over the edges identified by the flow.\n",
    "            # # count the edges sourcing from cores, and those targeting cores. Which is more?\n",
    "            # for edge in mfres.es:\n",
    "            #     sourceid = int(dgraph.vs[edge.source]['ophys_cell_id'])\n",
    "            #     targetid = int(dgraph.vs[edge.target]['ophys_cell_id'])\n",
    "            #     if sourceid in cell_total_capacity.keys():\n",
    "            #         edges_sourcing[sourceid] +=1 # just count\n",
    "            #     if targetid in cell_total_capacity.keys():\n",
    "            #         edges_targeting[targetid] +=1 # just count\n",
    "\n",
    "# print(cell_total_capacity)\n",
    "# print(edges_sourcing)\n",
    "# print(edges_targeting)\n",
    "\n",
    "flowvalue_cores = []\n",
    "for cid in np.array(ophys_cell_ids)[core_indexes]:\n",
    "    flowvalue_cores.extend(cell_total_capacity[cid])\n",
    "\n",
    "flowvalue_others = []\n",
    "for cid in np.array(ophys_cell_ids)[other_indexes]:\n",
    "    flowvalue_others.extend(cell_total_capacity[cid])\n",
    "\n",
    "# description\n",
    "print(\"    cores: \"+str(stats.describe(flowvalue_cores)) )\n",
    "print(\"    others: \"+str(stats.describe(flowvalue_others)) )\n",
    "# significativity\n",
    "print(\"    Welch t test:  %.3f p= %.3f\" % stats.ttest_ind(flowvalue_cores, flowvalue_others, equal_var=False))\n",
    "d,_ = stats.ks_2samp(flowvalue_cores, flowvalue_others) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(flowvalue_cores))\n",
    "plt.scatter(xs, flowvalue_cores, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(flowvalue_others))\n",
    "plt.scatter(xs, flowvalue_others, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([flowvalue_cores,flowvalue_others], widths=0.15, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('flowvalue')\n",
    "# plt.ylim([0,20])\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(flowvalue_cores)), \"other\\n(n={:d})\".format(len(flowvalue_others))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_flowvalue.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cores are crossroads of multiple paths\n",
    "\n",
    "If cores are more often than others part of the paths, it means that they might not be central by virtue of their degree, but by how many event trajectory path (not just any path as in the betweenness, or hubness) pass through them.     \n",
    "Their **pagerank** is a closer approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... PageRank centrality\n",
      "    cores: DescribeResult(nobs=11, minmax=(0.021617779139083786, 0.09699142115966584), mean=0.03293753110440167, variance=0.0005909452493032695, skewness=2.0080850961714316, kurtosis=2.548542402713462)\n",
      "    others: DescribeResult(nobs=101, minmax=(0.0, 0.09291515108299592), mean=0.006313734236154276, variance=0.00025638067918087057, skewness=3.429876222293849, kurtosis=13.097318966876085)\n",
      "    Kruskal-Wallis test:  27.029 p= 0.000\n",
      "    Kolmogorov-Smirnov Effect Size: 0.881\n"
     ]
    }
   ],
   "source": [
    "print('... PageRank centrality')\n",
    "pagerank_cores = np.array(dgraph.personalized_pagerank(vertices=core_indexes, directed=True, damping=0.85, reset=\"is_core\"))\n",
    "pagerank_others = np.array(dgraph.personalized_pagerank(vertices=other_indexes, directed=True, damping=0.85, reset=\"is_core\"))\n",
    "# description\n",
    "print(\"    cores: \"+str(stats.describe(pagerank_cores)) )\n",
    "print(\"    others: \"+str(stats.describe(pagerank_others)) )\n",
    "# significativity\n",
    "print(\"    Kruskal-Wallis test:  %.3f p= %.3f\" % stats.kruskal(pagerank_cores, pagerank_others))\n",
    "d,_ = stats.ks_2samp(pagerank_cores, pagerank_others) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(pagerank_cores))\n",
    "plt.scatter(xs, pagerank_cores, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(pagerank_others))\n",
    "plt.scatter(xs, pagerank_others, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([pagerank_cores,pagerank_others], widths=0.15, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('PageRank')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(pagerank_cores)), \"other\\n(n={:d})\".format(len(pagerank_others))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_pagerank.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Supplementary figure 1\n",
    "\n",
    "Connection strength may be due to other (unquantified) factors. To circumvent this possibility, we can look at functional connectivity.   \n",
    "Are cores more 1-lag correlated than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... post-synaptic efficacy as 1-lag correlation of core and other synapses\n",
      "    creating empty binary spike lists\n",
      "    filling binary spike lists\n",
      "    composing the adjacency matrix\n",
      "    52 core2core 1-lag R: 0.015±0.02\n",
      "    1516 core2other 1-lag R: 0.000±0.01\n",
      "    1516 other2core 1-lag R: 0.000±0.01\n",
      "    47092 other2other 1-lag R: 0.000±0.01\n",
      "    core-core vs other-other 1-lag R Kruskal-Wallis test results: 37.703679699862086 8.234907532819563e-10\n",
      "    Kolmogorov-Smirnov Effect Size: 0.438\n",
      "    core-core vs core-other 1-lag R Kruskal-Wallis test results: 36.10674331267931 1.8679931166810893e-09\n",
      "    Kolmogorov-Smirnov Effect Size: 0.451\n",
      "    core-core vs other-core 1-lag R Kruskal-Wallis test results: 36.32793438737887 1.6675651926013212e-09\n",
      "    Kolmogorov-Smirnov Effect Size: 0.457\n"
     ]
    }
   ],
   "source": [
    "print(\"... post-synaptic efficacy as 1-lag correlation of core and other synapses\")\n",
    "\n",
    "# make binary spiketrains\n",
    "print(\"    creating empty binary spike lists\")\n",
    "binary_spiketrains = np.zeros( (len(spiketrains),len(time)+2) )\n",
    "# print(binary_spiketrains.shape)\n",
    "print(\"    filling binary spike lists\")\n",
    "# iterate over spiketrains assigning 1 to the binary_spiketrains at the corresponding position\n",
    "for row,train in enumerate(spiketrains):\n",
    "    tidxs = np.trunc(np.array(train)/frame_duration).astype(int)\n",
    "    tidxs[tidxs>len(time)] = len(time) # double check. The frame_duration is periodic but we represent it to the fourth decimal position.\n",
    "    binary_spiketrains[row][tidxs] = 1\n",
    "    # binary_spiketrains[row][np.trunc(train/frame_duration).astype(int)] = 1\n",
    "# print(binary_spiketrains)\n",
    "print(\"    composing the adjacency matrix\")\n",
    "functional_adjacency_matrix = []\n",
    "for irow,bsti in enumerate(binary_spiketrains):\n",
    "    row_xcorr = []\n",
    "    for jrow,bstj in enumerate(binary_spiketrains):\n",
    "        if irow==jrow:\n",
    "            row_xcorr.append(0.0) # no self connections\n",
    "            continue\n",
    "        row_xcorr.append(crosscorrelation(bsti, bstj, maxlag=1, mode='corr')[2]) # correlation at lag 1\n",
    "    functional_adjacency_matrix.append(row_xcorr)\n",
    "functional_adjacency_matrix = np.array(functional_adjacency_matrix)\n",
    "np.save(exp_path+'/results/functional_adjacency_matrix.npy', adjacency_matrix)\n",
    "# plot\n",
    "fig = plt.figure()\n",
    "plt.pcolormesh(functional_adjacency_matrix)\n",
    "cbar = plt.colorbar()\n",
    "fig.savefig(exp_path+'/results/functional_adjacency_matrix.png', transparent=True)\n",
    "plt.close()\n",
    "fig.clear()\n",
    "fig.clf()\n",
    "\n",
    "# efficacy probability as 1-lag correlations\n",
    "core2core_efficacy = [] # probability\n",
    "core2other_efficacy = []\n",
    "other2core_efficacy = []\n",
    "other2other_efficacy = []\n",
    "for dyn_core in clusters_cores:\n",
    "    dyn_core_indexes = [ophys_cell_ids.index(strid) for strid in dyn_core]\n",
    "    dyn_other_indexes = list(set(ophys_cell_indexes).symmetric_difference(set(dyn_core_indexes)))\n",
    "    # selection\n",
    "    core2core_efficacy.extend( [conns for cid in functional_adjacency_matrix[dyn_core_indexes,:] for conns in cid[dyn_core_indexes]] )\n",
    "    core2other_efficacy.extend( [conns for cid in functional_adjacency_matrix[dyn_core_indexes,:] for conns in cid[dyn_other_indexes]] )\n",
    "    other2core_efficacy.extend( [conns for cid in functional_adjacency_matrix[dyn_other_indexes,:] for conns in cid[dyn_core_indexes]] )\n",
    "    other2other_efficacy.extend( [conns for cid in functional_adjacency_matrix[dyn_other_indexes,:] for conns in cid[dyn_other_indexes]] )\n",
    "\n",
    "print(\"    {:d} core2core 1-lag R: {:1.3f}±{:1.2f}\".format(len(core2core_efficacy), np.mean(core2core_efficacy),np.std(core2core_efficacy)) )\n",
    "print(\"    {:d} core2other 1-lag R: {:1.3f}±{:1.2f}\".format(len(core2other_efficacy), np.mean(core2other_efficacy),np.std(core2other_efficacy)) )\n",
    "print(\"    {:d} other2core 1-lag R: {:1.3f}±{:1.2f}\".format(len(other2core_efficacy), np.mean(other2core_efficacy),np.std(other2core_efficacy)) )\n",
    "print(\"    {:d} other2other 1-lag R: {:1.3f}±{:1.2f}\".format(len(other2other_efficacy), np.mean(other2other_efficacy),np.std(other2other_efficacy)) )\n",
    "# significativity\n",
    "kwstat,pval = stats.kruskal(core2core_efficacy, other2other_efficacy)\n",
    "print(\"    core-core vs other-other 1-lag R Kruskal-Wallis test results:\",kwstat,pval)\n",
    "d,_ = stats.ks_2samp(core2core_efficacy, other2other_efficacy) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "kwstat,pval = stats.kruskal(core2core_efficacy, core2other_efficacy)\n",
    "print(\"    core-core vs core-other 1-lag R Kruskal-Wallis test results:\",kwstat,pval)\n",
    "d,_ = stats.ks_2samp(core2core_efficacy, core2other_efficacy) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "kwstat,pval = stats.kruskal(core2core_efficacy, other2core_efficacy)\n",
    "print(\"    core-core vs other-core 1-lag R Kruskal-Wallis test results:\",kwstat,pval)\n",
    "d,_ = stats.ks_2samp(core2core_efficacy, other2core_efficacy) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "# all spine volumes by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(0, 0.04, len(core2core_efficacy))\n",
    "plt.scatter(xs, core2core_efficacy, edgecolor='forestgreen', facecolor=('#228B224d'))\n",
    "xs = np.random.normal(1, 0.04, len(core2other_efficacy))\n",
    "plt.scatter(xs, core2other_efficacy, edgecolor='forestgreen', facecolor=('#228B224d'))\n",
    "xs = np.random.normal(2, 0.04, len(other2core_efficacy))\n",
    "plt.scatter(xs, other2core_efficacy, edgecolor='silver', facecolor=('#C0C0C04d'))\n",
    "xs = np.random.normal(3, 0.04, len(other2other_efficacy))\n",
    "plt.scatter(xs, other2other_efficacy, edgecolor='silver', facecolor=('#C0C0C04d'))\n",
    "vp = ax.violinplot([core2core_efficacy,core2other_efficacy,other2core_efficacy,other2other_efficacy], [0,1,2,3], widths=0.3, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc in vp['bodies'][0:1]:\n",
    "    pc.set_facecolor('#228B224d')\n",
    "for pc in vp['bodies'][1:]:\n",
    "    pc.set_facecolor('#D3D3D34d')\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Efficacy (1-lag R)')\n",
    "plt.xticks([0, 1, 2, 3], [\"core-core\\n(n={:d})\".format(len(core2core_efficacy)), \"core-other\\n(n={:d})\".format(len(core2other_efficacy)),\"other-core\\n(n={:d})\".format(len(other2core_efficacy)),\"other-other\\n(n={:d})\".format(len(other2other_efficacy))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_efficacy.png', transparent=True, dpi=1500)\n",
    "# fig.savefig(exp_path+'/results/global_cores_others_efficacy.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Supplementary figure 3\n",
    "   \n",
    "To have keep cores within the attractor framework, cores activity could be sustained by indirect synaptic feedback, through highly connected secondary paths.   \n",
    "To back up the attractor idea, one would expect that core neurons would have shorter paths or cycles, compared to others. \n",
    "\n",
    "### Shortest paths of cores and others (panel S3A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... number of paths in a complete graph of the same size: 4.317298994652368e+178\n",
      "... number of shortest paths between cores\n",
      "    cores shortest paths: DescribeResult(nobs=110, minmax=(0, 5), mean=0.9727272727272728, variance=2.485487906588825, skewness=1.131712439974105, kurtosis=-0.412811249534613)\n",
      "    others shortest paths: DescribeResult(nobs=10100, minmax=(0, 8), mean=0.6076237623762376, variance=2.021983658807508, skewness=2.163248016247377, kurtosis=3.4165268418042007)\n",
      "    equal variances? LeveneResult(statistic=7.156175120461955, pvalue=0.007482545093017935)\n",
      "    Welch t test:  2.418 p= 0.017\n",
      "    Kolmogorov-Smirnov Effect Size: 0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_582/2252254418.py:7: RuntimeWarning: Couldn't reach some vertices at src/paths/unweighted.c:368\n",
      "  shrtpth = dgraph.get_shortest_paths(coreidx, to=othercores, weights=None, mode='out', output='vpath')\n",
      "/tmp/ipykernel_582/2252254418.py:14: RuntimeWarning: Couldn't reach some vertices at src/paths/unweighted.c:368\n",
      "  shrtpth = dgraph.get_shortest_paths(otheridx, to=otherothers, weights=None, mode='out', output='vpath')\n"
     ]
    }
   ],
   "source": [
    "print(\"... number of paths in a complete graph of the same size:\", (np.math.factorial(112-2)*np.e))\n",
    "print('... number of shortest paths between cores')\n",
    "core_shortestpaths = []\n",
    "for coreidx in core_indexes:\n",
    "    othercores = list(core_indexes)\n",
    "    othercores.remove(coreidx)\n",
    "    shrtpth = dgraph.get_shortest_paths(coreidx, to=othercores, weights=None, mode='out', output='vpath')\n",
    "    for strp in shrtpth:\n",
    "        core_shortestpaths.append(len(strp))\n",
    "other_shortestpaths = []\n",
    "for otheridx in other_indexes:\n",
    "    otherothers = list(other_indexes)\n",
    "    otherothers.remove(otheridx)\n",
    "    shrtpth = dgraph.get_shortest_paths(otheridx, to=otherothers, weights=None, mode='out', output='vpath')\n",
    "    for strp in shrtpth:\n",
    "        other_shortestpaths.append(len(strp))\n",
    "print(\"    cores shortest paths: \"+str(stats.describe(core_shortestpaths)) )\n",
    "print(\"    others shortest paths: \"+str(stats.describe(other_shortestpaths)) )\n",
    "print(\"    equal variances? \"+str(stats.levene(core_shortestpaths, other_shortestpaths)) )\n",
    "# significativity\n",
    "print(\"    Welch t test:  %.3f p= %.3f\" % stats.ttest_ind(core_shortestpaths, other_shortestpaths, equal_var=False))\n",
    "d,_ = stats.ks_2samp(core_shortestpaths, other_shortestpaths) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(core_shortestpaths))\n",
    "plt.scatter(xs, core_shortestpaths, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(other_shortestpaths))\n",
    "plt.scatter(xs, other_shortestpaths, alpha=0.3, c='silver')\n",
    "vp = ax.violinplot([core_shortestpaths,other_shortestpaths], widths=0.15, showextrema=False, showmedians=True)\n",
    "for pc in vp['bodies']:\n",
    "    pc.set_edgecolor('black')\n",
    "for pc,cb in zip(vp['bodies'],['#228B224d','#D3D3D34d']):\n",
    "    pc.set_facecolor(cb)\n",
    "vp['cmedians'].set_color('orange')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Shortest path length')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(core_shortestpaths)), \"other\\n(n={:d})\".format(len(other_shortestpaths))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_shortestpath.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycles between cores or others (panel S3B)\n",
    "\n",
    "Cycles are built starting from a core (or other) and iterating neighbors of different lenghts, where the last vertex is the starting one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... cycles\n"
     ]
    }
   ],
   "source": [
    "print('... cycles')\n",
    "# breadth first search of paths and unique cycles\n",
    "def get_cycles(adj, paths, maxlen):\n",
    "    # tracking the actual path length:\n",
    "    maxlen -= 1\n",
    "    nxt_paths = []\n",
    "    # iterating over all paths:\n",
    "    for path in paths['paths']:\n",
    "        # iterating neighbors of the last vertex in the path:\n",
    "        for nxt in adj[path[-1]]:\n",
    "            # attaching the next vertex to the path:\n",
    "            nxt_path = path + [nxt]\n",
    "            if path[0] == nxt and min(path) == nxt:\n",
    "                # the next vertex is the starting vertex, we found a cycle\n",
    "                # we keep the cycle only if the starting vertex has the\n",
    "                # lowest vertex id, to avoid having the same cycles\n",
    "                # more than once\n",
    "                paths['cycles'].append(nxt_path)\n",
    "                # if you don't need the starting vertex\n",
    "                # included at the end:\n",
    "                # paths$cycles <- c(paths$cycles, list(path))\n",
    "            elif nxt not in path:\n",
    "                # keep the path only if we don't create\n",
    "                # an internal cycle in the path\n",
    "                nxt_paths.append(nxt_path)\n",
    "    # paths grown by one step:\n",
    "    paths['paths'] = nxt_paths\n",
    "    if maxlen == 0:\n",
    "        # the final return when maximum search length reached\n",
    "        return paths\n",
    "    else:\n",
    "        # recursive return, to grow paths further\n",
    "        return get_cycles(adj, paths, maxlen)\n",
    "# Comparison of core based cycles vs other based cycles\n",
    "maxlen = 10 # the maximum length to limit computation time\n",
    "# creating an adjacency list\n",
    "adj = [[n.index for n in v.neighbors()] for v in dgraph.vs]\n",
    "# recursive search of cycles\n",
    "# for each core vertex as candidate starting point\n",
    "core_cycles = []\n",
    "for start in core_indexes:\n",
    "    core_cycles += get_cycles(adj,{'paths': [[start]], 'cycles': []}, maxlen)['cycles']\n",
    "print(\"    # core-based cycles:\", len(core_cycles) )\n",
    "# count the length of loops involving 1 core\n",
    "core_cycles_lens = [len(cycle) for cycle in core_cycles]\n",
    "print(\"    core-based cycles length: \"+str(stats.describe(core_cycles_lens)) )\n",
    "\n",
    "other_cycles = []\n",
    "for start in other_indexes:\n",
    "    other_cycles += get_cycles(adj,{'paths': [[start]], 'cycles': []}, maxlen)['cycles']\n",
    "print(\"    # other-based cycles:\", len(other_cycles) )\n",
    "# count the length of loops involving 1 core\n",
    "other_cycles_lens = [len(cycle) for cycle in other_cycles]\n",
    "print(\"    other-based cycles length: \"+str(stats.describe(other_cycles_lens)) )\n",
    "\n",
    "d,_ = stats.ks_2samp(core_cycles_lens, other_cycles_lens) # non-parametric measure of effect size [0,1]\n",
    "print('    Kolmogorov-Smirnov Effect Size: %.3f' % d)\n",
    "# all cycles by type\n",
    "fig, ax = plt.subplots()\n",
    "xs = np.random.normal(1, 0.04, len(core_cycles_lens))\n",
    "plt.scatter(xs, core_cycles_lens, alpha=0.3, c='forestgreen')\n",
    "xs = np.random.normal(2, 0.04, len(other_cycles_lens))\n",
    "plt.scatter(xs, other_cycles_lens, alpha=0.3, c='silver')\n",
    "bp = ax.boxplot([core_cycles_lens,other_cycles_lens], notch=0, sym='', showcaps=False, zorder=10)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Cycles length')\n",
    "plt.xticks([1, 2], [\"core\\n(n={:d})\".format(len(core_cycles_lens)), \"other\\n(n={:d})\".format(len(other_cycles_lens))])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_cyclelens.png', transparent=True, dpi=1500)\n",
    "plt.close()\n",
    "fig.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Do the cores of each cluster form a clique?\n",
    "\n",
    "If the cores of each cluster are pattern completion units, they should participate in more cliques (set of vertices where an edge is present between any two of them) than other non-core neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_582/1704612098.py:1: RuntimeWarning: Edge directions are ignored for clique calculations at src/cliques/cliquer_wrapper.c:57\n",
      "  cliques = dgraph.cliques(min=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(21, 24), (24, 30), (5, 21), (24, 30), (24, 30), (5, 21), (5, 21), (5, 21), (5, 21), (21, 24), (5, 21), (24, 30), (21, 24), (21, 24), (5, 21), (21, 24), (24, 30), (21, 24), (24, 30), (5, 21), (21, 24), (21, 24), (5, 21)]\n",
      "    cliques made by cores: 2.090909090909091\n",
      "    cliques made by others: 2.8613861386138613\n"
     ]
    }
   ],
   "source": [
    "cliques = dgraph.cliques(min=2)\n",
    "\n",
    "cliques_cores = []\n",
    "cliques_others = []\n",
    "\n",
    "for cluster_cids in clustered_spectrums:\n",
    "    cluster_core_indices = []\n",
    "    # we take the index of the cell participating in this cluster\n",
    "    cluster_indices = [ophys_cell_ids.index(strid) for strid in cluster_cids]\n",
    "    # we take the cores of this cluster\n",
    "    cluster_core_indices = list(set(core_indexes).intersection(cluster_indices))\n",
    "    cluster_other_indices = list(set(other_indexes).intersection(cluster_indices))\n",
    "    # we take the edges between the cores\n",
    "    for clique in cliques:\n",
    "        if set(clique).issubset(cluster_core_indices):\n",
    "            cliques_cores.append(clique)\n",
    "        if set(clique).issubset(cluster_other_indices):\n",
    "            cliques_others.append(clique)\n",
    "print(cliques_cores)\n",
    "cores_cliques_count = len(cliques_cores)/len(core_indexes)\n",
    "others_cliques_count = len(cliques_others)/len(other_indexes)\n",
    "\n",
    "print(\"    cliques made by cores:\",cores_cliques_count)\n",
    "print(\"    cliques made by others:\",others_cliques_count)\n",
    "\n",
    "# print(core_edges)\n",
    "x = np.array([\"cores\", \"others\"])\n",
    "y = np.array([cores_cliques_count, others_cliques_count])\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x, y, color=['forestgreen','silver'])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.ylabel('Normalized count of cliques')\n",
    "plt.xticks([0, 1], [\"core\\n(n={:.3f})\".format(cores_cliques_count), \"other\\n(n={:.3f})\".format(others_cliques_count)])\n",
    "fig.savefig(exp_path+'/results/global_cores_others_cliques.svg', transparent=True)\n",
    "plt.close()\n",
    "fig.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters of events are not reproducible trajectories of the population dynamics\n",
    "\n",
    "Clusters of population events are found by correlating population vectors, which only retain the cell IDs while ignoring the time of firing.    \n",
    "We can consider also time.\n",
    "\n",
    "Each recorded frame (~67ms) is an instantaneous population state defined by all its cells (112 of them are known for their firing, the others are unkown).    \n",
    "A sequence of population states is a trajectory in the population dynamical state space.    \n",
    "In this space, clusters of reproducible population events are represented by reproducible trajectories. \n",
    "\n",
    "We can compare the event trajectories visited within a cluster by comparing their patterns.    \n",
    "Events are made by cells firing (often multiple times) during the event interval, so each sequence is a 2D submatrix of the population rasterplot. This gives a measure of trajectory reproducibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... sequence internal consistency\n",
      "\n",
      "    common trajectory pattern with n cells: 6  and m intervals: 674\n",
      "    correlation across all trajectories: 0.310±0.02\n",
      "... searching for repeating sequences in the ordered firing of cell IDs\n",
      "    (92, 93) 2\n",
      "[ 5  8 21 24 30 36 47 50 81 92 93]\n",
      "\n",
      "    common trajectory pattern with n cells: 9  and m intervals: 809\n",
      "    correlation across all trajectories: 0.172±0.04\n",
      "... searching for repeating sequences in the ordered firing of cell IDs\n",
      "    (47, 81) 2\n",
      "[ 5  8 21 24 30 36 47 50 81 92 93]\n",
      "\n",
      "    common trajectory pattern with n cells: 14  and m intervals: 877\n",
      "    correlation across all trajectories: 0.216±0.03\n",
      "... searching for repeating sequences in the ordered firing of cell IDs\n",
      "    (24, 5) 2\n",
      "[ 5  8 21 24 30 36 47 50 81 92 93]\n",
      "\n",
      "    common trajectory pattern with n cells: 7  and m intervals: 337\n",
      "    correlation across all trajectories: 0.271±0.03\n",
      "... searching for repeating sequences in the ordered firing of cell IDs\n",
      "    (5, 21) 2\n",
      "[ 5  8 21 24 30 36 47 50 81 92 93]\n",
      "    (21, 24) 2\n",
      "[ 5  8 21 24 30 36 47 50 81 92 93]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2691: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:2692: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# print(cluster_events_spiketrains) # already expressed in integer (ms)\n",
    "\n",
    "print(\"... sequence internal consistency\")\n",
    "\n",
    "# cycle over clusters\n",
    "for cluster_k, events_cellindexes in sorted_events_indexes.items():\n",
    "    if cluster_k == 'gray':\n",
    "        continue\n",
    "    print()\n",
    "\n",
    "    # We want to compare the trajectories of this cluster.\n",
    "    # Trajectories should have same shape. We will subract them to get the difference (/num of events).\n",
    "    \n",
    "    # Finding the common-shape trajectory\n",
    "    # n is the maximal number of cells participating to events in this cluster\n",
    "    maxcells = max(events_cellindexes, key = lambda i: len(i))\n",
    "    # m is the largest interval between the first min spiketrain and the last max spiketrain of all events in the cluster\n",
    "    events_spiketrains = cluster_events_spiketrains[cluster_k]\n",
    "    # print(events_spiketrains)\n",
    "    maxinterval = 0 # \n",
    "    for evt_spktrains in events_spiketrains:\n",
    "        mint = np.amin([x for xs in evt_spktrains for x in xs]) # for cases of just one spiketinme in list\n",
    "        if isinstance(mint, list): mint = mint[0] # for cases of list\n",
    "        maxt = np.amax([x for xs in evt_spktrains for x in xs])\n",
    "        if isinstance(maxt, list): maxt = maxt[-1]\n",
    "        if maxt-mint > maxinterval:\n",
    "            maxinterval = maxt-mint\n",
    "    print(\"    common trajectory pattern with n cells:\", len(maxcells), \" and m intervals:\", maxinterval)\n",
    "    \n",
    "    # cluster trajectories, one per event, all same shape\n",
    "    cluster_trajectories = []\n",
    "    for evt_indexes,evt_spktrains in zip(events_cellindexes,events_spiketrains):\n",
    "        # create empty trajectory of shape n cell, m interval\n",
    "        trajectory = np.zeros((len(maxcells),maxinterval+1))\n",
    "        mint = np.amin([x for xs in evt_spktrains for x in xs]) # take local mintime to find the trajectory m index\n",
    "        if isinstance(mint, list): mint = mint[0] # for cases of just one spiketinme in list\n",
    "        for ncell,spktrain in enumerate(evt_spktrains):\n",
    "            trajectory[ncell][spktrain-mint] = 1\n",
    "        cluster_trajectories.append(trajectory)\n",
    "    \n",
    "    # correlation between trajectories\n",
    "    # very simple (probably too much) measure of trajectory correspondence\n",
    "    trajR = []\n",
    "    for itr,itrajectory in enumerate(cluster_trajectories):\n",
    "        for jtr,jtrajectory in enumerate(cluster_trajectories):\n",
    "            if itr!=jtr:\n",
    "                trajR.append( np.nanmean(np.corrcoef(itrajectory,jtrajectory)) )\n",
    "    print(\"    correlation across all trajectories: {:1.3f}±{:1.2f}\".format(np.mean(trajR),np.std(trajR)))\n",
    "\n",
    "    print(\"... searching for repeating sequences in the ordered firing of cell IDs\")\n",
    "    size = 2\n",
    "    # size = 3\n",
    "    cluster_sequences = [x for xs in events_cellindexes for x in xs]\n",
    "    # print(cluster_sequences)\n",
    "    windows = [\n",
    "        tuple(window)\n",
    "        for window in more_itertools.windowed(cluster_sequences, size)\n",
    "    ]\n",
    "    counter = collections.Counter(windows)\n",
    "    for window, count in counter.items():\n",
    "        if count > 1:\n",
    "            print(\"   \",window, count)\n",
    "            print(core_indexes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
